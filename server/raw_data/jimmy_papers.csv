paperId,url,title,abstract,venue,year,referenceCount,citationCount,authors
06c94251e4502c483dc918f189f788e57172c14c,https://www.semanticscholar.org/paper/06c94251e4502c483dc918f189f788e57172c14c,NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation,"Retrieval-augmented generation (RAG) grounds large language model (LLM) output by leveraging external knowledge sources to reduce factual hallucinations. However, prior works lack a comprehensive evaluation of different language families, making it challenging to evaluate LLM robustness against errors in external retrieved knowledge. To overcome this, we establish NoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across 18 typologically diverse languages. NoMIRACL includes both a non-relevant and a relevant subset. Queries in the non-relevant subset contain passages judged as non-relevant, whereas queries in the relevant subset include at least a single judged relevant passage. We measure LLM robustness using two metrics: (i) hallucination rate, measuring model tendency to hallucinate an answer, when the answer is not present in passages in the non-relevant subset, and (ii) error rate, measuring model inaccuracy to recognize relevant passages in the relevant subset. In our work, we measure robustness for a wide variety of multilingual-focused LLMs and observe that most of the models struggle to balance the two capacities. Models such as LLAMA-2, Orca-2, and FLAN-T5 observe more than an 88% hallucination rate on the non-relevant subset, whereas, Mistral overall hallucinates less, but can achieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is observed to provide the best tradeoff on both subsets, highlighting future work necessary to improve LLM robustness.",arXiv.org,2023.0,58,3,"[{'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2275196928', 'name': 'Luiz Bonifacio'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2238110973', 'name': 'Xiaoguang Li'}, {'authorId': '2275118289', 'name': 'Qun Liu'}, {'authorId': '2237517964', 'name': 'Boxing Chen'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
147af99d852c516e16d90b128504a43c82ceffb8,https://www.semanticscholar.org/paper/147af99d852c516e16d90b128504a43c82ceffb8,"""Low-Resource"" Text Classification: A Parameter-Free Classification Method with Compressors",,Annual Meeting of the Association for Computational Linguistics,2023.0,0,19,"[{'authorId': '2223324062', 'name': 'Zhiying Jiang'}, {'authorId': '2168609903', 'name': 'Matthew Y. R. Yang'}, {'authorId': '2197480639', 'name': 'Mikhail Tsirlin'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '5613954', 'name': 'Yiqin Dai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
17abec01047a09c1c57a8150957e1980e618d043,https://www.semanticscholar.org/paper/17abec01047a09c1c57a8150957e1980e618d043,AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation,"This paper presents the AToMiC (Authoring Tools for Multi media Content) dataset, designed to advance research in image/text cross-modal retrieval. While vision--language pretrained transformers have led to significant improvements in retrieval effectiveness, existing research has relied on image-caption datasets that feature only simplistic image--text relationships and underspecified user models of retrieval tasks. To address the gap between these oversimplified settings and real-world applications for multimedia content creation, we introduce a new approach for building retrieval test collections. We leverage hierarchical structures and diverse domains of texts, styles, and types of images, as well as large-scale image--document associations embedded in Wikipedia. We formulate two tasks based on a realistic user model and validate our dataset through retrieval experiments using baseline models. AToMiC offers a testbed for scalable, diverse, and reproducible multimedia retrieval research. Finally, our dataset provides the basis for a dedicated track at the 2023 Text Retrieval Conference (TREC), and is publicly available at https://github.com/TREC-AToMiC/AToMiC.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,58,4,"[{'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '2131640257', 'name': 'Carlos Lassance'}, {'authorId': '147961332', 'name': 'Rafael Sampaio de Rezende'}, {'authorId': '1391084712', 'name': 'Krishna Srinivasan'}, {'authorId': '2109913', 'name': 'Miriam Redi'}, {'authorId': '2207074', 'name': 'S. Clinchant'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
20a7b1e274aff828466bba3760992aa54e14951a,https://www.semanticscholar.org/paper/20a7b1e274aff828466bba3760992aa54e14951a,How Does Generative Retrieval Scale to Millions of Passages?,"Popularized by the Differentiable Search Index, the emerging paradigm of generative retrieval re-frames the classic information retrieval problem into a sequence-to-sequence modeling task, forgoing external indices and encoding an entire document corpus within a single Transformer. Although many different approaches have been proposed to improve the effectiveness of generative retrieval, they have only been evaluated on document corpora on the order of 100k in size. We conduct the first empirical study of generative retrieval techniques across various corpus scales, ultimately scaling up to the entire MS MARCO passage ranking task with a corpus of 8.8M passages and evaluating model sizes up to 11B parameters. We uncover several findings about scaling generative retrieval to millions of passages; notably, the central importance of using synthetic queries as document representations during indexing, the ineffectiveness of existing proposed architecture modifications when accounting for compute cost, and the limits of naively scaling model parameters with respect to retrieval performance. While we find that generative retrieval is competitive with state-of-the-art dual encoders on small corpora, scaling to millions of passages remains an important and unsolved challenge. We believe these findings will be valuable for the community to clarify the current state of generative retrieval, highlight the unique challenges, and inspire new research directions.",Conference on Empirical Methods in Natural Language Processing,2023.0,51,26,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '47214884', 'name': 'Kai Hui'}, {'authorId': '143702064', 'name': 'Jai Gupta'}, {'authorId': '143828990', 'name': '√Å. Lelkes'}, {'authorId': '39371343', 'name': 'Honglei Zhuang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680617', 'name': 'Donald Metzler'}, {'authorId': '2057663102', 'name': 'Vinh Q. Tran'}]"
37536416c0da8751409a3289ac6b6355c7d61d0c,https://www.semanticscholar.org/paper/37536416c0da8751409a3289ac6b6355c7d61d0c,What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations,"Do large language models (LLMs) exhibit sociodemographic biases, even when they decline to respond? To bypass their refusal to""speak,""we study this research question by probing contextualized embeddings and exploring whether this bias is encoded in its latent representations. We propose a logistic Bradley-Terry probe which predicts word pair preferences of LLMs from the words' hidden vectors. We first validate our probe on three pair preference tasks and thirteen LLMs, where we outperform the word embedding association test (WEAT), a standard approach in testing for implicit association, by a relative 27% in error rate. We also find that word pair preferences are best represented in the middle layers. Next, we transfer probes trained on harmless tasks (e.g., pick the larger number) to controversial ones (compare ethnicities) to examine biases in nationality, politics, religion, and gender. We observe substantial bias for all target classes: for instance, the Mistral model implicitly prefers Europe to Africa, Christianity to Judaism, and left-wing to right-wing politics, despite declining to answer. This suggests that instruction fine-tuning does not necessarily debias contextualized embeddings. Our codebase is at https://github.com/castorini/biasprobe.",arXiv.org,2023.0,41,3,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '52416773', 'name': 'Ferhan Ture'}]"
3a14af18549daee147c6c747592be314418eeac3,https://www.semanticscholar.org/paper/3a14af18549daee147c6c747592be314418eeac3,Evaluating Embedding APIs for Information Retrieval,"The ever-increasing size of language models curtails their widespread access to the community, thereby galvanizing many companies and startups into offering access to large language models through APIs. One particular API, suitable for dense retrieval, is the semantic embedding API that builds vector representations of a given text. With a growing number of APIs at our disposal, in this paper, our goal is to analyze semantic embedding APIs in realistic retrieval scenarios in order to assist practitioners and researchers in finding suitable services according to their needs. Specifically, we wish to investigate the capabilities of existing APIs on domain generalization and multilingual retrieval. For this purpose, we evaluate the embedding APIs on two standard benchmarks, BEIR, and MIRACL. We find that re-ranking BM25 results using the APIs is a budget-friendly approach and is most effective on English, in contrast to the standard practice, i.e., employing them as first-stage retrievers. For non-English retrieval, re-ranking still improves the results, but a hybrid model with BM25 works best albeit at a higher cost. We hope our work lays the groundwork for thoroughly evaluating APIs that are critical in search and more broadly, in information retrieval.",Annual Meeting of the Association for Computational Linguistics,2023.0,40,12,"[{'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3f8d51ad39f260f57280995f80dcfa29f5d26343,https://www.semanticscholar.org/paper/3f8d51ad39f260f57280995f80dcfa29f5d26343,SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval,"Traditionally, sparse retrieval systems relied on lexical representations to retrieve documents, such as BM25, dominated information retrieval tasks. With the onset of pre-trained transformer models such as BERT, neural sparse retrieval has led to a new paradigm within retrieval. Despite the success, there has been limited software supporting different sparse retrievers running in a unified, common environment. This hinders practitioners from fairly comparing different sparse models and obtaining realistic evaluation results. Another missing piece is, that a majority of prior work evaluates sparse retrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO. However, a key requirement in practical retrieval systems requires models that can generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In this work, we provide SPRINT, a unified python toolkit based on Pyserini and Lucene, supporting a common interface for evaluating neural sparse retrieval. The toolkit currently includes five built-in models: uniCOIL, DeepImpact, SPARTA, TILDEv2 and SPLADEv2. Users can also easily add customized models by defining their term weighting method. Using our toolkit, we establish strong and reproducible zero-shot sparse retrieval baselines across the well-acknowledged benchmark, BEIR. Our results demonstrate that SPLADEv2 achieves the best average score of 0.470 nDCG@10 on BEIR amongst all neural sparse retrievers. In this work, we further uncover the reasons behind its performance gain. We show that SPLADEv2 produces sparse representations with a majority of tokens outside of the original query and document which is often crucial for its performance gains, i.e. a limitation among its other sparse counterparts. We provide our SPRINT toolkit, models, and data used in our experiments publicly here: https://github.com/thakur-nandan/sprint.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,55,1,"[{'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2124617718', 'name': 'Kexin Wang'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4267ba44ced8e2c6afa39547aa6657aef62502e1,https://www.semanticscholar.org/paper/4267ba44ced8e2c6afa39547aa6657aef62502e1,"Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models","Recent work in zero-shot listwise reranking using LLMs has achieved state-of-the-art results. However, these methods are not without drawbacks. The proposed methods rely on large LLMs with billions of parameters and limited context sizes. This paper introduces LiT5-Distill and LiT5-Score, two methods for efficient zero-shot listwise reranking, leveraging T5 sequence-to-sequence encoder-decoder models. Our approaches demonstrate competitive reranking effectiveness compared to recent state-of-the-art LLM rerankers with substantially smaller models. Through LiT5-Score, we also explore the use of cross-attention to calculate relevance scores to perform reranking, eliminating the reliance on external passage relevance labels for training. We present a range of models from 220M parameters to 3B parameters, all with strong reranking results, challenging the necessity of large-scale models for effective zero-shot reranking and opening avenues for more efficient listwise reranking solutions. We provide code and scripts to reproduce our results at https://github.com/castorini/LiT5.",arXiv.org,2023.0,25,4,"[{'authorId': '2124417361', 'name': 'M. Tamber'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5605e5bbe71a6d52be0930865f1635ed8644dea8,https://www.semanticscholar.org/paper/5605e5bbe71a6d52be0930865f1635ed8644dea8,RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!,"In information retrieval, proprietary large language models (LLMs) such as GPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital role in reranking. However, the gap between open-source and closed models persists, with reliance on proprietary, non-transparent models constraining reproducibility. Addressing this gap, we introduce RankZephyr, a state-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr not only bridges the effectiveness gap with GPT-4 but in some cases surpasses the proprietary model. Our comprehensive evaluations across several datasets (TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability. RankZephyr benefits from strategic training choices and is resilient against variations in initial document ordering and the number of documents reranked. Additionally, our model outperforms GPT-4 on the NovelEval test set, comprising queries and passages past its training period, which addresses concerns about data contamination. To foster further research in this rapidly evolving field, we provide all code necessary to reproduce our results at https://github.com/castorini/rank_llm.",arXiv.org,2023.0,40,12,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '71076877', 'name': 'Sahel Sharifymoghaddam'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
610bfeb562ce11cd3a6e7588427daf489e3b4e94,https://www.semanticscholar.org/paper/610bfeb562ce11cd3a6e7588427daf489e3b4e94,Simple Yet Effective Neural Ranking and Reranking Baselines for Cross-Lingual Information Retrieval,"The advent of multilingual language models has generated a resurgence of interest in cross-lingual information retrieval (CLIR), which is the task of searching documents in one language with queries from another. However, the rapid pace of progress has led to a confusing panoply of methods and reproducibility has lagged behind the state of the art. In this context, our work makes two important contributions: First, we provide a conceptual framework for organizing different approaches to cross-lingual retrieval using multi-stage architectures for mono-lingual retrieval as a scaffold. Second, we implement simple yet effective reproducible baselines in the Anserini and Pyserini IR toolkits for test collections from the TREC 2022 NeuCLIR Track, in Persian, Russian, and Chinese. Our efforts are built on a collaboration of the two teams that submitted the most effective runs to the TREC evaluation. These contributions provide a firm foundation for future advances.",arXiv.org,2023.0,53,3,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2167031295', 'name': 'Vitor Jeronymo'}, {'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '2131640257', 'name': 'Carlos Lassance'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}]"
72a9187b489992cad3d54420611d5039eb6b9d86,https://www.semanticscholar.org/paper/72a9187b489992cad3d54420611d5039eb6b9d86,One Blade for One Purpose: Advancing Math Information Retrieval using Hybrid Search,"Neural retrievers have been shown to be effective for math-aware search. Their ability to cope with math symbol mismatches, to represent highly contextualized semantics, and to learn effective representations are critical to improving math information retrieval. However, the most effective retriever for math remains impractical as it depends on token-level dense representations for each math token, which leads to prohibitive storage demands, especially considering that math content generally consumes more tokens. In this work, we try to alleviate this efficiency bottleneck while boosting math information retrieval effectiveness via hybrid search. To this end, we propose MABOWDOR, a Math-Aware Bestof-Worlds Domain Optimized Retriever, which has an unsupervised structure search component, a dense retriever, and optionally a sparse retriever on top of a domain-adapted backbone learned by context-enhanced pretraining, each addressing a different need in retrieving heterogeneous data from math documents. Our hybrid search outperforms the previous state-of-the-art math IR system while eliminating efficiency bottlenecks. Our system is available at https://github.com/approach0/pya0.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,86,5,"[{'authorId': '2100393067', 'name': 'Wei Zhong'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
751563cf0c32fe4dfa43d3416c916f8eb053e5f3,https://www.semanticscholar.org/paper/751563cf0c32fe4dfa43d3416c916f8eb053e5f3,GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training Data Exploration,"Noticing the urgent need to provide tools for fast and user-friendly qualitative analysis of large-scale textual corpora of the modern NLP, we propose to turn to the mature and well-tested methods from the domain of Information Retrieval (IR) - a research field with a long history of tackling TB-scale document collections. We discuss how Pyserini - a widely used toolkit for reproducible IR research can be integrated with the Hugging Face ecosystem of open-source AI libraries and artifacts. We leverage the existing functionalities of both platforms while proposing novel features further facilitating their integration. Our goal is to give NLP researchers tools that will allow them to develop retrieval-based instrumentation for their data analytics needs with ease and agility.We include a Jupyter Notebook-based walk through the core interoperability features, available on GitHub: https://github.com/huggingface/gaia.We then demonstrate how the ideas we present can be operationalized to create a powerful tool for qualitative data analysis in NLP. We present GAIA Search - a search engine built following previously laid out principles, giving access to four popular large-scale text collections. GAIA serves a dual purpose of illustrating the potential of methodologies we discuss but also as a standalone qualitative analysis tool that can be leveraged by NLP researchers aiming to understand datasets prior to using them in training. GAIA is hosted live on Hugging Face Spaces: https://huggingface.co/spaces/spacerini/gaia.",Annual Meeting of the Association for Computational Linguistics,2023.0,54,5,"[{'authorId': '120174856', 'name': 'Aleksandra Piktus'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2003696840', 'name': 'Christopher Akiki'}, {'authorId': '2175480812', 'name': 'Akintunde Oladipo'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2184031883', 'name': 'Hailey Schoelkopf'}, {'authorId': '103476203', 'name': 'Stella Biderman'}, {'authorId': '3046200', 'name': 'Martin Potthast'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8be0ec99f80710887e3a8e6bac5fba51a8fd7186,https://www.semanticscholar.org/paper/8be0ec99f80710887e3a8e6bac5fba51a8fd7186,Zero-Shot Listwise Document Reranking with a Large Language Model,"Supervised ranking methods based on bi-encoder or cross-encoder architectures have shown success in multi-stage text ranking tasks, but they require large amounts of relevance judgments as training data. In this work, we propose Listwise Reranker with a Large Language Model (LRL), which achieves strong reranking effectiveness without using any task-specific training data. Different from the existing pointwise ranking methods, where documents are scored independently and ranked according to the scores, LRL directly generates a reordered list of document identifiers given the candidate documents. Experiments on three TREC web search datasets demonstrate that LRL not only outperforms zero-shot pointwise methods when reranking first-stage retrieval results, but can also act as a final-stage reranker to improve the top-ranked results of a pointwise method for improved efficiency. Additionally, we apply our approach to subsets of MIRACL, a recent multilingual retrieval dataset, with results showing its potential to generalize across different languages.",arXiv.org,2023.0,30,18,"[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
962052c6ef89d3ae317759df42bc762aab59dc30,https://www.semanticscholar.org/paper/962052c6ef89d3ae317759df42bc762aab59dc30,Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes,"Anserini is a Lucene-based toolkit for reproducible information retrieval research in Java that has been gaining traction in the community. It provides retrieval capabilities for both ""traditional"" bag-of-words retrieval models such as BM25 as well as retrieval using learned sparse representations such as SPLADE. With Pyserini, which provides a Python interface to Anserini, users gain access to both sparse and dense retrieval models, as Pyserini implements bindings to the Faiss vector search library alongside Lucene inverted indexes in a uniform, consistent interface. Nevertheless, hybrid fusion techniques that integrate sparse and dense retrieval models need to stitch together results from two completely different ""software stacks"", which creates unnecessary complexities and inefficiencies. However, the introduction of HNSW indexes for dense vector search in Lucene promises the integration of both dense and sparse retrieval within a single software framework. We explore exactly this integration in the context of Anserini. Experiments on the MS MARCO passage and BEIR datasets show that our Anserini HNSW integration supports (reasonably) effective and (reasonably) efficient approximate nearest neighbor search for dense retrieval models, using only Lucene.",International Conference on Information and Knowledge Management,2023.0,26,3,"[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '16973085', 'name': 'Tommaso Teofili'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9e3facfdf48fc6fbdeab602647f360ceaf9c6313,https://www.semanticscholar.org/paper/9e3facfdf48fc6fbdeab602647f360ceaf9c6313,MIRACL: A Multilingual Retrieval Dataset Covering 18 Diverse Languages,"Abstract MIRACL is a multilingual dataset for ad hoc retrieval across 18 languages that collectively encompass over three billion native speakers around the world. This resource is designed to support monolingual retrieval tasks, where the queries and the corpora are in the same language. In total, we have gathered over 726k high-quality relevance judgments for 78k queries over Wikipedia in these languages, where all annotations have been performed by native speakers hired by our team. MIRACL covers languages that are both typologically close as well as distant from 10 language families and 13 sub-families, associated with varying amounts of publicly available resources. Extensive automatic heuristic verification and manual assessments were performed during the annotation process to control data quality. In total, MIRACL represents an investment of around five person-years of human annotator effort. Our goal is to spur research on improving retrieval across a continuum of languages, thus enhancing information access capabilities for diverse populations around the world, particularly those that have traditionally been underserved. MIRACL is available at http://miracl.ai/.",Transactions of the Association for Computational Linguistics,2023.0,54,16,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2238110973', 'name': 'Xiaoguang Li'}, {'authorId': '1688015', 'name': 'Qun Liu'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a08bde10a47059b0ba1e58b425dd080ec9b42339,https://www.semanticscholar.org/paper/a08bde10a47059b0ba1e58b425dd080ec9b42339,Vector Search with OpenAI Embeddings: Lucene Is All You Need,"We provide a reproducible, end-to-end demonstration of vector search with OpenAI embeddings using Lucene on the popular MS MARCO passage ranking test collection. The main goal of our work is to challenge the prevailing narrative that a dedicated vector store is necessary to take advantage of recent advances in deep neural networks as applied to search. Quite the contrary, we show that hierarchical navigable small-world network (HNSW) indexes in Lucene are adequate to provide vector search capabilities in a standard bi-encoder architecture. This suggests that, from a simple cost-benefit analysis, there does not appear to be a compelling reason to introduce a dedicated vector store into a modern""AI stack""for search, since such applications have already received substantial investments in existing, widely deployed infrastructure.",Web Search and Data Mining,2023.0,30,4,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2235063355', 'name': 'Tommaso Teofili'}, {'authorId': '2235064158', 'name': 'Jasper Xian'}]"
a4867148c2f692efc6c22c3935a59be2d04ea3e9,https://www.semanticscholar.org/paper/a4867148c2f692efc6c22c3935a59be2d04ea3e9,How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval,"Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing model size. In particular, we systematically examine the contrastive learning of DRs, under the framework of Data Augmentation (DA). Our study shows that common DA practices such as query augmentation with generative models and pseudo-relevance label creation using a cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA approach with diverse queries and sources of supervision to progressively train a generalizable DR. As a result, DRAGON, our dense retriever trained with diverse augmentation, is the first BERT-base-sized DR to achieve state-of-the-art effectiveness in both supervised and zero-shot evaluations and even competes with models using more complex late interaction (ColBERTv2 and SPLADE++).",Conference on Empirical Methods in Natural Language Processing,2023.0,58,25,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '35584853', 'name': 'Akari Asai'}, {'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '9185192', 'name': 'Barlas Oƒüuz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2121361882', 'name': 'Yashar Mehdad'}, {'authorId': '2072801764', 'name': 'Wen-tau Yih'}, {'authorId': '1769736', 'name': 'Xilun Chen'}]"
a490b53568adca4c28f28b9660bbdf6a46bde37c,https://www.semanticscholar.org/paper/a490b53568adca4c28f28b9660bbdf6a46bde37c,MMEAD: MS MARCO Entity Annotations and Disambiguations,"MMEAD, or MS MARCO Entity Annotations and Disambiguations, is a resource for entity links for the MS MARCO datasets. We specify a format to store and share links for both document and passage collections of MS MARCO. Following this specification, we release entity links to Wikipedia for documents and passages in both MS MARCO collections (v1 and v2). Entity links have been produced by the REL and BLINK systems. MMEAD is an easy-to-install Python package, allowing users to load the link data and entity embeddings effortlessly. Using MMEAD takes only a few lines of code. Finally, we show how MMEAD can be used for IR research that uses entity information. We show how to improve recall@1000 and MRR@10 on more complex queries on the MS MARCO v1 passage dataset by using this resource. We also demonstrate how entity expansions can be used for interactive search applications.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,35,0,"[{'authorId': '1591687213', 'name': 'Chris Kamphuis'}, {'authorId': '2054897807', 'name': 'Aileen Lin'}, {'authorId': '6432982', 'name': 'Siwen Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1701063719', 'name': 'Arjen P. de Vries'}, {'authorId': '1951737', 'name': 'Faegheh Hasibi'}]"
a74c49d96ab32c9bf398a23c9b46f36bfeb6ec4b,https://www.semanticscholar.org/paper/a74c49d96ab32c9bf398a23c9b46f36bfeb6ec4b,Regex-augmented Domain Transfer Topic Classification based on a Pre-trained Language Model: An application in Financial Domain,"A common way to use large pre-trained language models for downstream tasks is to fine tune them using additional layers. This may not work well if downstream domain is a specialized domain whereas the large language model has been pre-trained on a generic corpus. In this paper, we discuss the use of regular expression patterns employed as features for domain knowledge during the process of fine tuning, in addition to domain specific text. Our experiments on real scenario production data show that this method of fine tuning improves the downstream text classification tasks as compared to fine tuning only on domain specific text. We also show that the use of attention network for fine tuning improves results compared to simple linear layers.",arXiv.org,2023.0,25,0,"[{'authorId': '2218487887', 'name': 'Vanessa Liao'}, {'authorId': '2307843', 'name': 'Syed Shariyar Murtaza'}, {'authorId': '152972511', 'name': 'Yifan Nie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b408198f2c891720738c385272afeeebcd747268,https://www.semanticscholar.org/paper/b408198f2c891720738c385272afeeebcd747268,HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution,"The rise of large language models (LLMs) had a transformative impact on search, ushering in a new era of search engines that are capable of generating search results in natural language text, imbued with citations for supporting sources. Building generative information-seeking models demands openly accessible datasets, which currently remain lacking. In this paper, we introduce a new dataset, HAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset) for building end-to-end generative information-seeking models that are capable of retrieving candidate quotes and generating attributed explanations. Unlike recent efforts that focus on human evaluation of black-box proprietary search engines, we built our dataset atop the English subset of MIRACL, a publicly available information retrieval dataset. HAGRID is constructed based on human and LLM collaboration. We first automatically collect attributed explanations that follow an in-context citation style using an LLM, i.e. GPT-3.5. Next, we ask human annotators to evaluate the LLM explanations based on two criteria: informativeness and attributability. HAGRID serves as a catalyst for the development of information-seeking models with better attribution capabilities.",arXiv.org,2023.0,57,13,"[{'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '31036999', 'name': 'A. Jafari'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
bda7b805cee90412e7043a333a809d0e78852eb3,https://www.semanticscholar.org/paper/bda7b805cee90412e7043a333a809d0e78852eb3,Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard,"BEIR is a benchmark dataset for zero-shot evaluation of information retrieval models across 18 different domain/task combinations. In recent years, we have witnessed the growing popularity of a representation learning approach to building retrieval models, typically using pretrained transformers in a supervised setting. This naturally begs the question: How effective are these models when presented with queries and documents that differ from the training data? Examples include searching in different domains (e.g., medical or legal text) and with different types of queries (e.g., keywords vs. well-formed questions). While BEIR was designed to answer these questions, our work addresses two shortcomings that prevent the benchmark from achieving its full potential: First, the sophistication of modern neural methods and the complexity of current software infrastructure create barriers to entry for newcomers. To this end, we provide reproducible reference implementations that cover the two main classes of approaches: learned dense and sparse models. Second, there does not exist a single authoritative nexus for reporting the effectiveness of different models on BEIR, which has led to difficulty in comparing different methods. To remedy this, we present an official self-service BEIR leaderboard that provides fair and consistent comparisons of retrieval models. By addressing both shortcomings, our work facilitates future explorations in a range of interesting research questions that BEIR enables.",arXiv.org,2023.0,42,5,"[{'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2131640257', 'name': 'Carlos Lassance'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c0e62e324dfc7bd45ec0a5ce4055823d1f0c03f1,https://www.semanticscholar.org/paper/c0e62e324dfc7bd45ec0a5ce4055823d1f0c03f1,Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval,"Dense retrieval models have predominantly been studied for English, where models have shown great success, due to the availability of human-labeled training pairs. However, there has been limited success for multilingual retrieval so far, as training data is uneven or scarcely available across multiple languages. Synthetic training data generation is promising (e.g., InPars or Promptagator), but has been investigated only for English. Therefore, to study model capabilities across both cross-lingual and monolingual retrieval tasks, we develop SWIM-IR, a synthetic retrieval training dataset containing 33 (high to very-low resource) languages for training multilingual dense retrieval models without requiring any human supervision. To construct SWIM-IR, we propose SAP (summarize-then-ask prompting), where the large language model (LLM) generates a textual summary prior to the query generation step. SAP assists the LLM in generating informative queries in the target language. Using SWIM-IR, we explore synthetic fine-tuning of multilingual dense retrieval models and evaluate them robustly on three retrieval benchmarks: XOR-Retrieve (cross-lingual), XTREME-UP (cross-lingual) and MIRACL (monolingual). Our models, called SWIM-X, are competitive with human-supervised dense retrieval models, e.g., mContriever, finding that SWIM-IR can cheaply substitute for expensive human-labeled retrieval training data.",arXiv.org,2023.0,66,3,"[{'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2148023', 'name': 'Jianmo Ni'}, {'authorId': '2124016663', 'name': 'Gustavo Hern√°ndez Abrego'}, {'authorId': '2261280849', 'name': 'J. Wieting'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2266238595', 'name': 'Daniel Cer'}]"
c198c1193f924953b649002413979e7733c93a48,https://www.semanticscholar.org/paper/c198c1193f924953b649002413979e7733c93a48,Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face,"We present Spacerini, a tool that integrates the Pyserini toolkit for reproducible information retrieval research with Hugging Face to enable the seamless construction and deployment of interactive search engines. Spacerini makes state-of-the-art sparse and dense retrieval models more accessible to non-IR practitioners while minimizing deployment effort. This is useful for NLP researchers who want to better understand and validate their research by performing qualitative analyses of training corpora, for IR researchers who want to demonstrate new retrieval models integrated into the growing Pyserini ecosystem, and for third parties reproducing the work of other researchers. Spacerini is open source and includes utilities for loading, preprocessing, indexing, and deploying search engines locally and remotely. We demonstrate a portfolio of 13 search engines created with Spacerini for different use cases.",Conference on Empirical Methods in Natural Language Processing,2023.0,33,4,"[{'authorId': '2003696840', 'name': 'Christopher Akiki'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '120174856', 'name': 'Aleksandra Piktus'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2175480812', 'name': 'Akintunde Oladipo'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3046200', 'name': 'Martin Potthast'}]"
c47676d655d82904d5844015a1cac08bdab2ed44,https://www.semanticscholar.org/paper/c47676d655d82904d5844015a1cac08bdab2ed44,Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models,"Listwise rerankers based on large language models (LLM) are the zero-shot state-of-the-art. However, current works in this direction all depend on the GPT models, making it a single point of failure in scientific reproducibility. Moreover, it raises the concern that the current research findings only hold for GPT models but not LLM in general. In this work, we lift this pre-condition and build for the first time effective listwise rerankers without any form of dependency on GPT. Our passage retrieval experiments show that our best list se reranker surpasses the listwise rerankers based on GPT-3.5 by 13% and achieves 97% effectiveness of the ones built on GPT-4. Our results also show that the existing training datasets, which were expressly constructed for pointwise ranking, are insufficient for building such listwise rerankers. Instead, high-quality listwise ranking data is required and crucial, calling for further work on building human-annotated listwise data resources.",arXiv.org,2023.0,57,1,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2269733348', 'name': 'Sebastian Hofstatter'}, {'authorId': '2269736739', 'name': 'Patrick Lewis'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d68753acfbd0a3d007842884d56a776b45982e6e,https://www.semanticscholar.org/paper/d68753acfbd0a3d007842884d56a776b45982e6e,Improving Out-of-Distribution Generalization of Neural Rerankers with Contextualized Late Interaction,"Recent progress in information retrieval finds that embedding query and document representation into multi-vector yields a robust bi-encoder retriever on out-of-distribution datasets. In this paper, we explore whether late interaction, the simplest form of multi-vector, is also helpful to neural rerankers that only use the [CLS] vector to compute the similarity score. Although intuitively, the attention mechanism of rerankers at the previous layers already gathers the token-level information, we find adding late interaction still brings an extra 5% improvement in average on out-of-distribution datasets, with little increase in latency and no degradation in in-domain effectiveness. Through extensive experiments and analysis, we show that the finding is consistent across different model sizes and first-stage retrievers of diverse natures and that the improvement is more prominent on longer queries.",arXiv.org,2023.0,27,1,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
daa475da0602008b72aa61a369fd8af1ebfadbfa,https://www.semanticscholar.org/paper/daa475da0602008b72aa61a369fd8af1ebfadbfa,Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages,"Large language models (LLMs) have shown impressive zero-shot capabilities in various document reranking tasks. Despite their successful implementations, there is still a gap in existing literature on their effectiveness in low-resource languages. To address this gap, we investigate how LLMs function as rerankers in cross-lingual information retrieval (CLIR) systems for African languages. Our implementation covers English and four African languages (Hausa, Somali, Swahili, and Yoruba) and we examine cross-lingual reranking with queries in English and passages in the African languages. Additionally, we analyze and compare the effectiveness of monolingual reranking using both query and document translations. We also evaluate the effectiveness of LLMs when leveraging their own generated translations. To get a grasp of the effectiveness of multiple LLMs, our study focuses on the proprietary models RankGPT-4 and RankGPT-3.5, along with the open-source model, RankZephyr. While reranking remains most effective in English, our results reveal that cross-lingual reranking may be competitive with reranking in African languages depending on the multilingual capability of the LLM.",arXiv.org,2023.0,21,0,"[{'authorId': '2056770646', 'name': 'Mofetoluwa Adeyemi'}, {'authorId': '2175480812', 'name': 'Akintunde Oladipo'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e1f513fe13b735b7829c5b7d27040512f189efcb,https://www.semanticscholar.org/paper/e1f513fe13b735b7829c5b7d27040512f189efcb,SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes,"This paper introduces Sparsified Late Interaction for Multi-vector (SLIM) retrieval with inverted indexes. Multi-vector retrieval methods have demonstrated their effectiveness on various retrieval datasets, and among them, ColBERT is the most established method based on the late interaction of contextualized token embeddings of pre-trained language models. However, efficient ColBERT implementations require complex engineering and cannot take advantage of off-the-shelf search libraries, impeding their practical use. To address this issue, SLIM first maps each contextualized token vector to a sparse, high-dimensional lexical space before performing late interaction between these sparse token embeddings. We then introduce an efficient two-stage retrieval architecture that includes inverted index retrieval followed by a score refinement module to approximate the sparsified late interaction, which is fully compatible with off-the-shelf lexical search libraries such as Lucene. SLIM achieves competitive accuracy on MS MARCO Passages and BEIR compared to ColBERT while being much smaller and faster on CPUs. To our knowledge, we are the first to explore using sparse token representations for multi-vector retrieval. Source code and data are integrated into the Pyserini IR toolkit.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,50,7,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e6f9e70182d2b10a9b97541091ecc73c37c6028a,https://www.semanticscholar.org/paper/e6f9e70182d2b10a9b97541091ecc73c37c6028a,Which Model Shall I Choose? Cost/Quality Trade-offs for Text Classification Tasks,"Industry practitioners always face the problem of choosing the appropriate model for deployment under different considerations, such as to maximize a metric that is crucial for production, or to reduce the total cost given financial concerns. In this work, we focus on the text classification task and present a quantitative analysis for this challenge. Using classification accuracy as the main metric, we evaluate the classifiers' performances for a variety of models, including large language models, along with their associated costs, including the annotation cost, training (fine-tuning) cost, and inference cost. We then discuss the model choices for situations like having a large number of samples needed for inference. We hope our work will help people better understand the cost/quality trade-offs for the text classification task.",arXiv.org,2023.0,16,1,"[{'authorId': '49392769', 'name': 'Shi Zong'}, {'authorId': '150162316', 'name': 'Joshua Seltzer'}, {'authorId': '1943594', 'name': 'Jia-Yu Pan'}, {'authorId': '2142236015', 'name': 'Kathy Cheng'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f170594b13efb4a93ef9819179fc929cac6809bf,https://www.semanticscholar.org/paper/f170594b13efb4a93ef9819179fc929cac6809bf,Approximating Human-Like Few-shot Learning with GPT-based Compression,"In this work, we conceptualize the learning process as information compression. We seek to equip generative pre-trained models with human-like learning capabilities that enable data compression during inference. We present a novel approach that utilizes the Generative Pre-trained Transformer (GPT) to approximate Kolmogorov complexity, with the aim of estimating the optimal Information Distance for few-shot learning. We first propose using GPT as a prior for lossless text compression, achieving a noteworthy compression ratio. Experiment with LLAMA2-7B backbone achieves a compression ratio of 15.5 on enwik9. We justify the pre-training objective of GPT models by demonstrating its equivalence to the compression length, and, consequently, its ability to approximate the information distance for texts. Leveraging the approximated information distance, our method allows the direct application of GPT models in quantitative text similarity measurements. Experiment results show that our method overall achieves superior performance compared to embedding and prompt baselines on challenging NLP tasks, including semantic similarity, zero and one-shot text classification, and zero-shot text ranking.",arXiv.org,2023.0,80,1,"[{'authorId': '2164357582', 'name': 'C.-Y. Huang'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '2227477490', 'name': 'Zhiying Jiang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2150652992', 'name': 'Ming Li'}]"
05cb33c55c44ab26848a865eb6062b5b027caacc,https://www.semanticscholar.org/paper/05cb33c55c44ab26848a865eb6062b5b027caacc,An Encoder Attribution Analysis for Dense Passage Retriever in Open-Domain Question Answering,"The bi-encoder design of dense passage retriever (DPR) is a key factor to its success in open-domain question answering (QA), yet it is unclear how DPR‚Äôs question encoder and passage encoder individually contributes to overall performance, which we refer to as the encoder attribution problem. The problem is important as it helps us identify the factors that affect individual encoders to further improve overall performance. In this paper, we formulate our analysis under a probabilistic framework called encoder marginalization, where we quantify the contribution of a single encoder by marginalizing other variables. First, we find that the passage encoder contributes more than the question encoder to in-domain retrieval accuracy. Second, we demonstrate how to find the affecting factors for each encoder, where we train DPR with different amounts of data and use encoder marginalization to analyze the results. We find that positive passage overlap and corpus coverage of training data have big impacts on the passage encoder, while the question encoder is mainly affected by training sample complexity under this setting. Based on this framework, we can devise data-efficient training regimes: for example, we manage to train a passage encoder on SQuAD using 60% less training data without loss of accuracy.",TRUSTNLP,2022.0,64,3,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0c430ea48e37ff43d3ab373ea1441468aa923653,https://www.semanticscholar.org/paper/0c430ea48e37ff43d3ab373ea1441468aa923653,Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking,"In information retrieval (IR), candidate set pruning has been commonly used to speed up two-stage relevance ranking. However, such an approach lacks accurate error control and often trades accuracy against computational efficiency in an empirical fashion, missing theoretical guarantees. In this paper, we propose the concept of certified error control of candidate set pruning for relevance ranking, which means that the test error after pruning is guaranteed to be controlled under a user-specified threshold with high probability. Both in-domain and out-of-domain experiments show that our method successfully prunes the first-stage retrieved candidate sets to improve the second-stage reranking speed while satisfying the pre-specified accuracy constraints in both settings. For example, on MS MARCO Passage v1, our method reduces the average candidate set size from 1000 to 27, increasing reranking speed by about 37 times, while keeping MRR@10 greater than a pre-specified value of 0.38 with about 90% empirical coverage. In contrast, empirical baselines fail to meet such requirements. Code and data are available at: https://github.com/alexlimh/CEC-Ranking.",Conference on Empirical Methods in Natural Language Processing,2022.0,52,4,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '40975176', 'name': 'Hongyang Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
34ff09ddf6ae64299564cb673044055b4615fc3c,https://www.semanticscholar.org/paper/34ff09ddf6ae64299564cb673044055b4615fc3c,Domain Adaptation for Memory-Efficient Dense Retrieval,"Dense retrievers encode documents into Ô¨Åxed dimensional embeddings. However, storing all the document embeddings within an index produces bulky indexes which are expensive to serve. Recently, BPR (Yamada et al., 2021) and JPQ (Zhan et al., 2021a) have been proposed which train the model to produce binary document vectors, which reduce the index 32 √ó and more. The authors showed these binary embedding models signiÔ¨Åcantly outperform more traditional index compression techniques like Product Quantization (PQ). Previous work evaluated these approaches just in-domain, i.e. the methods were evaluated on tasks for which training data is available. In practice, retrieval models are often used in an out-of-domain setting, where they have been train on a publicly available dataset, like MS MARCO, but are then used for some custom dataset for which no training data is available. In this work, we show that binary embedding models like BPR and JPQ can perform significantly worse than baselines once there is a domain-shift involved. We propose a modiÔ¨Å-cation to the training procedure of BPR and JPQ and combine it with a corpus speciÔ¨Åc generative procedure which allow the adaptation of BPR and JPQ to any corpus without requiring labeled training data. Our domain-adapted strategy known as GPL is model ag-nostic, achieves an improvement by up-to 19.3 and 11.6 points in nDCG@10 across the BEIR benchmark in comparison to BPR and JPQ while maintaining its 32x memory efÔ¨Åciency. JPQ+GPL even outperforms our upper base-line: uncompressed TAS-B model on average by 2.0 points. 1",arXiv.org,2022.0,68,13,"[{'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2959414', 'name': 'Nils Reimers'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
35a318073ab5b18cf364699e145a750940bcedb3,https://www.semanticscholar.org/paper/35a318073ab5b18cf364699e145a750940bcedb3,Neural Query Synthesis and Domain-Specific Ranking Templates for Multi-Stage Clinical Trial Matching,"In this work, we propose an effective multi-stage neural ranking system for the clinical trial matching problem. First, we introduce NQS, a neural query synthesis method that leverages a zero-shot document expansion model to generate multiple sentence-long queries from lengthy patient descriptions. These queries are independently issued to a search engine and the results are fused. We find that on the TREC 2021 Clinical Trials Track, this method outperforms strong traditional baselines like BM25 and BM25 + RM3 by about 12 points in nDCG@10, a relative improvement of 34%. This simple method is so effective that even a state-of-the-art neural relevance ranking method trained on the medical subset of MS MARCO passage, when reranking the results of NQS, fails to improve on the ranked list. Second, we introduce a two-stage neural reranking pipeline trained on clinical trial matching data using tailored ranking templates. In this setting, we can train a pointwise reranker using just 1.1k positive examples and obtain effectiveness improvements over NQS by 24 points. This end-to-end multi-stage system demonstrates a 20% relative effectiveness gain compared to the second-best submission at TREC 2021, making it an important step towards better automated clinical trial matching.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,17,9,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2162396776', 'name': 'Yilin Li'}, {'authorId': '2141320609', 'name': 'Yuetong Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
37d626720f5003373336098ce7c01a1a38e6b63d,https://www.semanticscholar.org/paper/37d626720f5003373336098ce7c01a1a38e6b63d,What the DAAM: Interpreting Stable Diffusion Using Cross Attention,"Diffusion models are a milestone in text-to-image generation, but they remain poorly understood, lacking interpretability analyses. In this paper, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced model. To produce attribution maps, we upscale and aggregate cross-attention maps in the denoising module, naming our method DAAM. We validate it by testing its segmentation ability on nouns, as well as its generalized attribution quality on all parts of speech, rated by humans. On two generated datasets, we attain a competitive 58.8-64.8 mIoU on noun segmentation and fair to good mean opinion scores (3.4-4.2) on generalized attribution. Then, we apply DAAM to study the role of syntax in the pixel space across head‚Äìdependent heat map interaction patterns for ten common dependency relations. We show that, for some relations, the head map consistently subsumes the dependent, while the opposite is true for others. Finally, we study several semantic phenomena, focusing on feature entanglement; we find that the presence of cohyponyms worsens generation quality by 9%, and descriptive adjectives attend too broadly. We are the first to interpret large diffusion models from a visuolinguistic perspective, which enables future research. Our code is at https://github.com/castorini/daam.",Annual Meeting of the Association for Computational Linguistics,2022.0,59,64,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2070539062', 'name': 'Akshat Pandey'}, {'authorId': '3109913', 'name': 'Zhiying Jiang'}, {'authorId': '47125226', 'name': 'Gefei Yang'}, {'authorId': '153359454', 'name': 'K. Kumar'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '52416773', 'name': 'Ferhan Ture'}]"
38e1a9c5599fc7597b7c5ffd37951ba5f528094c,https://www.semanticscholar.org/paper/38e1a9c5599fc7597b7c5ffd37951ba5f528094c,XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing,"In-context learning using large language models has recently shown surprising results for semantic parsing tasks such as Text-to-SQL translation. Prompting GPT-3 or Codex using several examples of question-SQL pairs can produce excellent results, comparable to state-of-the-art finetuning-based models. However, existing work primarily focuses on English datasets, and it is unknown whether large language models can serve as competitive semantic parsers for other languages. To bridge this gap, our work focuses on cross-lingual Text-to-SQL semantic parsing for translating non-English utterances into SQL queries based on an English schema. We consider a zero-shot transfer learning setting with the assumption that we do not have any labeled examples in the target language (but have annotated examples in English). This work introduces the XRICL framework, which learns to retrieve relevant English exemplars for a given query to construct prompts. We also include global translation exemplars for a target language to facilitate the translation process for large language models. To systematically evaluate our model, we construct two new benchmark datasets, XSpider and XKaggle-dbqa, which include questions in Chinese, Vietnamese, Farsi, and Hindi. Our experiments show that XRICL effectively leverages large pre-trained language models to outperform existing baselines. Data and code are publicly available at https://github.com/Impavidity/XRICL.",Conference on Empirical Methods in Natural Language Processing,2022.0,59,19,"[{'authorId': '2055357805', 'name': 'Peng Shi'}, {'authorId': '15176410', 'name': 'Rui Zhang'}, {'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3ea4d0bbb313dbaa28e3eb9680879dff80cab84d,https://www.semanticscholar.org/paper/3ea4d0bbb313dbaa28e3eb9680879dff80cab84d,Temporal Early Exiting for Streaming Speech Commands Recognition,"Limited-vocabulary speech commands recognition is the task of classifying a short utterance as one of several speech commands, for which neural networks obtain state-of-the-art results. In particular, recurrent neural networks represent a common approach for streaming commands recognition systems. In this paper, we explore resource-efficient methods to short-circuit such systems in the time domain when the model is confident in its prediction. We propose applying a frame-level labeling objective to further improve the efficiency‚Äìaccuracy trade-off. On two datasets in limited-vocabulary commands recognition, our best method achieves an average time savings of 45% of the utterance without reducing the absolute accuracy by more than 0.6 points. We show that the per-instance savings depend on the length of the unique prefix in the phonemes across a dataset.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2022.0,25,11,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '153359454', 'name': 'K. Kumar'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '48041468', 'name': 'P. Vyas'}, {'authorId': '50135600', 'name': 'Wenyan Li'}, {'authorId': '47125226', 'name': 'Gefei Yang'}, {'authorId': '49600216', 'name': 'Yajie Mao'}, {'authorId': '2161396007', 'name': 'Craig Murray'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
423f94251781e9169f2a96bb3208f7feb2a89b0e,https://www.semanticscholar.org/paper/423f94251781e9169f2a96bb3208f7feb2a89b0e,Document Expansion Baselines and Learned Sparse Lexical Representations for MS MARCO V1 and V2,"With doc2query, we train a neural sequence-to-sequence model that, given an input span of text, predicts a natural language query that the text might answer. These predictions can be viewed as document expansions that feed standard bag-of-words term weighting models such as BM25 or neural retrieval models based on learned sparse lexical representations such as uniCOIL. Previous experiments on the MS MARCO datasets have demonstrated the effectiveness of these methods, and they serve as baselines that are widely used by the community today. Following the recent release of the MS MARCO V2 passage and document ranking test collections, we have refreshed our doc2query and uniCOIL models. This work describes a number of resources that support competitive, reproducible baselines for both the MS MARCO V1 and V2 test collections using our Anserini and Pyserini IR toolkits. Together, they provide a solid foundation for future research on neural retrieval models using the MS MARCO datasets and beyond.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,33,11,"[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
45a3c9be0cc9a9b31e8c524b4a5ab7c43231fc84,https://www.semanticscholar.org/paper/45a3c9be0cc9a9b31e8c524b4a5ab7c43231fc84,Better Than Whitespace: Information Retrieval for Languages without Custom Tokenizers,"Tokenization is a crucial step in information retrieval, especially for lexical matching algorithms, where the quality of indexable tokens directly impacts the effectiveness of a retrieval system. Since different languages have unique properties, the design of the tokenization algorithm is usually language-specific and requires at least some lingustic knowledge. However, only a handful of the 7000+ languages on the planet benefit from specialized, custom-built tokenization algorithms, while the other languages are stuck with a""default""whitespace tokenizer, which cannot capture the intricacies of different languages. To address this challenge, we propose a different approach to tokenization for lexical matching retrieval algorithms (e.g., BM25): using the WordPiece tokenizer, which can be built automatically from unsupervised data. We test the approach on 11 typologically diverse languages in the MrTyDi collection: results show that the mBERT tokenizer provides strong relevance signals for retrieval""out of the box"", outperforming whitespace tokenization on most languages. In many cases, our approach also improves retrieval effectiveness when combined with existing custom-built tokenizers.",arXiv.org,2022.0,17,1,"[{'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5c32c653735b43a0a8923ca65ac191bd4bf15311,https://www.semanticscholar.org/paper/5c32c653735b43a0a8923ca65ac191bd4bf15311,Precise Zero-Shot Dense Retrieval without Relevance Labels,"While dense retrieval has been shown to be effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance labels are available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings (HyDE). Given a query, HyDE first zero-shot prompts an instruction-following language model (e.g., InstructGPT) to generate a hypothetical document. The document captures relevance patterns but is ‚Äúfake‚Äù and may contain hallucinations. Then, an unsupervised contrastively learned encoder (e.g., Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, from which similar real documents are retrieved based on vector similarity. This second step grounds the generated document to the actual corpus, with the encoder‚Äôs dense bottleneck filtering out the hallucinations. Our experiments show that HyDE significantly outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to fine-tuned retrievers across various tasks (e.g. web search, QA, fact verification) and in non-English languages (e.g., sw, ko, ja, bn).",Annual Meeting of the Association for Computational Linguistics,2022.0,61,89,"[{'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]"
67b583682c35cfb6fed37ca65f6458aa55285bce,https://www.semanticscholar.org/paper/67b583682c35cfb6fed37ca65f6458aa55285bce,Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval,"Pre-trained language models have been successful in many knowledge-intensive NLP tasks. However, recent work has shown that models such as BERT are not ‚Äústructurally ready‚Äù to aggregate textual information into a [CLS] vector for dense passage retrieval (DPR). This ‚Äúlack of readiness‚Äù results from the gap between language model pre-training and DPR fine-tuning. Previous solutions call for computationally expensive techniques such as hard negative mining, cross-encoder distillation, and further pre-training to learn a robust DPR model. In this work, we instead propose to fully exploit knowledge in a pre-trained language model for DPR by aggregating the contextualized token embeddings into a dense vector, which we call agg‚òÖ. By concatenating vectors from the [CLS] token and agg‚òÖ, our Aggretriever model substantially improves the effectiveness of dense retrieval models on both in-domain and zero-shot evaluations without introducing substantial training overhead. Code is available at https://github.com/castorini/dhr.",Transactions of the Association for Computational Linguistics,2022.0,52,10,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6e386d1720d9a81386960fcb4daec979ce0731ca,https://www.semanticscholar.org/paper/6e386d1720d9a81386960fcb4daec979ce0731ca,A Dense Representation Framework for Lexical and Semantic Matching,"Lexical and semantic matching capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust than either alone. Prior work performs hybrid retrieval by conducting lexical and semantic matching using different systems (e.g., Lucene and Faiss, respectively) and then fusing their model outputs. In contrast, our work integrates lexical representations with dense semantic representations by densifying high-dimensional lexical representations into what we call low-dimensional dense lexical representations (DLRs). Our experiments show that DLRs can effectively approximate the original lexical representations, preserving effectiveness while improving query latency. Furthermore, we can combine dense lexical and semantic representations to generate dense hybrid representations (DHRs) that are more flexible and yield faster retrieval compared to existing hybrid techniques. In addition, we explore jointly training lexical and semantic representations in a single model and empirically show that the resulting DHRs are able to combine the advantages of the individual components. Our best DHR model is competitive with state-of-the-art single-vector and multi-vector dense retrievers in both in-domain and zero-shot evaluation settings. Furthermore, our model is both faster and requires smaller indexes, making our dense representation framework an attractive approach to text retrieval. Our code is available at https://github.com/castorini/dhr.",ACM Trans. Inf. Syst.,2022.0,62,12,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
741a5536c2e58e1595e7396345f1e5d40a3aa775,https://www.semanticscholar.org/paper/741a5536c2e58e1595e7396345f1e5d40a3aa775,CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval,"Multi-vector retrieval methods combine the merits of sparse (e.g. BM25) and dense (e.g. DPR) retrievers and have achieved state-of-the-art performance on various retrieval tasks.These methods, however, are orders of magnitude slower and need much more space to store their indices compared to their single-vector counterparts.In this paper, we unify different multi-vector retrieval models from a token routing viewpoint and propose conditional token interaction via dynamic lexical routing, namely CITADEL, for efficient and effective multi-vector retrieval.CITADEL learns to route different token vectors to the predicted lexical keys such that a query token vector only interacts with document token vectors routed to the same key.This design significantly reduces the computation cost while maintaining high accuracy.Notably, CITADEL achieves the same or slightly better performance than the previous state of the art, ColBERT-v2, on both in-domain (MS MARCO) and out-of-domain (BEIR) evaluations, while being nearly 40 times faster. Source code and data are available at https://github.com/facebookresearch/dpr-scale/tree/citadel.",Annual Meeting of the Association for Computational Linguistics,2022.0,66,11,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '9185192', 'name': 'Barlas Oƒüuz'}, {'authorId': '2730123', 'name': 'Asish Ghoshal'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2121361882', 'name': 'Yashar Mehdad'}, {'authorId': '2072801764', 'name': 'Wen-tau Yih'}, {'authorId': '1769736', 'name': 'Xilun Chen'}]"
754fad16ccde2328b302162571650254acd38203,https://www.semanticscholar.org/paper/754fad16ccde2328b302162571650254acd38203,Query Expansion Using Contextual Clue Sampling with Language Models,"Query expansion is an effective approach for mitigating vocabulary mismatch between queries and documents in information retrieval. One recent line of research uses language models to generate query-related contexts for expansion. Along this line, we argue that expansion terms from these contexts should balance two key aspects: diversity and relevance. The obvious way to increase diversity is to sample multiple contexts from the language model. However, this comes at the cost of relevance, because there is a well-known tendency of models to hallucinate incorrect or irrelevant contexts. To balance these two considerations, we propose a combination of an effective filtering strategy and fusion of the retrieved documents based on the generation probability of each context. Our lexical matching based approach achieves a similar top-5/top-20 retrieval accuracy and higher top-100 accuracy compared with the well-established dense retrieval model DPR, while reducing the index size by more than 96%. For end-to-end QA, the reader model also benefits from our method and achieves the highest Exact-Match score against several competitive baselines.",arXiv.org,2022.0,31,6,"[{'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '48662861', 'name': 'Sebastian Riedel'}, {'authorId': '1918552', 'name': 'Pontus Stenetorp'}]"
83d373dc961122d207de17bf78b359c04fa489bd,https://www.semanticscholar.org/paper/83d373dc961122d207de17bf78b359c04fa489bd,A N E XPLORATION OF V OCABULARY S IZE AND T RANSFER E FFECTS IN M ULTILINGUAL L ANGUAGE M ODELS FOR A FRICAN L ANGUAGES,"Multilingual pretrained language models have been shown to work well on many languages, even those they were not originally pretrained on. Despite their empirical success in downstream tasks, there is still a gap in understanding of ‚Äúwhat makes them tick‚Äù. In this paper, we try to understand the effects of sharing a vocabulary space on the cross-lingual abilities of a multilingual model. We train multiple monolingual and multilingual models and compare their effectiveness on downstream tasks. In monolingual models, a single language occupies the entire vocabulary space, limiting possible cross-lingual transfer. Whereas in a multi-lingual setting, the model benefits from cross-lingual transfer with the tradeoff of having to split the vocabulary space between multiple languages. We present a comprehensive study of the effects of a shared vocabulary space, cross-script pretraining, and high-resource transfer on the cross-lingual abilities of multilingual models in zero-and few-shot settings. From our study, we observe that scaling the number of languages is beneficial for cross-lingual transfer in low-resource multilingual models up until a point, after which transfer effects saturate. We find that there is not much benefit from pretraining low-resource multilingual models with a high-resource language, and that cross-lingual transfer is possible even when the languages are written with different scripts. This empirical study was conducted in the context of three linguistically different low-resource African languages‚ÄîAmharic, Hausa, and Swahili‚Äîand evaluation was performed on two different tasks, text classification and named entity recognition. During the course of our",,2022.0,23,0,"[{'authorId': '2175480812', 'name': 'Akintunde Oladipo'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '1452683268', 'name': 'Kelechi Ogueji'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8551341fb2ac371ab7de7bc8b32014176a323a1e,https://www.semanticscholar.org/paper/8551341fb2ac371ab7de7bc8b32014176a323a1e,Efficient Document-at-a-time and Score-at-a-time Query Evaluation for Learned Sparse Representations,"Researchers have had much recent success with ranking models based on so-called learned sparse representations generated by transformers. One crucial advantage of this approach is that such models can exploit inverted indexes for top-k retrieval, thereby leveraging decades of work on efficient query evaluation. Yet, there remain many open questions about how these learned representations fit within the existing literature, which our work aims to tackle using four representative learned sparse models. We find that impact weights generated by transformers appear to greatly reduce opportunities for skipping and early exiting optimizations in well-studied document-at-a-time (DaaT) approaches. Similarly, ‚Äúoff-the-shelf‚Äù application of score-at-a-time (SaaT) processing exhibits a mismatch between these weights and assumptions behind accumulator management strategies. Building on these observations, we present solutions to address deficiencies with both DaaT and SaaT approaches, yielding substantial speedups in query evaluation. Our detailed empirical analysis demonstrates that both methods lie on the effectiveness‚Äìefficiency Pareto frontier, indicating that the optimal choice for deployment depends on operational constraints.",ACM Trans. Inf. Syst.,2022.0,86,10,"[{'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
859cbed6555319c3c31b84c1001a1df9a34889e2,https://www.semanticscholar.org/paper/859cbed6555319c3c31b84c1001a1df9a34889e2,Evaluating Token-Level and Passage-Level Dense Retrieval Models for Math Information Retrieval,"With the recent success of dense retrieval methods based on bi-encoders, studies have applied this approach to various interesting downstream retrieval tasks with good efficiency and in-domain effectiveness. Recently, we have also seen the presence of dense retrieval models in Math Information Retrieval (MIR) tasks, but the most effective systems remain classic retrieval methods that consider hand-crafted structure features. In this work, we try to combine the best of both worlds:\ a well-defined structure search method for effective formula search and efficient bi-encoder dense retrieval models to capture contextual similarities. Specifically, we have evaluated two representative bi-encoder models for token-level and passage-level dense retrieval on recent MIR tasks. Our results show that bi-encoder models are highly complementary to existing structure search methods, and we are able to advance the state-of-the-art on MIR datasets.",Conference on Empirical Methods in Natural Language Processing,2022.0,49,14,"[{'authorId': '2100393067', 'name': 'Wei Zhong'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
89beaeacb16e0ee4bbd8fe38a6c3b86de0d3373a,https://www.semanticscholar.org/paper/89beaeacb16e0ee4bbd8fe38a6c3b86de0d3373a,"SpeechNet: Weakly Supervised, End-to-End Speech Recognition at Industrial Scale","End-to-end automatic speech recognition systems represent the state of the art, but they rely on thousands of hours of manually annotated speech for training, as well as heavyweight computation for inference. Of course, this impedes commercialization since most companies lack vast human and computational resources. In this paper, we explore training and deploying an ASR system in the label-scarce, compute-limited setting. To reduce human labor, we use a third-party ASR system as a weak supervision source, supplemented with labeling functions derived from implicit user feedback. To accelerate inference, we propose to route production-time queries across a pool of CUDA graphs of varying input lengths, the distribution of which best matches the traffic's. Compared to our third-party ASR, we achieve a relative improvement in word-error rate of 8% and a speedup of 600%. Our system, called SpeechNet, currently serves 12 million queries per day on our voice-enabled smart television. To our knowledge, this is the first time a large-scale, Wav2vec-based deployment has been described in the academic literature.",Conference on Empirical Methods in Natural Language Processing,2022.0,32,3,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '153359454', 'name': 'K. Kumar'}, {'authorId': '47125226', 'name': 'Gefei Yang'}, {'authorId': '2070539062', 'name': 'Akshat Pandey'}, {'authorId': '49600216', 'name': 'Yajie Mao'}, {'authorId': '2069423772', 'name': 'Vladislav Belyaev'}, {'authorId': '2191604278', 'name': 'Madhuri Emmadi'}, {'authorId': '2161396007', 'name': 'Craig Murray'}, {'authorId': '52416773', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8ac975f8ece08246554f1ce9585fb13616a51097,https://www.semanticscholar.org/paper/8ac975f8ece08246554f1ce9585fb13616a51097,On the Interaction Between Differential Privacy and Gradient Compression in Deep Learning,"While differential privacy and gradient compression are separately well-researched topics in machine learning, the study of interaction between these two topics is still relatively new. We perform a detailed empirical study on how the Gaussian mechanism for differential privacy and gradient compression jointly impact test accuracy in deep learning. The existing literature in gradient compression mostly evaluates compression in the absence of differential privacy guarantees, and demonstrate that sufficiently high compression rates reduce accuracy. Similarly, existing literature in differential privacy evaluates privacy mechanisms in the absence of compression, and demonstrates that sufficiently strong privacy guarantees reduce accuracy. In this work, we observe while gradient compression generally has a negative impact on test accuracy in non-private training, it can sometimes improve test accuracy in differentially private training. Specifically, we observe that when employing aggressive sparsification or rank reduction to the gradients, test accuracy is less affected by the Gaussian noise added for differential privacy. These observations are explained through an analysis how differential privacy and compression effects the bias and variance in estimating the average gradient. We follow this study with a recommendation on how to improve test accuracy under the context of differentially private deep learning and gradient compression. We evaluate this proposal and find that it can reduce the negative impact of noise added by differential privacy mechanisms on test accuracy by up to 24.6%, and reduce the negative impact of gradient sparsification on test accuracy by up to 15.1%.",arXiv.org,2022.0,26,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8d715cbbec0a66f685e58b6148ad6a5be0d8ead2,https://www.semanticscholar.org/paper/8d715cbbec0a66f685e58b6148ad6a5be0d8ead2,"To Interpolate or not to Interpolate: PRF, Dense and Sparse Retrievers","Current pre-trained language model approaches to information retrieval can be broadly divided into two categories: sparse retrievers (to which belong also non-neural approaches such as bag-of-words methods, e.g., BM25) and dense retrievers. Each of these categories appears to capture different characteristics of relevance. Previous work has investigated how relevance signals from sparse retrievers could be combined with those from dense retrievers via interpolation. Such interpolation would generally lead to higher retrieval effectiveness. In this paper we consider the problem of combining the relevance signals from sparse and dense retrievers in the context of Pseudo Relevance Feedback (PRF). This context poses two key challenges: (1) When should interpolation occur: before, after, or both before and after the PRF process? (2) Which sparse representation should be considered: a zero-shot bag-of-words model (BM25), or a learned sparse representation? To answer these questions we perform a thorough empirical evaluation considering an effective and scalable neural PRF approach (Vector-PRF), three effective dense retrievers (ANCE, TCTv2, DistillBERT), and one state-of-the-art learned sparse retriever (uniCOIL). The empirical findings from our experiments suggest that, regardless of sparse representation and dense retriever, interpolation both before and after PRF achieves the highest effectiveness across most datasets and metrics.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,33,18,"[{'authorId': '2118384241', 'name': 'Hang Li'}, {'authorId': '2146514461', 'name': 'Shuai Wang'}, {'authorId': '1630489015', 'name': 'Shengyao Zhuang'}, {'authorId': '143832672', 'name': 'Ahmed Mourad'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]"
943487997ecd26e871a2ab16160bd5640020369d,https://www.semanticscholar.org/paper/943487997ecd26e871a2ab16160bd5640020369d,Toward Best Practices for Training Multilingual Dense Retrieval Models,"Dense retrieval models using a transformer-based bi-encoder architecture have emerged as an active area of research. In this article, we focus on the task of monolingual retrieval in a variety of typologically diverse languages using such an architecture. Although recent work with multilingual transformers demonstrates that they exhibit strong cross-lingual generalization capabilities, there remain many open research questions, which we tackle here. Our study is organized as a ‚Äúbest practices‚Äù guide for training multilingual dense retrieval models, broken down into three main scenarios: when a multilingual transformer is available, but training data in the form of relevance judgments are not available in the language and domain of interest (‚Äúhave model, no data‚Äù); when both models and training data are available (‚Äúhave model and data‚Äù); and when training data are available but not models (‚Äúhave data, no model‚Äù). In considering these scenarios, we gain a better understanding of the role of multi-stage fine-tuning, the strength of cross-lingual transfer under various conditions, the usefulness of out-of-language data, and the advantages of multilingual vs. monolingual transformers. Our recommendations offer a guide for practitioners building search applications, particularly for low-resource languages, and while our work leaves open a number of research questions, we provide a solid foundation for future work.",ACM Trans. Inf. Syst.,2022.0,73,19,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '1452683268', 'name': 'Kelechi Ogueji'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
979fd6c0eb8571c170c46903ec2c62a4f7b35bc6,https://www.semanticscholar.org/paper/979fd6c0eb8571c170c46903ec2c62a4f7b35bc6,Too Many Relevants: Whither Cranfield Test Collections?,"This paper presents the lessons regarding the construction and use of large Cranfield-style test collections learned from the TREC 2021 Deep Learning track. The corpus used in the 2021 edition of the track was much bigger than the corpus used previously and it contains many more relevant documents. The process used to select documents to judge that had been used in earlier years of the track failed to produce a reliable collection because most topics have too many relevant documents. Judgment budgets were exceeded before an adequate sample of the relevant set could be found, so there are likely many unknown relevant documents in the unjudged portion of the corpus. As a result, the collection is not reusable, and furthermore, recall-based measures are unreliable even for the retrieval systems that were used to build the collection. Yet, early-precision measures cannot distinguish among system results because the maximum score is easily obtained for many topics. And since the existing tools for appraising the quality of test collections depend on systems' scores, they also fail when there are too many relevant documents. Collection builders will need new strategies and tools for building reliable test collections for continued use of the Cranfield paradigm on ever-larger corpora. Ensuring that the definition of 'relevant' truly reflects the desired systems' rankings is a provisional strategy for continued collection building.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,22,13,"[{'authorId': '1746656', 'name': 'E. Voorhees'}, {'authorId': '2286321410', 'name': 'Nick Craswell'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9d06ef8ecab568b371727df9a47dff3b2e26fc61,https://www.semanticscholar.org/paper/9d06ef8ecab568b371727df9a47dff3b2e26fc61,Improving Precancerous Case Characterization via Transformer-based Ensemble Learning,"The application of natural language processing (NLP) to cancer pathology reports has been focused on detecting cancer cases, largely ignoring precancerous cases. Improving the characterization of precancerous adenomas assists in developing diagnostic tests for early cancer detection and prevention, especially for colorectal cancer (CRC). Here we developed transformer-based deep neural network NLP models to perform the CRC phenotyping, with the goal of extracting precancerous lesion attributes and distinguishing cancer and precancerous cases. We achieved 0.914 macro-F1 scores for classifying patients into negative, non-advanced adenoma, advanced adenoma and CRC. We further improved the performance to 0.923 using an ensemble of classifiers for cancer status classification and lesion size named entity recognition (NER). Our results demonstrated the potential of using NLP to leverage real-world health record data to facilitate the development of diagnostic tests for early cancer prevention.",Conference on Empirical Methods in Natural Language Processing,2022.0,37,0,"[{'authorId': '32718063', 'name': 'Yizhen Zhong'}, {'authorId': '8166413', 'name': 'Jiajie Xiao'}, {'authorId': '50712921', 'name': 'Thomas Vetterli'}, {'authorId': '6478298', 'name': 'M. Matin'}, {'authorId': '2049418137', 'name': 'E. Loo'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2593005', 'name': 'R. Bourgon'}, {'authorId': '49962519', 'name': 'Ofer Shapira'}]"
a19438a28ba9eb5eeefa9324840758b1b5fe3c65,https://www.semanticscholar.org/paper/a19438a28ba9eb5eeefa9324840758b1b5fe3c65,Another Look at Information Retrieval as Statistical Translation,"Over two decades ago, Berger and Lafferty proposed ""information retrieval as statistical translation"" (IRST), a simple and elegant method for ad hoc retrieval based on the noisy channel model. At the time, they lacked the large-scale human-annotated datasets necessary to properly train their models. In this paper, we ask the simple question: What if Berger and Lafferty had access to datasets such as the MS MARCO passage ranking dataset that we take for granted today? The answer to this question tells us how much of recent improvements in ranking can be solely attributed to having more data available, as opposed to improvements in models (e.g., pretrained transformers) and optimization techniques (e.g., contrastive loss). In fact, Boytsov and Kolter recently began to answer this question with a replication of Berger and Lafferty's model, and this work can be viewed as another independent replication effort, with generalizations to additional conditions not previously explored, including replacing the sum of translation probabilities with ColBERT's MaxSim operator. We confirm that while neural models (particularly pretrained transformers) have indeed led to great advances in retrieval effectiveness, the IRST model proposed decades ago is quite effective if provided sufficient training data.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,28,1,"[{'authorId': '2144468595', 'name': 'Yuqi Liu'}, {'authorId': '2118956992', 'name': 'Chengcheng Hu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a89e809576880a93775e7b973d6758fc2c74a44e,https://www.semanticscholar.org/paper/a89e809576880a93775e7b973d6758fc2c74a44e,Simple Yet Effective Neural Ranking and Reranking Baselines for Cross-Lingual Information Retrieval,"The advent of multilingual language models has generated a resur-genceofinterestincross-lingualinformationretrieval(CLIR),which isthetaskofsearchingdocumentsinonelanguagewithqueries fromanother.However,therapidpaceofprogresshasledtoacon-fusingpanoplyofmethodsandreproducibilityhaslaggedbehind thestateoftheart.Inthiscontext,ourworkmakestwoimpor-tantcontributions:First,weprovideaconceptualframeworkfor organizingdifferentapproachestocross-lingualretrievalusing multi-stagearchitecturesformono-lingualretrievalasascaffold. Second,weimplementsimpleyeteffectivereproduciblebaselines intheAnseriniandPyseriniIRtoolkitsfortestcollectionsfromthe TREC2022NeuCLIRTrack,inPersian,Russian,andChinese.Our effortsarebuiltonacollaborationofthetwoteamsthatsubmitted themosteffectiverunstotheTRECevaluation.Thesecontributions provideafirmfoundationforfutureadvances.",Text Retrieval Conference,2022.0,52,3,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2274328833', 'name': 'Vitor Jeronymo'}, {'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '2131640257', 'name': 'Carlos Lassance'}, {'authorId': '2274330487', 'name': 'Rodrigo Frassetto Nogueira'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}]"
c27f3904490b8e5f9f39fe2b36722090c189e916,https://www.semanticscholar.org/paper/c27f3904490b8e5f9f39fe2b36722090c189e916,"Applying Structural and Dense Semantic Matching for the ARQMath Lab 2022, CLEF","This work describes the participation of our team in the ARQMath 2022 Lab, where we have applied two highly complementary methods for effective math answer and formula retrieval. More specifically, a lexical sparse retriever (Approach Zero) capable of first-stage structure matching is combined with a fine-tuned bi-encoder dense retriever (ColBERT) to capture contextual similarity and semantic matching. The dense retrieval model is further pretrained to adapt to math domain content containing L A TEX tokens. In the Open Domain QA task, we take an extractive approach and filter sentences using heuristic rules applied to top-ranked answers returned from our retrievers. We provide an analysis of both the effectiveness and efficiency of our models. In this contest, our effectiveness is ranked at the top among all three tasks.",Conference and Labs of the Evaluation Forum,2022.0,68,6,"[{'authorId': '2100393067', 'name': 'Wei Zhong'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c36e493820c2b5981d43282d33b8b020d65d61e1,https://www.semanticscholar.org/paper/c36e493820c2b5981d43282d33b8b020d65d61e1,Aligning the Research and Practice of Building Search Applications: Elasticsearch and Pyserini,"We demonstrate, via competitive bag-of-words first-stage retrieval baselines for the MS MARCO document ranking task, seamless replicability and interoperability between Elasticsearch and the Pyserini IR toolkit, which are both built on the open-source Lucene search library. This integration highlights the benefits of recent efforts to promote the use of Lucene in information retrieval research to better align the research and practice of building search applications. Closer alignment between academia and industry is mutually beneficial: Academic researchers gain a smoother path to real-world impact because their contributions can be more easily deployed in production applications. Industry practitioners gain an easy way to benchmark their innovations in a rigorous and vendor-neutral manner by exploiting evaluation resources and infrastructure built by the academic community. This two-way exchange between academia and industry allows both parties to ""have their cakes and eat them too"".",Web Search and Data Mining,2022.0,18,8,"[{'authorId': '2152789112', 'name': 'Josh Devins'}, {'authorId': '2099589', 'name': 'J. Tibshirani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
cf387294994faf86b3c8332ba72fc17b1442651c,https://www.semanticscholar.org/paper/cf387294994faf86b3c8332ba72fc17b1442651c,AfriCLIRMatrix: Enabling Cross-Lingual Information Retrieval for African Languages,"Language diversity in NLP is critical in enabling the development of tools for a wide range of users.However, there are limited resources for building such tools for many languages, particularly those spoken in Africa.For search, most existing datasets feature few or no African languages, directly impacting researchers‚Äô ability to build and improve information access capabilities in those languages.Motivated by this, we created AfriCLIRMatrix, a test collection for cross-lingual information retrieval research in 15 diverse African languages.In total, our dataset contains 6 million queries in English and 23 million relevance judgments automatically mined from Wikipedia inter-language links, covering many more African languages than any existing information retrieval test collection.In addition, we release BM25, dense retrieval, and sparse‚Äìdense hybrid baselines to provide a starting point for the development of future systems.We hope that these efforts can spur additional work in search for African languages.AfriCLIRMatrix can be downloaded at https://github.com/castorini/africlirmatrix.",Conference on Empirical Methods in Natural Language Processing,2022.0,39,3,"[{'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2152990621', 'name': 'Shuo Sun'}, {'authorId': '1800354', 'name': 'Kevin Duh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d0629d89120409b6bb2c7cc3b309b15839ff73cb,https://www.semanticscholar.org/paper/d0629d89120409b6bb2c7cc3b309b15839ff73cb,Squeezing Water from a Stone: A Bag of Tricks for Further Improving Cross-Encoder Effectiveness for Reranking,,European Conference on Information Retrieval,2022.0,59,18,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2144468595', 'name': 'Yuqi Liu'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2162396776', 'name': 'Yilin Li'}, {'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d18bf4a546db824f6ed1efcd48b81aa4433b5fec,https://www.semanticscholar.org/paper/d18bf4a546db824f6ed1efcd48b81aa4433b5fec,REBL: Entity Linking at Scale,"REBL is an extension of the Radboud Entity Linker (REL) for Batch Entity Linking. REBL is developed after encountering unforeseen issues when trying to link the large MS MARCO v2 web document collection with REL. In this paper we discuss the issues we ran into and our solutions to mitigate them. REBL makes it easier to isolate the GPU heavy operations from the CPU heavy operations, by separating the mention detection stage from the candidate selection and entity disambiguation stages. By improving the entity disambiguation module we were able to lower the time needed for linking documents by an order of magnitude. The code for REBL is publicly available on GitHub. modest This paper describes our experience with optimizing the Radboud Entity Linking (REL) toolkit for batch processing large corpora. REL annotates individual documents efficiently, requiring only modest computational resources, while performing competitively when compared to the state-of-the-art methods on effectiveness. It considers entity linking as a modular problem consisting of three stages:",,2022.0,19,2,"[{'authorId': '1591687213', 'name': 'Chris Kamphuis'}, {'authorId': '1951737', 'name': 'Faegheh Hasibi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
d2d913ce77dc2bf4b4bb954e3ce531dcc47b8fc3,https://www.semanticscholar.org/paper/d2d913ce77dc2bf4b4bb954e3ce531dcc47b8fc3,Tevatron: An Efficient and Flexible Toolkit for Dense Retrieval,"Recent rapid advancements in deep pre-trained language models and the introductions of large datasets have powered research in embedding-based dense retrieval. While several good research papers have emerged, many of them come with their own software stacks. These stacks are typically optimized for some particular research goals instead of efficiency or code structure. In this paper, we present Tevatron, a dense retrieval toolkit optimized for efficiency, flexibility, and code simplicity. Tevatron provides a standardized pipeline for dense retrieval including text processing, model training, corpus/query encoding, and search. This paper presents an overview of Tevatron and demonstrates its effectiveness and efficiency across several IR and QA data sets. We also show how Tevatron's flexible design enables easy generalization across datasets, model architectures, and accelerator platforms(GPU/TPU). We believe Tevatron can serve as an effective software foundation for dense retrieval system research including design, modeling, and optimization.",arXiv.org,2022.0,27,54,"[{'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]"
d6885ea92c9c720b58f5ed278f5aea42dfdf9918,https://www.semanticscholar.org/paper/d6885ea92c9c720b58f5ed278f5aea42dfdf9918,Few-Shot Non-Parametric Learning with Deep Latent Variable Model,"Most real-world problems that machine learning algorithms are expected to solve face the situation with 1) unknown data distribution; 2) little domain-specific knowledge; and 3) datasets with limited annotation. We propose Non-Parametric learning by Compression with Latent Variables (NPC-LV), a learning framework for any dataset with abundant unlabeled data but very few labeled ones. By only training a generative model in an unsupervised way, the framework utilizes the data distribution to build a compressor. Using a compressor-based distance metric derived from Kolmogorov complexity, together with few labeled data, NPC-LV classifies without further training. We show that NPC-LV outperforms supervised methods on all three datasets on image classification in low data regime and even outperform semi-supervised learning methods on CIFAR-10. We demonstrate how and when negative evidence lowerbound (nELBO) can be used as an approximate compressed length for classification. By revealing the correlation between compression rate and classification accuracy, we illustrate that under NPC-LV, the improvement of generative models can enhance downstream classification accuracy.",Neural Information Processing Systems,2022.0,91,3,"[{'authorId': '2197574931', 'name': 'Zhiying Jiang'}, {'authorId': '3154581', 'name': 'Yi-Zhu Dai'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '7755014', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d821afef2e506c0bbbeb88b4622f2a5a5bb8358b,https://www.semanticscholar.org/paper/d821afef2e506c0bbbeb88b4622f2a5a5bb8358b,Making a MIRACL: Multilingual Information Retrieval Across a Continuum of Languages,"MIRACL (Multilingual Information Retrieval Across a Continuum of Languages) is a multilingual dataset we have built for the WSDM 2023 Cup challenge that focuses on ad hoc retrieval across 18 different languages, which collectively encompass over three billion native speakers around the world. These languages have diverse typologies, originate from many different language families, and are associated with varying amounts of available resources -- including what researchers typically characterize as high-resource as well as low-resource languages. Our dataset is designed to support the creation and evaluation of models for monolingual retrieval, where the queries and the corpora are in the same language. In total, we have gathered over 700k high-quality relevance judgments for around 77k queries over Wikipedia in these 18 languages, where all assessments have been performed by native speakers hired by our team. Our goal is to spur research that will improve retrieval across a continuum of languages, thus enhancing information access capabilities for diverse populations around the world, particularly those that have been traditionally underserved. This overview paper describes the dataset and baselines that we share with the community. The MIRACL website is live at http://miracl.ai/.",arXiv.org,2022.0,29,29,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2166106776', 'name': 'Odunayo Ogundepo'}, {'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '1419474794', 'name': 'David Alfonso-Hermelo'}, {'authorId': '2108181908', 'name': 'Xiaoguang Li'}, {'authorId': '1688015', 'name': 'Qun Liu'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e1ca2570b1916398377a7bbd3d3731a389b0bdc2,https://www.semanticscholar.org/paper/e1ca2570b1916398377a7bbd3d3731a389b0bdc2,Can Old TREC Collections Reliably Evaluate Modern Neural Retrieval Models?,"Neural retrieval models are generally regarded as fundamentally different from the retrieval techniques used in the late 1990's when the TREC ad hoc test collections were constructed. They thus provide the opportunity to empirically test the claim that pooling-built test collections can reliably evaluate retrieval systems that did not contribute to the construction of the collection (in other words, that such collections can be reusable). To test the reusability claim, we asked TREC assessors to judge new pools created from new search results for the TREC-8 ad hoc collection. These new search results consisted of five new runs (one each from three transformer-based models and two baseline runs that use BM25) plus the set of TREC-8 submissions that did not previously contribute to pools. The new runs did retrieve previously unseen documents, but the vast majority of those documents were not relevant. The ranking of all runs by mean evaluation score when evaluated using the official TREC-8 relevance judgment set and the newly expanded relevance set are almost identical, with Kendall's tau correlations greater than 0.99. Correlations for individual topics are also high. The TREC-8 ad hoc collection was originally constructed using deep pools over a diverse set of runs, including several effective manual runs. Its judgment budget, and hence construction cost, was relatively large. However, it does appear that the expense was well-spent: even with the advent of neural techniques, the collection has stood the test of time and remains a reliable evaluation instrument as retrieval techniques have advanced.",arXiv.org,2022.0,27,15,"[{'authorId': '1746656', 'name': 'E. Voorhees'}, {'authorId': '144526707', 'name': 'I. Soboroff'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e46cd6f065e57adf1321c42890db1a2209e17f7b,https://www.semanticscholar.org/paper/e46cd6f065e57adf1321c42890db1a2209e17f7b,VoxelCache: Accelerating Online Mapping in Robotics and 3D Reconstruction Tasks,"Real-time 3D mapping is a critical component in many important applications today including robotics, AR/VR, and 3D visualization. 3D mapping involves continuously fusing depth maps obtained from depth sensors in phones, robots, and autonomous vehicles into a single 3D representative model of the scene. Many important applications, e.g., global path planning and trajectory generation in micro aerial vehicles, require the construction of large maps at high resolutions. In this work, we identify mapping, i.e., construction and updates of 3D maps to be a critical bottleneck in these applications. The memory required and access times of these maps limit the size of the environment and the resolution with which the environment can be feasibly mapped, especially in resource constrained environments such as autonomous robot platforms and portable devices. To address this challenge, we propose VoxelCache: a hardware-software technique to accelerate map data access times in 3D mapping applications. We observe that mapping applications typically access voxels in the map that are spatially co-located to each other. We leverage this temporal locality in voxel accesses to cache indices to blocks of voxels to enable quick lookup and avoid expensive access times. We evaluate VoxelCache on popularly used mapping and reconstruction applications on both GPUs and CPUs. We demonstrate an average speedup of 1.47X (up to 1.66X) and 1.79X (up to 1.91X) on CPUs and GPUs respectively.",International Conference on Parallel Architectures and Compilation Techniques,2022.0,39,1,"[{'authorId': '2187933748', 'name': 'Sankeerth Durvasula'}, {'authorId': '2187934388', 'name': 'Raymond Kiguru'}, {'authorId': '153090671', 'name': 'Samarth Mathur'}, {'authorId': '49394536', 'name': 'Jenny Xu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1920997', 'name': 'Nandita Vijaykumar'}]"
eac257efef9ed0230b0036f9c5f478de94333fb6,https://www.semanticscholar.org/paper/eac257efef9ed0230b0036f9c5f478de94333fb6,Document Expansions and Learned Sparse Lexical Representations for MS MARCO V1 and V2,"With doc2query, we train a neural sequence-to-sequence model that, given an input span of text, predicts a natural language query that the text might answer. These predictions can be viewed as document expansions that feed standard bag-of-words term weighting models such as BM25 or neural retrieval models based on learned sparse lexical representations such as uniCOIL. Previous experiments on the MS MARCO datasets have demonstrated the effectiveness of these methods, and they serve as baselines that are widely used by the community today. Following the recent release of the MS MARCO V2 passage and document ranking test collections, we have refreshed our doc2query and uniCOIL models. This work describes a number of resources that support competitive, reproducible base-lines for both the MS MARCO V1 and V2 test collections using our Anserini and Pyserini IR toolkits. Together, they provide a solid foundation for future research on neural retrieval models using the MS MARCO datasets and beyond.",,2022.0,32,8,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
f0746fd7e2d1c303a46929bdd0bd74b82ede4f2a,https://www.semanticscholar.org/paper/f0746fd7e2d1c303a46929bdd0bd74b82ede4f2a,Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval,"Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B dense retriever while maintaining efficiency at inference. Our results demonstrate that, unlike prior work, LTH strategies when applied naively can underperform the zero-shot TAS-B dense retriever on average by up to 14% nDCG@10 on the BEIR benchmark. To solve this limitation, in our work, we propose an easy yet effective solution of injecting domain adaptation with existing supervised LTH techniques. We experiment with two well-known unsupervised domain adaptation techniques: GenQ and GPL. Our domain adaptation injection technique can improve the downstream zero-shot retrieval effectiveness for both BPR and JPQ variants of the TAS-B model by on average 11.5% and 8.2% nDCG@10 while both maintaining 32$\times$ memory efficiency and 14$\times$ and 2$\times$ speedup respectively in CPU retrieval latency on BEIR. All our code, models, and data are publicly available at https://github.com/thakur-nandan/income.",,2022.0,37,2,"[{'authorId': '47583894', 'name': 'Nandan Thakur'}, {'authorId': '2959414', 'name': 'Nils Reimers'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f162b74b73e53e5980e9b3346be370934753acf1,https://www.semanticscholar.org/paper/f162b74b73e53e5980e9b3346be370934753acf1,A Common Framework for Exploring Document-at-a-Time and Score-at-a-Time Retrieval Methods,"Document-at-a-time (DaaT) and score-at-a-time (SaaT) query evaluation techniques are different approaches to top-k retrieval with inverted indexes. While modern systems are dominated by DaaT, the academic literature has seen decades of debate about the merits of each. Recently, there has been renewed interest in SaaT methods for learned sparse lexical models, where studies have shown that transformers generate ""wacky weights"" that appear to reduce opportunities for optimizations in DaaT methods. However, researchers currently lack an easy-to-use SaaT system to support further exploration. This is the gap that our work fills. Starting with a modern SaaT system (JASS), we built Python bindings in order to integrate into the DaaT Pyserini IR toolkit (Lucene). The result is a common frontend to both a DaaT and a SaaT system. We demonstrate how recent experiments with a wide range of learned sparse lexical models can be easily reproduced. Our contribution is a framework that enables future research comparing DaaT and SaaT methods in the context of modern neural retrieval models.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,40,1,"[{'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '1477624286', 'name': 'P. Parameswaran'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f9986ca86ef1a617252630c72b3084b039976e5f,https://www.semanticscholar.org/paper/f9986ca86ef1a617252630c72b3084b039976e5f,Building an Efficiency Pipeline: Commutativity and Cumulativeness of Efficiency Operators for Transformers,"There exists a wide variety of efficiency methods for natural language processing (NLP) tasks, such as pruning, distillation, dynamic inference, quantization, etc. We can consider an efficiency method as an operator applied on a model. Naturally, we may construct a pipeline of multiple efficiency methods, i.e., to apply multiple operators on the model sequentially. In this paper, we study the plausibility of this idea, and more importantly, the commutativity and cumulativeness of efficiency operators. We make two interesting observations: (1) Efficiency operators are commutative -- the order of efficiency methods within the pipeline has little impact on the final results; (2) Efficiency operators are also cumulative -- the final results of combining several efficiency methods can be estimated by combining the results of individual methods. These observations deepen our understanding of efficiency operators and provide useful guidelines for their real-world applications.",arXiv.org,2022.0,39,1,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '3109913', 'name': 'Zhiying Jiang'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
007a06e9674f58d496ef36ef54a2fd1363299c08,https://www.semanticscholar.org/paper/007a06e9674f58d496ef36ef54a2fd1363299c08,Chatty Goose: A Python Framework for Conversational Search,"Chatty Goose is an open-source Python conversational search framework that provides strong, reproducible reranking pipelines built on recent advances in neural models. The framework comprises extensible modular components that integrate with popular libraries such as Transformers by HuggingFace and ParlAI by Facebook. Our aim is to lower the barrier of entry for research in conversational search by providing reproducible baselines that researchers can build on top of. We provide an overview of the framework and demonstrate how to instantiate a new system from scratch. Chatty Goose incorporates improvements to components that we introduced in the TREC 2019 Conversational Assistance Track (CAsT), where our submission represented the top-performing system. Using our framework, a comparable run can be reproduced with just a few lines of code.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,24,4,"[{'authorId': '6549913', 'name': 'Edwin Zhang'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
0c1d53fc87ca482037360b3547111158b505b26e,https://www.semanticscholar.org/paper/0c1d53fc87ca482037360b3547111158b505b26e,Exploring Listwise Evidence Reasoning with T5 for Fact Verification,"This work explores a framework for fact verification that leverages pretrained sequence-to-sequence transformer models for sentence selection and label prediction, two key sub-tasks in fact verification. Most notably, improving on previous pointwise aggregation approaches for label prediction, we take advantage of T5 using a listwise approach coupled with data augmentation. With this enhancement, we observe that our label prediction stage is more robust to noise and capable of verifying complex claims by jointly reasoning over multiple pieces of evidence. Experimental results on the FEVER task show that our system attains a FEVER score of 75.87% on the blind test set. This puts our approach atop the competitive FEVER leaderboard at the time of our work, scoring higher than the second place submission by almost two points in label accuracy and over one point in FEVER score.",Annual Meeting of the Association for Computational Linguistics,2021.0,34,35,"[{'authorId': '46822553', 'name': 'Kelvin Jiang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
0effb07e34ed93ec11b1f2371ec80781e0268561,https://www.semanticscholar.org/paper/0effb07e34ed93ec11b1f2371ec80781e0268561,Encoder Adaptation of Dense Passage Retrieval for Open-Domain Question Answering,"One key feature of dense passage retrievers (DPR) is the use of separate question and passage encoder in a bi-encoder design. Previous work on generalization of DPR mainly focus on testing both encoders in tandem on out-of-distribution (OOD) question-answering (QA) tasks, which is also known as domain adaptation. However, it is still unknown how DPR's individual question/passage encoder affects generalization. Specifically, in this paper, we want to know how an in-distribution (IND) question/passage encoder would generalize if paired with an OOD passage/question encoder from another domain. We refer to this challenge as \textit{encoder adaptation}. To answer this question, we inspect different combinations of DPR's question and passage encoder learned from five benchmark QA datasets on both in-domain and out-of-domain questions. We find that the passage encoder has more influence on the lower bound of generalization while the question encoder seems to affect the upper bound in general. For example, applying an OOD passage encoder usually hurts the retrieval accuracy while an OOD question encoder sometimes even improves the accuracy.",arXiv.org,2021.0,37,7,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
122ed3c2e45badc1292422d7e9a5f3a43c402128,https://www.semanticscholar.org/paper/122ed3c2e45badc1292422d7e9a5f3a43c402128,The Art of Abstention: Selective Prediction and Error Regularization for Natural Language Processing,"In selective prediction, a classifier is allowed to abstain from making predictions on low-confidence examples. Though this setting is interesting and important, selective prediction has rarely been examined in natural language processing (NLP) tasks. To fill this void in the literature, we study in this paper selective prediction for NLP, comparing different models and confidence estimators. We further propose a simple error regularization trick that improves confidence estimation without substantially increasing the computation budget. We show that recent pre-trained transformer models simultaneously improve both model accuracy and confidence estimation effectiveness. We also find that our proposed regularization improves confidence estimation and can be applied to other relevant scenarios, such as using classifier cascades for accuracy‚Äìefficiency trade-offs. Source code for this paper can be found at https://github.com/castorini/transformers-selective.",Annual Meeting of the Association for Computational Linguistics,2021.0,50,40,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1973f251069086d850bde83fabfb05ceaf7b8859,https://www.semanticscholar.org/paper/1973f251069086d850bde83fabfb05ceaf7b8859,Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting,"Conversational search plays a vital role in conversational information seeking. As queries in information seeking dialogues are ambiguous for traditional ad hoc information retrieval (IR) systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial. In this article, we tackle conversational passage retrieval, an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad hoc IR system. Specifically, we propose two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, stand-alone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the best submission of Text REtrieval Conference (TREC) Conversational Assistant Track (CAsT) 2019.",ACM Trans. Inf. Syst.,2021.0,74,48,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1b09222cfe10f11c4cb0b18a9727d2baf6b991ac,https://www.semanticscholar.org/paper/1b09222cfe10f11c4cb0b18a9727d2baf6b991ac,Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval,"We present Mr. TyDi, a multi-lingual benchmark dataset for mono-lingual retrieval in eleven typologically diverse languages, designed to evaluate ranking with learned dense representations. The goal of this resource is to spur research in dense retrieval techniques in non-English languages, motivated by recent observations that existing techniques for representation learning perform poorly when applied to out-of-distribution data. As a starting point, we provide zero-shot baselines for this new dataset based on a multi-lingual adaptation of DPR that we call ‚ÄúmDPR‚Äù. Experiments show that although the effectiveness of mDPR is much lower than BM25, dense representations nevertheless appear to provide valuable relevance signals, improving BM25 results in sparse‚Äìdense hybrids. In addition to analyses of our results, we also discuss future challenges and present a research agenda in multi-lingual dense retrieval. Mr. TyDi can be downloaded at https://github.com/castorini/mr.tydi.",MRL,2021.0,24,69,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2055357849', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
27b7fc608e66298a0a92776d986bca61b521efa0,https://www.semanticscholar.org/paper/27b7fc608e66298a0a92776d986bca61b521efa0,How Does BERT Rerank Passages? An Attribution Analysis with Information Bottlenecks,"Fine-tuned pre-trained transformers achieve the state of the art in passage reranking. Unfortunately, how they make their predictions remains vastly unexplained, especially at the end-to-end, input-to-output level. Little known is how tokens, layers, and passages precisely contribute to the final prediction. In this paper, we address this gap by leveraging the recently developed information bottlenecks for attribution (IBA) framework. On BERT-based models for passage reranking, we quantitatively demonstrate the framework‚Äôs veracity in extracting attribution maps, from which we perform detailed, token-wise analysis about how predictions are made. Overall, we find that BERT still cares about exact token matching for reranking; the [CLS] token mainly gathers information for predictions at the last layer; top-ranked passages are robust to token removal; and BERT fine-tuned on MSMARCO has positional bias towards the start of the passage.",BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,2021.0,40,6,"[{'authorId': '2197574931', 'name': 'Zhiying Jiang'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2c74e7258e7c89ca2da1784fb0cb4106a23ac382,https://www.semanticscholar.org/paper/2c74e7258e7c89ca2da1784fb0cb4106a23ac382,In-Batch Negatives for Knowledge Distillation with Tightly-Coupled Teachers for Dense Retrieval,"We present an efficient training approach to text retrieval with dense representations that applies knowledge distillation using the ColBERT late-interaction ranking model. Specifically, we propose to transfer the knowledge from a bi-encoder teacher to a student by distilling knowledge from ColBERT‚Äôs expressive MaxSim operator into a simple dot product. The advantage of the bi-encoder teacher‚Äìstudent setup is that we can efficiently add in-batch negatives during knowledge distillation, enabling richer interactions between teacher and student models. In addition, using ColBERT as the teacher reduces training cost compared to a full cross-encoder. Experiments on the MS MARCO passage and document ranking tasks and data from the TREC 2019 Deep Learning Track demonstrate that our approach helps models learn robust representations for dense retrieval effectively and efficiently.",Workshop on Representation Learning for NLP,2021.0,37,141,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
398c7443dfb39319632d0766f6facb2ee2783e71,https://www.semanticscholar.org/paper/398c7443dfb39319632d0766f6facb2ee2783e71,PYA0: A Python Toolkit for Accessible Math-Aware Search,"Mathematical Information Retrieval (MIR) has been actively studied in recent years and many fruitful results have emerged. Among those, the Approach Zero system is one of the few math-aware search engines that is able to perform substructure matching efficiently. Furthermore, it has been deployed in ARQMath2020, the most recent community-wide MIR evaluation, as a strong baseline due to its empirical effectiveness and ability to handle structured math content. However, in order to implement a retrieval model that handles structured queries efficiently, Approach Zero is written in C from the ground up, requiring special pipelines for processing math content and queries. Thus, the system is not conveniently accessible and reusable to the community as a research tool. In this paper, we present PyA0, an easy-to-use Python toolkit built on Approach Zero that improves its accessibility to researchers. We introduce the toolkit interface and report evaluation results on popular MIR datasets to demonstrate the effectiveness and efficiency of our toolkit. We have made PyA0 source code publicly accessible at https://github.com/approach0/pya0, which includes a link to a notebook demo.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,14,6,"[{'authorId': '2100393067', 'name': 'Wei Zhong'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
45f2e6f7cccb446f0e9bd94bfed41c3edcb2dc43,https://www.semanticscholar.org/paper/45f2e6f7cccb446f0e9bd94bfed41c3edcb2dc43,Serverless BM25 Search and BERT Reranking,"The retrieve‚Äìrerank pipeline is a well-established architecture for search applications, typically with first-stage retrieval usingkeywordsearchfollowedbyrerankingwithatransformer-basedmodel. Indeployingsuchanarchitectureinthecloud, developers must devote considerable effort to resource provisioning and management: typically, the goal is to optimize the infrastructure configuration (number and type of server instance) to achieve certain performance characteristics (latency, throughput, etc.) while reducing operating costs. In this paper, we introduce a serverless prototype of the retrieve‚Äìrerank pipeline for search using Amazon Web Services (AWS), comprised of BM25 for first-stage retrieval using Lucene followed by reranking with the monoBERT model using Hugging Face Transformers. The advantage of a serverless design is that a cloud provider shoulders the burden of operational management, for example, allocating server instances and scaling with query load. We experimentally show with the popular MS MARCO passage ranking test collection that compared to a traditional server-based deployment, our serverless implementation (1) retains the same level of effectiveness, (2) can reduce average latency by exploiting massive parallelism, and (3) incurs comparable costs if the service is expected to be idle for some fraction of the time. Our implementation is open-sourced at https://github.com/castorini/serverless-bert-reranking.",Biennial Conference on Design of Experimental Search & Information Retrieval Systems,2021.0,33,5,"[{'authorId': '2130746910', 'name': 'Mayank Anand'}, {'authorId': '2108047879', 'name': 'Jiarui Zhang'}, {'authorId': '1805948109', 'name': 'Shan Ding'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
471dea6589d6f19e78db1f47fbc7cff0d9f1aab3,https://www.semanticscholar.org/paper/471dea6589d6f19e78db1f47fbc7cff0d9f1aab3,Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback: A Reproducibility Study,,European Conference on Information Retrieval,2021.0,36,20,"[{'authorId': '2118384241', 'name': 'Hang Li'}, {'authorId': '1630489015', 'name': 'Shengyao Zhuang'}, {'authorId': '143832672', 'name': 'Ahmed Mourad'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]"
4deed74a3eee7e629dce2b8ef1e437ca74b2e64a,https://www.semanticscholar.org/paper/4deed74a3eee7e629dce2b8ef1e437ca74b2e64a,Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling,"A vital step towards the widespread adoption of neural retrieval models is their resource efficiency throughout the training, indexing and query workflows. The neural IR community made great advancements in training effective dual-encoder dense retrieval (DR) models recently. A dense text retrieval model uses a single vector representation per query and passage to score a match, which enables low-latency first-stage retrieval with a nearest neighbor search. Increasingly common, training approaches require enormous compute power, as they either conduct negative passage sampling out of a continuously updating refreshing index or require very large batch sizes. Instead of relying on more compute capability, we introduce an efficient topic-aware query and balanced margin sampling technique, called TAS-Balanced. We cluster queries once before training and sample queries out of a cluster per batch. We train our lightweight 6-layer DR model with a novel dual-teacher supervision that combines pairwise and in-batch negative teachers. Our method is trainable on a single consumer-grade GPU in under 48 hours. We show that our TAS-Balanced training method achieves state-of-the-art low-latency (64ms per query) results on two TREC Deep Learning Track query sets. Evaluated on NDCG@10, we outperform BM25 by 44%, a plainly trained DR by 19%, docT5query by 11%, and the previous best DR model by 5%. Additionally, TAS-Balanced produces the first dense retriever that outperforms every other method on recall at any cutoff on TREC-DL and allows more resource intensive re-ranking models to operate on fewer passages to improve results further.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,49,267,"[{'authorId': '97393346', 'name': 'Sebastian Hofst√§tter'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1699657', 'name': 'A. Hanbury'}]"
591cb4d880dbebcc934623738f0a6f4e92fdc40f,https://www.semanticscholar.org/paper/591cb4d880dbebcc934623738f0a6f4e92fdc40f,MS MARCO: Benchmarking Ranking Models in the Large-Data Regime,"Evaluation efforts such as TREC, CLEF, NTCIR and FIRE, alongside public leaderboard such as MS MARCO, are intended to encourage research and track our progress, addressing big questions in our field. However, the goal is not simply to identify which run is ""best"", achieving the top score. The goal is to move the field forward by developing new robust techniques, that work in many different settings, and are adopted in research and practice. This paper uses the MS MARCO and TREC Deep Learning Track as our case study, comparing it to the case of TREC ad hoc ranking in the 1990s. We show how the design of the evaluation effort can encourage or discourage certain outcomes, and raising questions about internal and external validity of results. We provide some analysis of certain pitfalls, and a statement of best practices for avoiding such pitfalls. We summarize the progress of the effort so far, and describe our desired end state of ""robust usefulness"", along with steps that might be required to get us there.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,93,46,"[{'authorId': '2286321410', 'name': 'Nick Craswell'}, {'authorId': '116506812', 'name': 'Bhaskar Mitra'}, {'authorId': '49724730', 'name': 'Emine Yilmaz'}, {'authorId': '144081089', 'name': 'Daniel Fernando Campos'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5ac627f229fa8d54f5ad43f7f99e9b29d93ada29,https://www.semanticscholar.org/paper/5ac627f229fa8d54f5ad43f7f99e9b29d93ada29,Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations,"Pyserini is an easy-to-use Python toolkit that supports replicable IR research by providing effective first-stage retrieval in a multi-stage ranking architecture. Our toolkit is self-contained as a standard Python package and comes with queries, relevance judgments, pre-built indexes, and evaluation scripts for many commonly used IR test collections. We aim to support, out of the box, the entire research lifecycle of efforts aimed at improving ranking with modern neural approaches. In particular, Pyserini supports sparse retrieval (e.g., BM25 scoring using bag-of-words representations), dense retrieval (e.g., nearest-neighbor search on transformer-encoded representations), as well as hybrid retrieval that integrates both approaches. This paper provides an overview of toolkit features and presents empirical results that illustrate its effectiveness on two popular ranking tasks. We also describe how our group has built a culture of replicability through shared norms and tools that enable rigorous automated testing.",arXiv.org,2021.0,31,65,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]"
608e5a3f3588d43ea4d0cbbb58153b19edc62f6a,https://www.semanticscholar.org/paper/608e5a3f3588d43ea4d0cbbb58153b19edc62f6a,Cross-Lingual Training of Dense Retrievers for Document Retrieval,"Dense retrieval has shown great success for passage ranking in English. However, its effectiveness for non-English languages remains unexplored due to limitation in training resources. In this work, we explore different transfer techniques for document ranking from English annotations to non-English languages. Our experiments reveal that zero-shot model-based transfer using mBERT improves search quality. We find that weakly-supervised target language transfer is competitive compared to generation-based target language transfer, which requires translation models.",MRL,2021.0,5,10,"[{'authorId': '2055357805', 'name': 'Peng Shi'}, {'authorId': '2118403769', 'name': 'Rui Zhang'}, {'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6096f3be4b39ffb09a2ba3042b1d4cb6a18c9cdf,https://www.semanticscholar.org/paper/6096f3be4b39ffb09a2ba3042b1d4cb6a18c9cdf,On the Separation of Logical and Physical Ranking Models for Text Retrieval Applications,"Text retrieval using bags of words is typically formulated as inner products between vector representations of queries and documents, realized in query evaluation algorithms that traverse postings in an inverted index. Viewed in database terms, this captures a tight coupling between the ‚Äúlogical‚Äù aspects of ranking (i",Biennial Conference on Design of Experimental Search & Information Retrieval Systems,2021.0,19,5,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '39662889', 'name': 'Antonio Mallia'}]"
60af7ea858c52df04bdb5d8c874c0549a83e1105,https://www.semanticscholar.org/paper/60af7ea858c52df04bdb5d8c874c0549a83e1105,Unsupervised Chunking as Syntactic Structure Induction with a Knowledge-Transfer Approach,"In this paper, we address unsupervised chunking as a new task of syntactic structure induction, which is helpful for understanding the linguistic structures of human languages as well as processing low-resource languages. We propose a knowledge-transfer approach that heuristically induces chunk labels from state-of-the-art unsupervised parsing models; a hierarchical recurrent neural network (HRNN) learns from such induced chunk labels to smooth out the noise of the heuristics. Experiments show that our approach largely bridges the gap between supervised and unsupervised chunking. 1",Conference on Empirical Methods in Natural Language Processing,2021.0,38,4,"[{'authorId': '72413767', 'name': 'Anup Anand Deshmukh'}, {'authorId': '2230216153', 'name': 'Qianqiu Zhang'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '38956216', 'name': 'Lili Mou'}]"
66ee9661ebcdbd0a171c9ee1fc17c26778789c67,https://www.semanticscholar.org/paper/66ee9661ebcdbd0a171c9ee1fc17c26778789c67,Cross-Lingual Training with Dense Retrieval for Document Retrieval,"Dense retrieval has shown great success in passage ranking in English. However, its effectiveness in document retrieval for non-English languages remains unexplored due to the limitation in training resources. In this work, we explore different transfer techniques for document ranking from English annotations to multiple non-English languages. Our experiments on the test collections in six languages (Chinese, Arabic, French, Hindi, Bengali, Spanish) from diverse language families reveal that zero-shot model-based transfer using mBERT improves the search quality in non-English mono-lingual retrieval. Also, we find that weakly-supervised target language transfer yields competitive performances against the generation-based target language transfer that requires external translators and query generators.",arXiv.org,2021.0,32,6,"[{'authorId': '2055357805', 'name': 'Peng Shi'}, {'authorId': '15176410', 'name': 'Rui Zhang'}, {'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6b6e13bd552d1ad640b3fca34049559dc2b3a560,https://www.semanticscholar.org/paper/6b6e13bd552d1ad640b3fca34049559dc2b3a560,Voice Query Auto Completion,"Query auto completion (QAC) is the task of predicting a search engine user‚Äôs final query from their intermediate, incomplete query. In this paper, we extend QAC to the streaming voice search setting, where automatic speech recognition systems produce intermediate transcriptions as users speak. Naively applying existing methods fails because the intermediate transcriptions often don‚Äôt form prefixes or even substrings of the final transcription. To address this issue, we propose to condition QAC approaches on intermediate transcriptions to complete voice queries. We evaluate our models on a speech-enabled smart television with real-life voice search traffic, finding that this ASR-aware conditioning improves the completion quality. Our best method obtains an 18% relative improvement in mean reciprocal rank over previous methods.",Conference on Empirical Methods in Natural Language Processing,2021.0,18,2,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2110686073', 'name': 'K. Kumar'}, {'authorId': '2139677183', 'name': 'Kendra Chalkley'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '2144165654', 'name': 'Liming Zhang'}, {'authorId': '50135600', 'name': 'Wenyan Li'}, {'authorId': '47125226', 'name': 'Gefei Yang'}, {'authorId': '49600216', 'name': 'Yajie Mao'}, {'authorId': '2148289757', 'name': 'Junho Shin'}, {'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6ee287800c2aecef59d2b1d98c0ebfcab4294f53,https://www.semanticscholar.org/paper/6ee287800c2aecef59d2b1d98c0ebfcab4294f53,Significant Improvements over the State of the Art? A Case Study of the MS MARCO Document Ranking Leaderboard,"Leaderboards are a ubiquitous part of modern research in applied machine learning. By design, they sort entries into some linear order, where the top-scoring entry is recognized as the ""state of the art"" (SOTA). Due to the rapid progress being made today, particularly with neural models, the top entry in a leaderboard is replaced with some regularity. These are touted as improvements in the state of the art. Such pronouncements, however, are almost never qualified with significance testing. In the context of the MS MARCO document ranking leaderboard, we pose a specific question: How do we know if a run is significantly better than the current SOTA? Against the backdrop of recent IR debates on scale types, our study proposes an evaluation framework that explicitly treats certain outcomes as distinct and avoids aggregating them into a single-point metric. Empirical analysis of SOTA runs from the MS MARCO document ranking leaderboard reveals insights about how one run can be ""significantly better"" than another that are obscured by the current official evaluation metric (MRR@100).",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,18,16,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144081089', 'name': 'Daniel Fernando Campos'}, {'authorId': '2286321410', 'name': 'Nick Craswell'}, {'authorId': '116506812', 'name': 'Bhaskar Mitra'}, {'authorId': '49724730', 'name': 'Emine Yilmaz'}]"
7a4c0523dbb99e2b437ab8e222420e193a517686,https://www.semanticscholar.org/paper/7a4c0523dbb99e2b437ab8e222420e193a517686,Vera: Prediction Techniques for Reducing Harmful Misinformation in Consumer Health Search,"The COVID-19 pandemic has brought about a proliferation of harmful news articles online, with sources lacking credibility and misrepresenting scientific facts. Misinformation has real consequences for consumer health search, i.e., users searching for health information. In the context of multi-stage ranking architectures, there has been little work exploring whether they prioritize correct and credible information over misinformation. We find that, indeed, training models on standard relevance ranking datasets like MS MARCO passage---which have been curated to contain mostly credible information---yields models that might also promote harmful misinformation. To rectify this, we propose a label prediction technique that can separate helpful from harmful content. Our design leverages pretrained sequence-to-sequence transformer models for both relevance ranking and label prediction. Evaluated at the TREC 2020 Health Misinformation Track, our techniques represent the top-ranked system: Our best submitted run was 19.2 points higher than the second-best run based on the primary metric, a 68% relative improvement. Additional post-hoc experiments show that we can boost effectiveness by another 3.5 points.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,26,23,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2141122507', 'name': 'Xueguang Ma'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
7b37c0a4976c4d2a5a440d494fbb0f3daede2a00,https://www.semanticscholar.org/paper/7b37c0a4976c4d2a5a440d494fbb0f3daede2a00,BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression,"The slow speed of BERT has motivated much research on accelerating its inference, and the early exiting idea has been proposed to make trade-offs between model quality and efficiency. This paper aims to address two weaknesses of previous work: (1) existing fine-tuning strategies for early exiting models fail to take full advantage of BERT; (2) methods to make exiting decisions are limited to classification tasks. We propose a more advanced fine-tuning strategy and a learning-to-exit module that extends early exiting to tasks other than classification. Experiments demonstrate improved early exiting for BERT, with better trade-offs obtained by the proposed fine-tuning strategy, successful application to regression tasks, and the possibility to combine it with other acceleration methods. Source code can be found at https://github.com/castorini/berxit.",Conference of the European Chapter of the Association for Computational Linguistics,2021.0,35,75,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7e8a05e4ce38dffc4e7e3134c6135350133c7183,https://www.semanticscholar.org/paper/7e8a05e4ce38dffc4e7e3134c6135350133c7183,The Simplest Thing That Can Possibly Work: (Pseudo-)Relevance Feedback via Text Classification,"Motivated by recent commentary that has questioned today's pursuit of ever-more complex models and mathematical formalisms in applied machine learning and whether meaningful empirical progress is actually being made, this paper tackles the decades-old problem of pseudo-relevance feedback with ""the simplest thing that can possibly work"". We present a technique based on training a document relevance classifier for each information need using pseudo-labels from an initial ranked list and then applying the classifier to rerank the retrieved documents. Experiments demonstrate significant improvements across a number of standard newswire collections, with initial rankings supplied by bag-of-words BM25 as well as from query expansion. Further evaluations in the TREC-COVID challenge using human relevance judgments verify the effectiveness and robustness of our proposed technique. While this simple idea draws elements from several well-known threads in the literature, to our knowledge this exact combination has not previously been proposed and rigorously evaluated.",International Conference on the Theory of Information Retrieval,2021.0,48,4,"[{'authorId': '2118233916', 'name': 'Xiao Han'}, {'authorId': '2144468595', 'name': 'Yuqi Liu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7ea7640c674f75987230e5334981a0c4fa7aa03a,https://www.semanticscholar.org/paper/7ea7640c674f75987230e5334981a0c4fa7aa03a,Course Objectives,"‚Ä¢ Apply economic and risk management evaluation tools for oil & gas project proposals ‚Ä¢ Identify and quantify key uncertainties during field development and full life cycle economics ‚Ä¢ Calculate the economic and financial viability of expenditure proposals projects under risk conditions ‚Ä¢ Develop a structured approach to measuring, managing and combating commercial risk ‚Ä¢ Assess the ranking of alternative projects ‚Ä¢ Prepare convincing project proposals in a way that will win management, partner and government approval. ‚Ä¢ Improve project and business outcomes",Teaching American Studies,2021.0,54,73,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1745899', 'name': 'Chris Dyer'}]"
86e44fc1cb3c2931be947fe07d1c23b8efda841a,https://www.semanticscholar.org/paper/86e44fc1cb3c2931be947fe07d1c23b8efda841a,From archive to analysis: accessing web archives at scale through a cloud-based interface,,International Journal of Digital Humanities,2021.0,30,5,"[{'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '28929508', 'name': 'Ryan Deschamps'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}]"
89a19523b0cfb587d272b9ceb950c7bc4e8e221e,https://www.semanticscholar.org/paper/89a19523b0cfb587d272b9ceb950c7bc4e8e221e,A Replication Study of Dense Passage Retriever,"Text retrieval using learned dense representations has recently emerged as a promising alternative to""traditional""text retrieval using sparse bag-of-words representations. One recent work that has garnered much attention is the dense passage retriever (DPR) technique proposed by Karpukhin et al. (2020) for end-to-end open-domain question answering. We present a replication study of this work, starting with model checkpoints provided by the authors, but otherwise from an independent implementation in our group's Pyserini IR toolkit and PyGaggle neural text ranking library. Although our experimental results largely verify the claims of the original paper, we arrived at two important additional findings that contribute to a better understanding of DPR: First, it appears that the original authors under-report the effectiveness of the BM25 baseline and hence also dense--sparse hybrid retrieval results. Second, by incorporating evidence from the retriever and an improved answer span scoring technique, we are able to improve end-to-end question answering effectiveness using exactly the same models as in the original work.",arXiv.org,2021.0,14,46,"[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2113849068', 'name': 'Kai Sun'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
89d373d61c68465fd49da1257aa959e5abefd155,https://www.semanticscholar.org/paper/89d373d61c68465fd49da1257aa959e5abefd155,"A Few Brief Notes on DeepImpact, COIL, and a Conceptual Framework for Information Retrieval Techniques","Recent developments in representational learning for information retrieval can be organized in a conceptual framework that establishes two pairs of contrasts: sparse vs. dense representations and unsupervised vs. learned representations. Sparse learned representations can further be decomposed into expansion and term weighting components. This framework allows us to understand the relationship between recently proposed techniques such as DPR, ANCE, DeepCT, DeepImpact, and COIL, and furthermore, gaps revealed by our analysis point to""low hanging fruit""in terms of techniques that have yet to be explored. We present a novel technique dubbed""uniCOIL"", a simple extension of COIL that achieves to our knowledge the current state-of-the-art in sparse retrieval on the popular MS MARCO passage ranking dataset. Our implementation using the Anserini IR toolkit is built on the Lucene search library and thus fully compatible with standard inverted indexes.",arXiv.org,2021.0,25,104,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}]"
8b84b9b1fd3ac5822dada565d48bcb159f493c04,https://www.semanticscholar.org/paper/8b84b9b1fd3ac5822dada565d48bcb159f493c04,Comparing Score Aggregation Approaches for Document Retrieval with Pretrained Transformers,,European Conference on Information Retrieval,2021.0,20,16,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
93ddb1188e4c6197a49fe261686e676cdf466623,https://www.semanticscholar.org/paper/93ddb1188e4c6197a49fe261686e676cdf466623,Simple and Effective Unsupervised Redundancy Elimination to Compress Dense Vectors for Passage Retrieval,"Recent work has shown that dense passage retrieval techniques achieve better ranking accuracy in open-domain question answering compared to sparse retrieval techniques such as BM25, but at the cost of large space and memory requirements. In this paper, we analyze the redundancy present in encoded dense vectors and show that the default dimension of 768 is unnecessarily large. To improve space efficiency, we propose a simple unsupervised compression pipeline that consists of principal component analysis (PCA), product quantization, and hybrid search. We further investigate other supervised baselines and find surprisingly that unsupervised PCA outperforms them in some settings. We perform extensive experiments on five question answering datasets and demonstrate that our best pipeline achieves good accuracy‚Äìspace trade-offs, for example, 48\times compression with less than 3% drop in top-100 retrieval accuracy on average or 96\times compression with less than 4% drop. Code and data are available at http://pyserini.io/.",Conference on Empirical Methods in Natural Language Processing,2021.0,16,16,"[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '2113849068', 'name': 'Kai Sun'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9f617ea70b8bce960e5f74faa11b051711fdb828,https://www.semanticscholar.org/paper/9f617ea70b8bce960e5f74faa11b051711fdb828,Learning to Rank in the Age of Muppets: Effectiveness‚ÄìEfficiency Tradeoffs in Multi-Stage Ranking,"It is well known that rerankers built on pretrained transformer models such as BERT have dramatically improved retrieval effectiveness in many tasks. However, these gains have come at substantial costs in terms of efficiency, as noted by many researchers. In this work, we show that it is possible to retain the benefits of transformer-based rerankers in a multi-stage reranking pipeline by first using feature-based learning-to-rank techniques to reduce the number of candidate documents under consideration without adversely affecting their quality in terms of recall. Applied to the MS MARCO passage and document ranking tasks, we are able to achieve the same level of effectiveness, but with up to 18√ó increase in efficiency. Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains. A higher-level message from our work is that, even though pretrained transformers dominate the modern IR landscape, there are still important roles for ‚Äútraditional‚Äù LTR techniques, and that we should not forget history.",SUSTAINLP,2021.0,37,7,"[{'authorId': '1591125925', 'name': 'Yue Zhang'}, {'authorId': '2118956992', 'name': 'Chengcheng Hu'}, {'authorId': '2144468595', 'name': 'Yuqi Liu'}, {'authorId': '2113484881', 'name': 'Hui Fang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a5c030e1fbf8354227559e374ab573e9230efa72,https://www.semanticscholar.org/paper/a5c030e1fbf8354227559e374ab573e9230efa72,Wacky Weights in Learned Sparse Representations and the Revenge of Score-at-a-Time Query Evaluation,"Recent advances in retrieval models based on learned sparse representations generated by transformers have led us to, once again, consider score-at-a-time query evaluation techniques for the top-k retrieval problem. Previous studies comparing document-at-a-time and score-at-a-time approaches have consistently found that the former approach yields lower mean query latency, although the latter approach has more predictable query latency. In our experiments with four different retrieval models that exploit representational learning with bags of words, we find that transformers generate""wacky weights""that appear to greatly reduce the opportunities for skipping and early exiting optimizations that lie at the core of standard document-at-a-time techniques. As a result, score-at-a-time approaches appear to be more competitive in terms of query evaluation latency than in previous studies. We find that, if an effectiveness loss of up to three percent can be tolerated, a score-at-a-time approach can yield substantial gains in mean query latency while at the same time dramatically reducing tail latency.",arXiv.org,2021.0,49,29,"[{'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b2474a00d7de3373bab934c09acef1994fa82207,https://www.semanticscholar.org/paper/b2474a00d7de3373bab934c09acef1994fa82207,Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages,"Pretrained multilingual language models have been shown to work well on many languages for a variety of downstream NLP tasks. However, these models are known to require a lot of training data. This consequently leaves out a huge percentage of the world‚Äôs languages as they are under-resourced. Furthermore, a major motivation behind these models is that lower-resource languages benefit from joint training with higher-resource languages. In this work, we challenge this assumption and present the first attempt at training a multilingual language model on only low-resource languages. We show that it is possible to train competitive multilingual language models on less than 1 GB of text. Our model, named AfriBERTa, covers 11 African languages, including the first language model for 4 of these languages. Evaluations on named entity recognition and text classification spanning 10 languages show that our model outperforms mBERT and XLM-Rin several languages and is very competitive overall. Results suggest that our ‚Äúsmall data‚Äù approach based on similar languages may sometimes work better than joint training on large datasets with high-resource languages. Code, data and models are released at https://github.com/keleog/afriberta.",MRL,2021.0,46,124,"[{'authorId': '1452683268', 'name': 'Kelechi Ogueji'}, {'authorId': '2144317694', 'name': 'Yuxin Zhu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b88d69b643b3a7d0872931aeed2cdf1876588e26,https://www.semanticscholar.org/paper/b88d69b643b3a7d0872931aeed2cdf1876588e26,Densifying Sparse Representations for Passage Retrieval by Representational Slicing,"Learned sparse and dense representations capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust. Prior work combines dense and sparse retrievers by fusing their model scores. As an alternative, this paper presents a simple approach to densifying sparse representations for text retrieval that does not involve any training. Our densified sparse representations (DSRs) are interpretable and can be easily combined with dense representations for end-to-end retrieval. We demonstrate that our approach can jointly learn sparse and dense representations within a single model and then combine them for dense retrieval. Experimental results suggest that combining our DSRs and dense representations yields a balanced tradeoff between effectiveness and efficiency.",arXiv.org,2021.0,31,12,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c107835a05ca6fda6e73b64e2ed9884de4fcec0f,https://www.semanticscholar.org/paper/c107835a05ca6fda6e73b64e2ed9884de4fcec0f,A proposed conceptual framework for a representational approach to information retrieval,"This paper outlines a conceptual framework for understanding recent developments in information retrieval and natural language processing that attempts to integrate dense and sparse retrieval methods. I propose a representational approach that breaks the core text retrieval problem into a logical scoring model and a physical retrieval model. The scoring model is defined in terms of encoders, which map queries and documents into a representational space, and a comparison function that computes query-document scores. The physical retrieval model defines how a system produces the top-k scoring documents from an arbitrarily large corpus with respect to a query. The scoring model can be further analyzed along two dimensions: dense vs. sparse representations and supervised (learned) vs. unsupervised approaches. I show that many recently proposed retrieval methods, including multi-stage ranking designs, can be seen as different parameterizations in this framework, and that a unified view suggests a number of open research questions, providing a roadmap for future work. As a bonus, this conceptual framework establishes connections to sentence similarity tasks in natural language processing and information access ""technologies"" prior to the dawn of computing.",SIGIR Forum,2021.0,87,38,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c3df8f8b7f1ed68f0ffeef6afcf60039f955b397,https://www.semanticscholar.org/paper/c3df8f8b7f1ed68f0ffeef6afcf60039f955b397,Overview of the TREC 2021 Deep Learning Track,"This is the third year of the TREC Deep Learning track. As in previous years, we leverage the MS MARCO datasets that made hundreds of thousands of human annotated training labels available for both passage and document ranking tasks. In addition, this year we refreshed both the document and the passage collections which also led to a nearly four times increase in the document collection size and nearly 16 times increase in the size of the passage collection. Deep neural ranking models that employ large scale pretraininig continued to outperform traditional retrieval methods this year. We also found that single stage retrieval can achieve good performance on both tasks although they still do not perform at par with multistage retrieval pipelines. Finally, the increase in the collection size and the general data refresh raised some questions about completeness of NIST judgments and the quality of the training labels that were mapped to the new collections from the old ones which we discuss in this report.",Text Retrieval Conference,2021.0,19,26,"[{'authorId': '2286321410', 'name': 'Nick Craswell'}, {'authorId': '116506812', 'name': 'Bhaskar Mitra'}, {'authorId': '49724730', 'name': 'Emine Yilmaz'}, {'authorId': '144081089', 'name': 'Daniel Fernando Campos'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
cbbcc7d518c626bbce1e859c6179d1faa2d2fd46,https://www.semanticscholar.org/paper/cbbcc7d518c626bbce1e859c6179d1faa2d2fd46,Bag-of-Words Baselines for Semantic Code Search,"The task of semantic code search is to retrieve code snippets from a source code corpus based on an information need expressed in natural language. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. It is a common assumption that ‚Äútraditional‚Äù bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption. Specifically, we examine the effectiveness of two traditional IR methods, namely BM25 and RM3, on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets. We find that the two keyword-based methods outperform several pre-BERT neural models. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.",NLP4PROG,2021.0,27,0,"[{'authorId': None, 'name': 'Xinyu Zhang'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
d2082f0af7f1b093b280446f2bdc48a129ba2d5b,https://www.semanticscholar.org/paper/d2082f0af7f1b093b280446f2bdc48a129ba2d5b,H 2 oloo at TREC 2019: Combining Sentence and Document Evidence in the Deep Learning Track,,,2021.0,14,6,"[{'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '1678689', 'name': 'Shengjin Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
d69c0ed04ecc852e8c921900d3e7967f74f81263,https://www.semanticscholar.org/paper/d69c0ed04ecc852e8c921900d3e7967f74f81263,Pyserini: A Python Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations,"Pyserini is a Python toolkit for reproducible information retrieval research with sparse and dense representations. It aims to provide effective, reproducible, and easy-to-use first-stage retrieval in a multi-stage ranking architecture. Our toolkit is self-contained as a standard Python package and comes with queries, relevance judgments, pre-built indexes, and evaluation scripts for many commonly used IR test collections. We aim to support, out of the box, the entire research lifecycle of efforts aimed at improving ranking with modern neural approaches. In particular, Pyserini supports sparse retrieval (e.g., BM25 scoring using bag-of-words representations), dense retrieval (e.g., nearest-neighbor search on transformer-encoded representations), as well as hybrid retrieval that integrates both approaches. This paper provides an overview of toolkit features and presents empirical results that illustrate its effectiveness on two popular ranking tasks. Around this toolkit, our group has built a culture of reproducibility through shared norms and tools that enable rigorous automated testing.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,42,282,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
dd0e36831fa19da2e56fa925397407961a506bb6,https://www.semanticscholar.org/paper/dd0e36831fa19da2e56fa925397407961a506bb6,Contextualized Query Embeddings for Conversational Search,"This paper describes a compact and effective model for low-latency passage retrieval in conversational search based on learned dense representations. Prior to our work, the state-of-the-art approach uses a multi-stage pipeline comprising conversational query reformulation and information retrieval modules. Despite its effectiveness, such a pipeline often includes multiple neural models that require long inference times. In addition, independently optimizing each module ignores dependencies among them. To address these shortcomings, we propose to integrate conversational query reformulation directly into a dense retrieval model. To aid in this goal, we create a dataset with pseudo-relevance labels for conversational search to overcome the lack of training data and to explore different training strategies. We demonstrate that our model effectively rewrites conversational queries as dense representations in conversational search and open-domain question answering datasets. Finally, after observing that our model learns to adjust the L2 norm of query token embeddings, we leverage this property for hybrid retrieval and to support error analysis.",Conference on Empirical Methods in Natural Language Processing,2021.0,36,36,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e08eed9608382beea1febca49119c665fbabd031,https://www.semanticscholar.org/paper/e08eed9608382beea1febca49119c665fbabd031,The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained Sequence-to-Sequence Models,"We propose a design pattern for tackling text ranking problems, dubbed""Expando-Mono-Duo"", that has been empirically validated for a number of ad hoc retrieval tasks in different domains. At the core, our design relies on pretrained sequence-to-sequence models within a standard multi-stage ranking architecture.""Expando""refers to the use of document expansion techniques to enrich keyword representations of texts prior to inverted indexing.""Mono""and""Duo""refer to components in a reranking pipeline based on a pointwise model and a pairwise model that rerank initial candidates retrieved using keyword search. We present experimental results from the MS MARCO passage and document ranking tasks, the TREC 2020 Deep Learning Track, and the TREC-COVID challenge that validate our design. In all these tasks, we achieve effectiveness that is at or near the state of the art, in some cases using a zero-shot approach that does not exploit any training data from the target task. To support replicability, implementations of our design pattern are open-sourced in the Pyserini IR toolkit and PyGaggle neural reranking library.",arXiv.org,2021.0,61,109,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e15b57e7cc156676f986abd3da442cea20812c6c,https://www.semanticscholar.org/paper/e15b57e7cc156676f986abd3da442cea20812c6c,Fostering Community Engagement through Datathon Events: The Archives Unleashed Experience,"This article explores the impact that a series of Archives Unleashed datathon events have had on community engagement both within the web archiving field, and more specifically, on the professional practices of attendees. We present results from surveyed datathon participants, in addition to related evidence from our events, to discuss how our participants saw the datathons as dramatically impacting both their professional practices as well as the broader web archiving community. Drawing on and adapting two leading community engagement models, we combine them to introduce a new understanding of how to build and engage users in an open-source digital humanities project. Our model illustrates both the activities undertaken by our project as well as the related impact they have on the field. The model can be broadly applied to other digital humanities projects seeking to engage their communities.",Digital Humanities Quarterly,2021.0,30,0,"[{'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e47d338ca879a184c1977ffa8623d2a225b0a319,https://www.semanticscholar.org/paper/e47d338ca879a184c1977ffa8623d2a225b0a319,Multi-Task Dense Retrieval via Model Uncertainty Fusion for Open-Domain Question Answering,"Multi-task dense retrieval models can be used to retrieve documents from a common corpus (e.g., Wikipedia) for different open-domain question-answering (QA) tasks. However, Karpukhin et al. (2020) shows that jointly learning different QA tasks with one dense model is not always beneÔ¨Åcial due to corpus inconsistency. For example, SQuAD only focuses on a small set of Wikipedia articles while datasets like NQ and Trivia cover more entries, and joint training on their union can cause performance degradation. To solve this problem, we propose to train individual dense passage retrievers (DPR) for different tasks and aggregate their predictions during test time, where we use uncertainty estimation as weights to indicate how probable a speciÔ¨Åc query belongs to each expert‚Äôs expertise. Our method reaches state-of-the-art performance on 5 benchmark QA datasets, with up to 10% improvement in top-100 accuracy compared to a joint-training multi-task DPR on SQuAD. We also show that our method handles corpus inconsistency better than the joint-training DPR on a mixed subset of different QA datasets. Code and data are available at https://github.com/ alexlimh/DPR_MUF .",Conference on Empirical Methods in Natural Language Processing,2021.0,45,11,"[{'authorId': '2135230554', 'name': 'Minghan Li'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ebde99678faf2960beec8010a6217efdc3513cb9,https://www.semanticscholar.org/paper/ebde99678faf2960beec8010a6217efdc3513cb9,Distilling Massive Amounts of Data into Simple Visualizations: Twitter Case Studies,"
 
 We present three Twitter case studies of distilling massive amounts of data into simple visualizations.
 
",Proceedings of the International AAAI Conference on Web and Social Media,2021.0,3,2,"[{'authorId': '145290517', 'name': 'Miguel Rios'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ec7253bc9cbde42f1fbebd5c7a68a91501e2483e,https://www.semanticscholar.org/paper/ec7253bc9cbde42f1fbebd5c7a68a91501e2483e,Approach Zero and Anserini at the CLEF-2021 ARQMath Track: Applying Substructure Search and BM25 on Operator Tree Path Tokens,"This paper reports on substructure-aware math search system Approach Zero that is applied to our submission for ARQMath lab at CLEF 2021. We have participated in both Task 1 (math ARQ) and Task 2 (formula retrieval) this year. In addition to substructure retrieval, we have added a traditional full-text search pass based on the Anserini toolkit [1]. We use the same path features extracted from Operator Tree (OPT) to index and retrieve math formulas in Anserini, and we interpolate Anserini results with structural results from Approach Zero. Automatic and table-based keyword expansion methods for math formulas have also been explored. Additionally, we report preliminary results from using previous years‚Äô labels and applying learning to rank for our first-stage search results. In this lab, we obtain the most effective search results in Task 2 (formula retrieval) among submissions from 7 participants including the baseline system. Our experiments have also shown a great improvement over the baseline result we produced from previous year.",Conference and Labs of the Evaluation Forum,2021.0,20,8,"[{'authorId': '2100393067', 'name': 'Wei Zhong'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '1793699', 'name': 'R. Zanibbi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f71ed8967b26226da15f81e99eb41f656467e148,https://www.semanticscholar.org/paper/f71ed8967b26226da15f81e99eb41f656467e148,Sparsifying Sparse Representations for Passage Retrieval by Top-k Masking,"Sparse lexical representation learning has demonstrated much progress in improving passage retrieval effectiveness in recent models such as DeepImpact, uniCOIL, and SPLADE. This paper describes a straightforward yet effective approach for sparsifying lexical representations for passage retrieval, building on SPLADE by introducing a top-$k$ masking scheme to control sparsity and a self-learning method to coax masked representations to mimic unmasked representations. A basic implementation of our model is competitive with more sophisticated approaches and achieves a good balance between effectiveness and efficiency. The simplicity of our methods opens the door for future explorations in lexical representation learning for passage retrieval.",arXiv.org,2021.0,28,12,"[{'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fa080a3427af8b7d871e05d381d7a322f38dccd9,https://www.semanticscholar.org/paper/fa080a3427af8b7d871e05d381d7a322f38dccd9,Don‚Äôt Change Me! User-Controllable Selective Paraphrase Generation,"In the paraphrase generation task, source sentences often contain phrases that should not be altered. Which phrases, however, can be context dependent and can vary by application. Our solution to this challenge is to provide the user with explicit tags that can be placed around any arbitrary segment of text to mean ‚Äúdon‚Äôt change me!‚Äù when generating a paraphrase; the model learns to explicitly copy these phrases to the output. The contribution of this work is a novel data generation technique using distant supervision that allows us to start with a pretrained sequence-to-sequence model and fine-tune a paraphrase generator that exhibits this behavior, allowing user-controllable paraphrase generation. Additionally, we modify the loss during fine-tuning to explicitly encourage diversity in model output. Our technique is language agnostic, and we report experiments in English and Chinese.",Conference of the European Chapter of the Association for Computational Linguistics,2021.0,10,2,"[{'authorId': '48985313', 'name': 'Mohan Zhang'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '101028678', 'name': 'Zihang Fu'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '1924612088', 'name': 'Zhengkai Tu'}]"
0413170928fa88cde7c964cb987d094e8e3d76f0,https://www.semanticscholar.org/paper/0413170928fa88cde7c964cb987d094e8e3d76f0,Rapid Adaptation of BERT for Information Extraction on Domain-Specific Business Documents,"Techniques for automatically extracting important content elements from business documents such as contracts, statements, and filings have the potential to make business operations more efficient. This problem can be formulated as a sequence labeling task, and we demonstrate the adaption of BERT to two types of business documents: regulatory filings and property lease agreements. There are aspects of this problem that make it easier than ""standard"" information extraction tasks and other aspects that make it more difficult, but on balance we find that modest amounts of annotated data (less than 100 documents) are sufficient to achieve reasonable accuracy. We integrate our models into an end-to-end cloud platform that provides both an easy-to-use annotation interface as well as an inference interface that allows users to upload documents and inspect model outputs.",arXiv.org,2020.0,16,17,"[{'authorId': '2124894440', 'name': 'Ruixue Zhang'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '1491450668', 'name': 'Luyun Lin'}, {'authorId': '1924612088', 'name': 'Zhengkai Tu'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '101028678', 'name': 'Zihang Fu'}, {'authorId': '94510137', 'name': 'Yuhao Xie'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0f995b05821b58b02e914422b56fba615d0e8d7f,https://www.semanticscholar.org/paper/0f995b05821b58b02e914422b56fba615d0e8d7f,Rapidly Bootstrapping a Question Answering Dataset for COVID-19,"We present CovidQA, the beginnings of a question answering dataset specifically designed for COVID-19, built by hand from knowledge gathered from Kaggle's COVID-19 Open Research Dataset Challenge. To our knowledge, this is the first publicly available resource of its type, and intended as a stopgap measure for guiding research until more substantial evaluation resources become available. While this dataset, comprising 124 question-article pairs as of the present version 0.1 release, does not have sufficient examples for supervised machine learning, we believe that it can be helpful for evaluating the zero-shot or transfer capabilities of existing models on topics specifically related to COVID-19. This paper describes our methodology for constructing the dataset and presents the effectiveness of a number of baselines, including term-based techniques and various transformer-based models. The dataset is available at this http URL",arXiv.org,2020.0,21,67,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '6549913', 'name': 'Edwin Zhang'}, {'authorId': '1573914472', 'name': 'Nikhil Gupta'}, {'authorId': '120968710', 'name': 'P. C·∫©m'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
10b79d7b377fac08c2569fdc9cb7b3cd903c9637,https://www.semanticscholar.org/paper/10b79d7b377fac08c2569fdc9cb7b3cd903c9637,Exploring the Limits of Simple Learners in Knowledge Distillation for Document Classification with DocBERT,"Fine-tuned variants of BERT are able to achieve state-of-the-art accuracy on many natural language processing tasks, although at significant computational costs. In this paper, we verify BERT‚Äôs effectiveness for document classification and investigate the extent to which BERT-level effectiveness can be obtained by different baselines, combined with knowledge distillation‚Äîa popular model compression method. The results show that BERT-level effectiveness can be achieved by a single-layer LSTM with at least 40\times fewer FLOPS and only {\sim}3\% parameters. More importantly, this study analyzes the limits of knowledge distillation as we distill BERT‚Äôs knowledge all the way down to linear models‚Äîa relevant baseline for the task. We report substantial improvement in effectiveness for even the simplest models, as they capture the knowledge learnt by BERT.",Workshop on Representation Learning for NLP,2020.0,22,19,"[{'authorId': '51941200', 'name': 'Ashutosh Adhikari'}, {'authorId': '46253949', 'name': 'Achyudh Ram'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '49437682', 'name': 'William L. Hamilton'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
11909b4cf231c7fc91933098402c75429fd4c364,https://www.semanticscholar.org/paper/11909b4cf231c7fc91933098402c75429fd4c364,A Prototype of Serverless Lucene,"This paper describes a working prototype that adapts Lucene, the world's most popular and most widely deployed open-source search library, to operate within a serverless environment in the cloud. Although the serverless search concept is not new, this work represents a substantial improvement over a previous implementation in eliminating most custom code and in enabling interactive search. While there remain limitations to the design, it nevertheless challenges conventional thinking about search architectures for particular operating points.",arXiv.org,2020.0,19,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
188c4b9a13bf98e0c8818d43baf75b1930342912,https://www.semanticscholar.org/paper/188c4b9a13bf98e0c8818d43baf75b1930342912,Semantics of the Unwritten: The Effect of End of Paragraph and Sequence Tokens on Text Generation with GPT2,"The semantics of a text is manifested not only by what is read but also by what is not read. In this article, we will study how those implicit ‚Äúnot read‚Äù information such as end-of-paragraph () and end-of-sequence () affect the quality of text generation. Specifically, we find that the pre-trained language model GPT2 can generate better continuations by learning to generate the in the fine-tuning stage. Experimental results on English story generation show that can lead to higher BLEU scores and lower perplexity. We also conduct experiments on a self-collected Chinese essay dataset with Chinese-GPT2, a character level LM without and during pre-training. Experimental results show that the Chinese GPT2 can generate better essay endings with .",Annual Meeting of the Association for Computational Linguistics,2020.0,18,4,"[{'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '2055357849', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2153578299', 'name': 'Wen Gao'}, {'authorId': '2146651412', 'name': 'Jie Liu'}, {'authorId': '2150652992', 'name': 'Ming Li'}]"
1b59747fb24f77406d7234b12421d1cbd7738946,https://www.semanticscholar.org/paper/1b59747fb24f77406d7234b12421d1cbd7738946,Generalized and Scalable Optimal Sparse Decision Trees,"Decision tree optimization is notoriously difficult from a computational perspective but essential for the field of interpretable machine learning. Despite efforts over the past 40 years, only recently have optimization breakthroughs been made that have allowed practical algorithms to find optimal decision trees. These new techniques have the potential to trigger a paradigm shift where it is possible to construct sparse decision trees to efficiently optimize a variety of objective functions without relying on greedy splitting and pruning heuristics that often lead to suboptimal solutions. The contribution in this work is to provide a general framework for decision tree optimization that addresses the two significant open problems in the area: treatment of imbalanced data and fully optimizing over continuous variables. We present techniques that produce optimal decision trees over a variety of objectives including F-score, AUC, and partial area under the ROC convex hull. We also introduce a scalable algorithm that produces provably optimal results in the presence of continuous variables and speeds up decision tree construction by several orders of magnitude relative to the state-of-the art.",International Conference on Machine Learning,2020.0,43,103,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1750932565', 'name': 'Chudi Zhong'}, {'authorId': '2070035422', 'name': 'Diane Hu'}, {'authorId': '48395540', 'name': 'C. Rudin'}, {'authorId': '1745942', 'name': 'M. Seltzer'}]"
1cc0b98b938b984e5da85f86c1a24099b9b4b582,https://www.semanticscholar.org/paper/1cc0b98b938b984e5da85f86c1a24099b9b4b582,SegaBERT: Pre-training of Segment-aware BERT for Language Understanding,"Pre-trained language models have achieved state-of-the-art results in various natural language processing tasks. Most of them are based on the Transformer architecture, which distinguishes tokens with the token position index of the input sequence. However, sentence index and paragraph index are also important to indicate the token position in a document. We hypothesize that better contextual representations can be generated from the text encoder with richer positional information. To verify this, we propose a segment-aware BERT, by replacing the token position embedding of Transformer with a combination of paragraph index, sentence index, and token index embeddings. We pre-trained the SegaBERT on the masked language modeling task in BERT but without any affiliated tasks. Experimental results show that our pre-trained model can outperform the original BERT model on various NLP tasks.",arXiv.org,2020.0,31,7,"[{'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '2055357849', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2153578299', 'name': 'Wen Gao'}, {'authorId': '2150652992', 'name': 'Ming Li'}]"
1db81c2e030f37bc14a01c6e43171a8079e7cccd,https://www.semanticscholar.org/paper/1db81c2e030f37bc14a01c6e43171a8079e7cccd,Conversational Question Reformulation via Sequence-to-Sequence Architectures and Pretrained Language Models,"This paper presents an empirical study of conversational question reformulation (CQR) with sequence-to-sequence architectures and pretrained language models (PLMs). We leverage PLMs to address the strong token-to-token independence assumption made in the common objective, maximum likelihood estimation, for the CQR task. In CQR benchmarks of task-oriented dialogue systems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset as an in-domain task and validate the models using data from the TREC 2019 CAsT Track as an out-domain task. Examining a variety of architectures with different numbers of parameters, we demonstrate that the recent text-to-text transfer transformer (T5) achieves the best results both on CANARD and CAsT with fewer parameters, compared to similar transformer architectures.",arXiv.org,2020.0,26,54,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
241072e21b8f35d91fe072b77ef926d017c12100,https://www.semanticscholar.org/paper/241072e21b8f35d91fe072b77ef926d017c12100,A Little Bit Is Worse Than None: Ranking with Limited Training Data,"Researchers have proposed simple yet effective techniques for the retrieval problem based on using BERT as a relevance classifier to rerank initial candidates from keyword search. In this work, we tackle the challenge of fine-tuning these models for specific domains in a data and computationally efficient manner. Typically, researchers fine-tune models using corpus-specific labeled data from sources such as TREC. We first answer the question: How much data of this type do we need? Recognizing that the most computationally efficient training is no training, we explore zero-shot ranking using BERT models that have already been fine-tuned with the large MS MARCO passage retrieval dataset. We arrive at the surprising and novel finding that ‚Äúsome‚Äù labeled in-domain data can be worse than none at all.",SUSTAINLP,2020.0,19,13,"[{'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
24967a55839cf9d8c26187888aac67b3ee4999b9,https://www.semanticscholar.org/paper/24967a55839cf9d8c26187888aac67b3ee4999b9,Inserting Information Bottleneck for Attribution in Transformers,"Pretrained transformers achieve the state of the art across tasks in natural language processing, motivating researchers to investigate their inner mechanisms. One common direction is to understand what features are important for prediction. In this paper, we apply information bottlenecks to analyze the attribution of each feature for prediction on a black-box model. We use BERT as the example and evaluate our approach both quantitatively and qualitatively. We show the effectiveness of our method in terms of attribution and the ability to provide insight into how information flows through layers. We demonstrate that our technique outperforms two competitive methods in degradation tests on four datasets. Code is available at https://github.com/bazingagin/IBA.",Findings,2020.0,29,6,"[{'authorId': None, 'name': 'Zhiying Jiang'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2bbc8d4d6249206190790e3bcf608fccfbacd32e,https://www.semanticscholar.org/paper/2bbc8d4d6249206190790e3bcf608fccfbacd32e,A Lightweight Environment for Learning Experimental IR Research Practices,"Tools, computing environments, and datasets form the three critical ingredients for teaching and learning the practical aspects of experimental IR research. Assembling these ingredients can often be challenging, particularly in the context of short courses that cannot afford large startup costs. As an initial attempt to address these issues, we describe materials that we have developed for the ""Introduction to IR"" session at the ACM SIGIR/SIGKDD Africa Summer School on Machine Learning for Data Mining and Search (AFIRM 2020), which builds on three components: the open-source Lucene search library, cloud-based notebooks, and the MS MARCO dataset. We offer a self-reflective evaluation of our efforts and hope that our lessons shared can benefit future efforts.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2020.0,12,12,"[{'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2c953a3c378b40dadf2e3fb486713c8608b8e282,https://www.semanticscholar.org/paper/2c953a3c378b40dadf2e3fb486713c8608b8e282,Pretrained Transformers for Text Ranking: BERT and Beyond,"The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task. Although the most common formulation of text ranking is search, instances of the task can also be found in many text processing applications. This tutorial provides an overview of text ranking with neural network architectures known as transformers, of which BERT (Bidirectional Encoder Representations from Transformers) is the best-known example. These models produce high quality results across many domains, tasks, and settings. This tutorial, which is based on the preprint of a forthcoming book to be published by Morgan and & Claypool under the Synthesis Lectures on Human Language Technologies series, provides an overview of existing work as a single point of entry for practitioners who wish to deploy transformers for text ranking in real-world applications and researchers who wish to pursue work in this area. We cover a wide range of techniques, grouped into two categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that perform ranking directly.",North American Chapter of the Association for Computational Linguistics,2020.0,480,471,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '144115896', 'name': 'Andrew Yates'}]"
320efa53dea3e8f836790682fbd4196132c49749,https://www.semanticscholar.org/paper/320efa53dea3e8f836790682fbd4196132c49749,Segatron: Segment-Aware Transformer for Language Modeling and Understanding,"Transformers are powerful for sequence modeling. Nearly all state-of-the-art language models and pre-trained language models are based on the Transformer architecture. However, it distinguishes sequential tokens only with the token position index. We hypothesize that better contextual representations can be generated from the Transformer with richer positional information. To verify this, we propose a segment-aware Transformer (Segatron), by replacing the original token position encoding with a combined position encoding of paragraph, sentence, and token. We first introduce the segment-aware mechanism to Transformer-XL, which is a popular Transformer-based language model with memory extension and relative position encoding. We find that our method can further improve the Transformer-XL base model and large model, achieving 17.1 perplexity on the WikiText-103 dataset. We further investigate the pre-training masked language modeling task with Segatron. Experimental results show that BERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla Transformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence representation learning. Our code is available on GitHub.",AAAI Conference on Artificial Intelligence,2020.0,39,17,"[{'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '2055357849', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2153578299', 'name': 'Wen Gao'}, {'authorId': '2150652992', 'name': 'Ming Li'}]"
3d733e63d44bddd235a41e47cf0718ff5e70b8e1,https://www.semanticscholar.org/paper/3d733e63d44bddd235a41e47cf0718ff5e70b8e1,Navigation-based candidate expansion and pretrained language models for citation recommendation,,Scientometrics,2020.0,60,17,"[{'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': None, 'name': 'Zhiying Jiang'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
421c3f395b4483c2b723ecb3472cb88708b50264,https://www.semanticscholar.org/paper/421c3f395b4483c2b723ecb3472cb88708b50264,Capreolus: A Toolkit for End-to-End Neural Ad Hoc Retrieval,"We present Capreolus, a toolkit designed to facilitate end-to-end it ad hoc retrieval experiments with neural networks by providing implementations of prominent neural ranking models within a common framework. Our toolkit adopts a standard reranking architecture via tight integration with the Anserini toolkit for candidate document generation using standard bag-of-words approaches. Using Capreolus, we are able to reproduce Yang et al.'s recent SIGIR 2019 finding that, in a reranking scenario on the test collection from the TREC 2004 Robust Track, many neural retrieval models do not significantly outperform a strong query expansion baseline. Furthermore, we find that this holds true for five additional models implemented in Capreolus. We describe the architecture and design of our toolkit, which includes a Web interface to facilitate comparisons between rankings returned by different models.",Web Search and Data Mining,2020.0,20,22,"[{'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '72401599', 'name': 'Siddhant Arora'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '2117356', 'name': 'Kevin Martin Jose'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4b91247cc0692f34eb3e39485aa3d2d4e8ac9dc5,https://www.semanticscholar.org/paper/4b91247cc0692f34eb3e39485aa3d2d4e8ac9dc5,"H2oloo at TREC 2020: When all you got is a hammer... Deep Learning, Health Misinformation, and Precision Medicine",",",Text Retrieval Conference,2020.0,19,25,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '3129614', 'name': 'H. Cui'}, {'authorId': '2087110267', 'name': 'Ruizhou Xu'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
50fe89d2109f1f186e5e91aa8a7853d92a85daee,https://www.semanticscholar.org/paper/50fe89d2109f1f186e5e91aa8a7853d92a85daee,Evaluating Pretrained Transformer Models for Citation Recommendation,". Citation recommendation systems for the scientiÔ¨Åc literature, to help authors Ô¨Ånd papers that should be cited, have the potential to speed up discoveries and uncover new routes for scientiÔ¨Åc exploration. We treat this task as a ranking problem, which we tackle with a two-stage approach: candidate generation followed by re-ranking. Within this framework, we adapt to the scientiÔ¨Åc domain a proven combination based on ‚Äúbag of words‚Äù retrieval followed by re-scoring with a BERT model. We experimentally show the eÔ¨Äects of domain adaptation, both in terms of pretraining on in-domain data and exploiting in-domain vocabulary. In addition, we evaluate eleven pretrained transformer models and analyze some unexpected failure cases. On three diÔ¨Äerent collections from diÔ¨Äerent scientiÔ¨Åc disciplines, our models perform close to or at the state of the art in the citation recommendation task.",BIR@ECIR,2020.0,37,7,"[{'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': None, 'name': 'Zhiying Jiang'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5749bf08ef69d6005e5e084f071a505328053670,https://www.semanticscholar.org/paper/5749bf08ef69d6005e5e084f071a505328053670,Identification and Ranking of Biomedical Informatics Researcher Citation Statistics through a Google Scholar Scraper,"To overcome limitations of previously developed scientific productivity ranking services, we created the Biomedical Informatics Researchers ranking website (rank.informatics-review.com). The website is composed of four key components that work together to create the automatically updating ranking website: 1) list of biomedical informatics researchers, 2) Google Scholar scraper, 3) display page, and 4) updater. The interactive website has facilitated identification of leaders in each of the key citation statistics categories (i.e., number of citations, h-index, and i10-index), and it has allowed other groups, such as tenure and promotions committees, to more effectively and efficiently evaluate researchers and interpret the various citation statistics reported by candidates. Creation of the biomedical informatics researcher ranking website highlights the vast differences in scholarly productivity among members of the biomedical informatics research community. Future efforts are underway to add new functionality to the website and to expand the work to identify top papers in biomedical informatics.",American Medical Informatics Association Annual Symposium,2020.0,7,3,"[{'authorId': '13983559', 'name': 'A. McCoy'}, {'authorId': '1690314', 'name': 'Dean F. Sittig'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '143731512', 'name': 'A. Wright'}]"
58737fba500075136ee0f33f7801a5ac7f82ab68,https://www.semanticscholar.org/paper/58737fba500075136ee0f33f7801a5ac7f82ab68,Which BM25 Do You Mean? A Large-Scale Reproducibility Study of Scoring Variants,,European Conference on Information Retrieval,2020.0,13,41,"[{'authorId': '1591687213', 'name': 'Chris Kamphuis'}, {'authorId': '144509504', 'name': 'A. D. Vries'}, {'authorId': '3308561', 'name': 'Leonid Boytsov'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5d31f47e0cd4a4bffc68a3f5ff4f37e714215df7,https://www.semanticscholar.org/paper/5d31f47e0cd4a4bffc68a3f5ff4f37e714215df7,Generalized Optimal Sparse Decision Trees,"Decision tree optimization is notoriously difficult from a computational perspective but essential for the field of interpretable machine learning. Despite efforts over the past 40 years, only recently have optimization breakthroughs been made that have allowed practical algorithms to find optimal decision trees. These new techniques have the potential to trigger a paradigm shift where it is possible to construct sparse decision trees to efficiently optimize a variety of objective functions without relying on greedy splitting and pruning heuristics that often lead to suboptimal solutions. The contribution in this work is to provide a general framework for decision tree optimization that addresses the two significant open problems in the area: treatment of imbalanced data and fully optimizing over continuous variables. We present techniques that produce optimal decision trees over a variety of objectives including F-score, AUC, and partial area under the ROC convex hull. We also introduce a scalable algorithm that produces provably optimal results in the presence of continuous variables and speeds up decision tree construction by several orders of magnitude relative to the state-of-the art.",arXiv.org,2020.0,0,4,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1750932565', 'name': 'Chudi Zhong'}, {'authorId': '2070035422', 'name': 'Diane Hu'}, {'authorId': '48395540', 'name': 'C. Rudin'}, {'authorId': '1745942', 'name': 'M. Seltzer'}]"
63076064a7775f4ab6a094d93a233d32b7031686,https://www.semanticscholar.org/paper/63076064a7775f4ab6a094d93a233d32b7031686,Distant Supervision for Multi-Stage Fine-Tuning in Retrieval-Based Question Answering,"We tackle the problem of question answering directly on a large document collection, combining simple ‚Äúbag of words‚Äù passage retrieval with a BERT-based reader for extracting answer spans. In the context of this architecture, we present a data augmentation technique using distant supervision to automatically annotate paragraphs as either positive or negative examples to supplement existing training data, which are then used together to fine-tune BERT. We explore a number of details that are critical to achieving high accuracy in this setup: the proper sequencing of different datasets during fine-tuning, the balance between ‚Äúdifficult‚Äù vs. ‚Äúeasy‚Äù examples, and different approaches to gathering negative examples. Experimental results show that, with the appropriate settings, we can achieve large gains in effectiveness on two English and two Chinese QA datasets. We are able to achieve results at or near the state of the art without any modeling advances, which once again affirms the clich√© ‚Äúthere‚Äôs no data like more data‚Äù.",The Web Conference,2020.0,31,22,"[{'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2123146', 'name': 'Nicholas Jing Yuan'}, {'authorId': '2422046', 'name': 'Baoxing Huai'}, {'authorId': '7755014', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
67e5e67ac9fcfb241984d791c1d211a434901639,https://www.semanticscholar.org/paper/67e5e67ac9fcfb241984d791c1d211a434901639,Designing Templates for Eliciting Commonsense Knowledge from Pretrained Sequence-to-Sequence Models,"While internalized ‚Äúimplicit knowledge‚Äù in pretrained transformers has led to fruitful progress in many natural language understanding tasks, how to most effectively elicit such knowledge remains an open question. Based on the text-to-text transfer transformer (T5) model, this work explores a template-based approach to extract implicit knowledge for commonsense reasoning on multiple-choice (MC) question answering tasks. Experiments on three representative MC datasets show the surprisingly good performance of our simple template, coupled with a logit normalization technique for disambiguation. Furthermore, we verify that our proposed template can be easily extended to other MC tasks with contexts such as supporting facts in open-book question answering settings. Starting from the MC task, this work initiates further research to find generic natural language templates that can effectively leverage stored knowledge in pretrained models.",International Conference on Computational Linguistics,2020.0,17,5,"[{'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7075a35256a595b1a4bc5a7ab02c82f570a28a76,https://www.semanticscholar.org/paper/7075a35256a595b1a4bc5a7ab02c82f570a28a76,From MAXSCORE to Block-Max Wand: The Story of How Lucene Significantly Improved Query Evaluation Performance,,European Conference on Information Retrieval,2020.0,21,16,"[{'authorId': '1630471753', 'name': 'Adrien Grand'}, {'authorId': '69562841', 'name': 'R. Muir'}, {'authorId': '1630493434', 'name': 'Jim Ferenczi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
79f14789a2cedb128f3bbc3f484927d30c97e156,https://www.semanticscholar.org/paper/79f14789a2cedb128f3bbc3f484927d30c97e156,"We Could, but Should We?: Ethical Considerations for Providing Access to GeoCities and Other Historical Digital Collections","We live in an era in which the ways that we can make sense of our past are evolving as more artifacts from that past become digital. At the same time, the responsibilities of traditional gatekeepers who have negotiated the ethics of historical data collection and use, such as librarians and archivists, are increasingly being sidelined by the system builders who decide whether and how to provide access to historical digital collections, often without sufficient reflection on the ethical issues at hand. It is our aim to better prepare system builders to grapple with these issues. This paper focuses discussions around one such digital collection from the dawn of the web, asking what sorts of analyses can and should be conducted on archival copies of the GeoCities web hosting platform that dates to 1994.",Conference on Human Information Interaction and Retrieval,2020.0,58,10,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '1737250', 'name': 'Douglas W. Oard'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '3214594', 'name': 'Katie Shilton'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
821f9468f885570d376317fe0a5d471b5d019c31,https://www.semanticscholar.org/paper/821f9468f885570d376317fe0a5d471b5d019c31,TREC 2020 Notebook: CAsT Track,"This notebook describes our participation (h2oloo) in TREC CAsT 2020. We Ô¨Årst illustrate our multi-stage pipeline for conversational search: sequence-to-sequence query reformulation followed by an ad hoc text ranking pipeline; then, detail our proposed method for canonical response entry. Empirically, we show that our method effectively reformulates conversational queries considering both historical user utterances and system responses, yielding Ô¨Ånal ranking result 0.363 and 0.494 in terms of MAP and NDCG@3 respectively, which is our best submission to CAsT 2020.",Text Retrieval Conference,2020.0,13,1,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '2109723027', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8369578a29e57724c8bdb983d63ad9a3ae983223,https://www.semanticscholar.org/paper/8369578a29e57724c8bdb983d63ad9a3ae983223,To Paraphrase or Not To Paraphrase: User-Controllable Selective Paraphrase Generation,"In this article, we propose a paraphrase generation technique to keep the key phrases in source sentences during paraphrasing. We also develop a model called TAGPA with such technique, which has multiple pre-configured or trainable key phrase detector and a paraphrase generator. The paraphrase generator aims to keep the key phrases and increase the diversity of the paraphrased sentences. The key phrases can be entities provided by our user, like company names, people's names, domain-specific terminologies, etc., or can be learned from a given dataset.",arXiv.org,2020.0,13,0,"[{'authorId': '48985313', 'name': 'Mohan Zhang'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '1924612088', 'name': 'Zhengkai Tu'}, {'authorId': '101028678', 'name': 'Zihang Fu'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
83f915d30720f1aa1c6f6a4342d7f9e52add756e,https://www.semanticscholar.org/paper/83f915d30720f1aa1c6f6a4342d7f9e52add756e,Distilling Dense Representations for Ranking using Tightly-Coupled Teachers,"We present an approach to ranking with dense representations that applies knowledge distillation to improve the recently proposed late-interaction ColBERT model. Specifically, we distill the knowledge from ColBERT's expressive MaxSim operator for computing relevance scores into a simple dot product, thus enabling single-step ANN search. Our key insight is that during distillation, tight coupling between the teacher model and the student model enables more flexible distillation strategies and yields better learned representations. We empirically show that our approach improves query latency and greatly reduces the onerous storage requirements of ColBERT, while only making modest sacrifices in terms of effectiveness. By combining our dense representations with sparse representations derived from document expansion, we are able to approach the effectiveness of a standard cross-encoder reranker using BERT that is orders of magnitude slower.",arXiv.org,2020.0,28,100,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
87bfc3de39c4beab43744bbca73da0f5c88ce126,https://www.semanticscholar.org/paper/87bfc3de39c4beab43744bbca73da0f5c88ce126,Supporting Interoperability Between Open-Source Search Engines with the Common Index File Format,"There exists a natural tension between encouraging a diverse ecosystem of open-source search engines and supporting fair, replicable comparisons across those systems. To balance these two goals, we examine two approaches to providing interoperability between the inverted indexes of several systems. The first takes advantage of internal abstractions around index structures and building wrappers that allow one system to directly read the indexes of another. The second involves sharing indexes across systems via a data exchange specification that we have developed, called the Common Index File Format (CIFF). We demonstrate the first approach with the Java systems Anserini and Terrier, and the second approach with Anserini, JASSv2, OldDog, PISA, and Terrier. Together, these systems provide a wide range of implementations and features, with different research goals. Overall, we recommend CIFF as a low-effort approach to support independent innovation while enabling the types of fair evaluations that are critical for driving the field forward.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2020.0,16,30,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '1591687213', 'name': 'Chris Kamphuis'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '39662889', 'name': 'Antonio Mallia'}, {'authorId': '66497215', 'name': 'Michal Siedlaczek'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
8c1ca95db7eb4cb243587d45b9aa8418d7b0a735,https://www.semanticscholar.org/paper/8c1ca95db7eb4cb243587d45b9aa8418d7b0a735,SimClusters: Community-Based Representations for Heterogeneous Recommendations at Twitter,"Personalized recommendation products at Twitter target a multitude of heterogeneous items: Tweets, Events, Topics, Hashtags, and users. Each of these targets varies in their cardinality (which affects the scale of the problem) and their ""shelf life'' (which constrains the latency of generating the recommendations). Although Twitter has built a variety of recommendation systems before dating back a decade, solutions to the broader problem were mostly tackled piecemeal. In this paper, we present SimClusters, a general-purpose representation layer based on overlapping communities into which users as well as heterogeneous content can be captured as sparse, interpretable vectors to support a multitude of recommendation tasks. We propose a novel algorithm for community discovery based on Metropolis-Hastings sampling, which is both more accurate and significantly faster than off-the-shelf alternatives. SimClusters scales to networks with billions of users and has been effective across a variety of deployed applications at Twitter.",Knowledge Discovery and Data Mining,2020.0,43,30,"[{'authorId': '2417199', 'name': 'Venu Satuluri'}, {'authorId': '2145046275', 'name': 'Yao Wu'}, {'authorId': '2496226', 'name': 'Xun Zheng'}, {'authorId': '1894899231', 'name': 'Yilei Qian'}, {'authorId': '1900391601', 'name': 'Brian Wichers'}, {'authorId': '2279233', 'name': 'Qieyun Dai'}, {'authorId': '1897056734', 'name': 'Gui Ming Tang'}, {'authorId': '2116635559', 'name': 'Jerry Jiang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8ffa054a33c19812d78b29c411f0661bed1ed3ee,https://www.semanticscholar.org/paper/8ffa054a33c19812d78b29c411f0661bed1ed3ee,Flexible IR Pipelines with Capreolus,"While a number of recent open-source toolkits for training and using neural information retrieval models have greatly simplified experiments with neural reranking methods, they essentially hard code a ""search-then-rerank'' experimental pipeline. These pipelines consist of an efficient first-stage ranking method, like BM25, followed by a neural reranking method. Deviations from this setup often require hacks; some improvements, like adding a second reranking step that uses a more expensive neural method, are infeasible without major code changes. In order to improve the flexibility of such toolkits, we propose implementing experimental pipelines as dependency graphs of functional ""IR primitives,'' which we call modules, that can be used and combined as needed. For example, a neural IR pipeline may rerank results from a Searcher module that efficiently retrieves results from an Index module that it depends on. In turn, the Index depends on a Collection to index, which is provided by the pipeline. This Searcher module is self-contained: the pipeline does not need to know about or interact with the Index of the Searcher, which is transparently shared among Searcher modules when possible (e.g., a BM25 and a QL Searcher might share the same Index). Similarly, a Reranker module might depend on a Trainer (e.g., Tensorflow), feature Extractor, Tokenizer, etc. In both cases, the pipeline needs to interact only with the Reranker or Searcher directly; the complexity of their dependencies is hidden and intelligently managed. We rewrite the Capreolus toolkit to take this approach and demonstrate its use. %in a series of code examples and experiments.",International Conference on Information and Knowledge Management,2020.0,29,13,"[{'authorId': '144115896', 'name': 'Andrew Yates'}, {'authorId': '2117356', 'name': 'Kevin Martin Jose'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
90a1491ac32e732c93773354e4e665794ed4d490,https://www.semanticscholar.org/paper/90a1491ac32e732c93773354e4e665794ed4d490,DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference,"Large-scale pre-trained language models such as BERT have brought significant improvements to NLP applications. However, they are also notorious for being slow in inference, which makes them difficult to deploy in real-time applications. We propose a simple but effective method, DeeBERT, to accelerate BERT inference. Our approach allows samples to exit earlier without passing through the entire model. Experiments show that DeeBERT is able to save up to ~40% inference time with minimal degradation in model quality. Further analyses show different behaviors in the BERT transformer layers and also reveal their redundancy. Our work provides new ideas to efficiently apply deep transformer-based models to downstream tasks. Code is available at https://github.com/castorini/DeeBERT.",Annual Meeting of the Association for Computational Linguistics,2020.0,21,270,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a529449b65f307bb216e081f31b0746ede2ab8e6,https://www.semanticscholar.org/paper/a529449b65f307bb216e081f31b0746ede2ab8e6,Building community at distance: a datathon during COVID-19,"This paper aims to use the experience of an in-person event that was forced to go virtual in the wake of COVID-19 as an entryway into a discussion on the broader implications around transitioning events online. It gives both practical recommendation to event organizers as well as broader reflections on the role of digital libraries during the COVID-19 pandemic and beyond.,The authors draw on their personal experiences with the datathon, as well as a comprehensive review of literature. The authors provide a candid assessment of what approaches worked and which ones did not.,A series of best practices are provided, including factors for assessing whether an event can be run online; the mixture of synchronous versus asynchronous content; and important technical questions around delivery. Focusing on a detailed case study of the shift of the physical team-building exercise, the authors note how cloud-based platforms were able to successfully assemble teams and jumpstart online collaboration. The existing decision to use cloud-based infrastructure facilitated the event‚Äôs transition as well. The authors use these examples to provide some broader insights on meaningful content delivery during the COVID-19 pandemic.,Moving an event online during a novel pandemic is part of a broader shift within the digital libraries‚Äô community. This paper thus provides a useful professional resource for others exploring this shift, as well as those exploring new program delivery in the post-pandemic period (both due to an emphasis on climate reduction as well as reduced travel budgets in a potential period of financial austerity).",Digital Library Perspectives,2020.0,47,15,"[{'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ad84471593d07525bc78099eed0643f65e142df6,https://www.semanticscholar.org/paper/ad84471593d07525bc78099eed0643f65e142df6,"The Archives Unleashed Project: Technology, Process, and Community to Improve Scholarly Access to Web Archives","The Archives Unleashed project aims to improve scholarly access to web archives through a multi-pronged strategy involving tool creation, process modeling, and community building---all proceeding concurrently in mutually-reinforcing efforts. As we near the end of our initially-conceived three-year project, we report on our progress and share lessons learned along the way. The main contribution articulated in this paper is a process model that decomposes scholarly inquiries into four main activities: filter, extract, aggregate, and visualize. Based on the insight that these activities can be disaggregated across time, space, and tools, it is possible to generate ""derivative products"", using our Archives Unleashed Toolkit, that serve as useful starting points for scholarly inquiry. Scholars can download these products from the Archives Unleashed Cloud and manipulate them just like any other dataset, thus providing access to web archives without requiring any specialized knowledge. Over the past few years, our platform has processed over a thousand different collections from over two hundred users, totaling around 300 terabytes of web archives.",ACM/IEEE Joint Conference on Digital Libraries,2020.0,22,25,"[{'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}]"
b4bda0f201446b77548794724bd8238a42c7e6c5,https://www.semanticscholar.org/paper/b4bda0f201446b77548794724bd8238a42c7e6c5,Content-Based Exploration of Archival Images Using Neural Networks,"We present DAIRE (Deep Archival Image Retrieval Engine), an image exploration tool based on latent representations derived from neural networks, which allows scholars to ""query"" using an image of interest to rapidly find related images within a web archive. This work represents one part of our broader effort to move away from text-centric analyses of web archives and scholarly tools that are direct reflections of methods for accessing the live web. This short piece describes the implementation of our system and a case study on a subset of the GeoCities web archive.",ACM/IEEE Joint Conference on Digital Libraries,2020.0,14,2,"[{'authorId': '1845854832', 'name': 'Tobi Adewoye'}, {'authorId': '2118233916', 'name': 'Xiao Han'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
b4fa5accb3f83ab398772a913b8aa443c34e4000,https://www.semanticscholar.org/paper/b4fa5accb3f83ab398772a913b8aa443c34e4000,Cydex: Neural Search Infrastructure for the Scholarly Literature,"Cydex is a platform that provides neural search infrastructure for domain-specific scholarly literature. The platform represents an abstraction of Covidex, our recently developed full-stack open-source search engine for the COVID-19 Open Research Dataset (CORD-19) from AI2. While Covidex takes advantage of the latest best practices for keyword search using the popular Lucene search library as well as state-of-the-art neural ranking models using T5, parts of the system were hard coded to only work with CORD-19. This paper describes our efforts to generalize Covidex into Cydex, which can be applied to scholarly literature in different domains. By decoupling corpus-specific configurations from the frontend implementation, we are able to demonstrate the generality of Cydex on two very different corpora: the ACL Anthology and a collection of hydrology abstracts. Our platform is entirely open source and available at cydex.ai.",SDP,2020.0,22,3,"[{'authorId': '2066433162', 'name': 'S. Ding'}, {'authorId': '6549913', 'name': 'Edwin Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ba29b10f20168939402f0f17119a1f6c488d1639,https://www.semanticscholar.org/paper/ba29b10f20168939402f0f17119a1f6c488d1639,Rapidly Deploying a Neural Search Engine for the COVID-19 Open Research Dataset,The Neural Covidex is a search engine that exploits the latest neural ranking architectures to provide information access to the COVID-19 Open Research Dataset (CORD-19) curated by the Allen Institute for AI. It exists as part of a suite of tools we have developed to help domain experts tackle the ongoing global pandemic. We hope that improved information access capabilities to the scientific literature can inform evidence-based decision making and insight generation.,NLPCOVID19,2020.0,34,57,"[{'authorId': '6549913', 'name': 'Edwin Zhang'}, {'authorId': '1573914472', 'name': 'Nikhil Gupta'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c0a5be99a0ea38d1adbffb6110ce3a1d227e13f7,https://www.semanticscholar.org/paper/c0a5be99a0ea38d1adbffb6110ce3a1d227e13f7,Query Reformulation using Query History for Passage Retrieval in Conversational Search,"Passage retrieval in a conversational context is essential for many downstream applications; it is however extremely challenging due to limited data resources. To address this problem, we present an effective multi-stage pipeline for passage ranking in conversational search that integrates a widely-used IR system with a conversational query reformulation module. Along these lines, we propose two simple yet effective query reformulation approaches: historical query expansion (HQE) and neural transfer reformulation (NTR). Whereas HQE applies query expansion, a traditional IR query reformulation technique, NTR transfers human knowledge of conversational query understanding to a neural query reformulation model. The proposed HQE method was the top-performing submission of automatic systems in CAsT Track at TREC 2019. Building on this, our NTR approach improves an additional 18% over that best entry in terms of NDCG@3. We further analyze the distinct behaviors of the two approaches, and show that fusing their output reduces the performance gap (measured in NDCG@3) between the manually-rewritten and automatically-generated queries to 4 from 22 points when compared with the best CAsT submission.",arXiv.org,2020.0,62,23,"[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d20025487e31cbbf186d1a4e902fc55159a82a9b,https://www.semanticscholar.org/paper/d20025487e31cbbf186d1a4e902fc55159a82a9b,Approximate Nearest Neighbor Search and Lightweight Dense Vector Reranking in Multi-Stage Retrieval Architectures,"In the context of a multi-stage retrieval architecture, we explore candidate generation based on approximate nearest neighbor (ANN) search and lightweight reranking based on dense vector representations. These results serve as input to slower but more accurate rerankers such as those based on transformers. Our goal is to characterize the effectiveness-efficiency tradeoff space in this context. We find that, on sentence-length segments of text, ANN techniques coupled with dense vector reranking dominate approaches based on inverted indexes, and thus our proposed design should be preferred. For paragraph-length segments, ANN-based and index-based techniques share the Pareto frontier, which means that the choice of alternatives depends on the desired operating point.",International Conference on the Theory of Information Retrieval,2020.0,22,10,"[{'authorId': '1924612088', 'name': 'Zhengkai Tu'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '101028678', 'name': 'Zihang Fu'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d80b23150de329e6434a436edc6ea4378bd0b658,https://www.semanticscholar.org/paper/d80b23150de329e6434a436edc6ea4378bd0b658,Showing Your Work Doesn‚Äôt Always Work,"In natural language processing, a recently popular line of work explores how to best report the experimental results of neural networks. One exemplar publication, titled ‚ÄúShow Your Work: Improved Reporting of Experimental Results‚Äù (Dodge et al., 2019), advocates for reporting the expected validation effectiveness of the best-tuned model, with respect to the computational budget. In the present work, we critically examine this paper. As far as statistical generalizability is concerned, we find unspoken pitfalls and caveats with this approach. We analytically show that their estimator is biased and uses error-prone assumptions. We find that the estimator favors negative errors and yields poor bootstrapped confidence intervals. We derive an unbiased alternative and bolster our claims with empirical evidence from statistical simulation. Our codebase is at https://github.com/castorini/meanmax.",Annual Meeting of the Association for Computational Linguistics,2020.0,18,5,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '2110789748', 'name': 'Xinyu Liu'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e3e36944102c9baee49dfec397fc0e4bb63a7c77,https://www.semanticscholar.org/paper/e3e36944102c9baee49dfec397fc0e4bb63a7c77,Covidex: Neural Ranking Models and Keyword Search Infrastructure for the COVID-19 Open Research Dataset,"We present Covidex, a search engine that exploits the latest neural ranking models to provide information access to the COVID-19 Open Research Dataset curated by the Allen Institute for AI. Our system has been online and serving users since late March 2020. The Covidex is the user application component of our three-pronged strategy to develop technologies for helping domain experts tackle the ongoing global pandemic. In addition, we provide robust and easy-to-use keyword search infrastructure that exploits mature fusion-based methods as well as standalone neural ranking models that can be incorporated into other applications. These techniques have been evaluated in the multi-round TREC-COVID challenge: Our infrastructure and baselines have been adopted by many participants, including some of the best systems. In round 3, we submitted the highest-scoring run that took advantage of previous training data and the second-highest fully automatic run. In rounds 4 and 5, we submitted the highest-scoring fully automatic runs.",SDP,2020.0,43,58,"[{'authorId': '6549913', 'name': 'Edwin Zhang'}, {'authorId': '1573914472', 'name': 'Nikhil Gupta'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2118233916', 'name': 'Xiao Han'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '49245966', 'name': 'Kuang Lu'}, {'authorId': '1591125925', 'name': 'Yue Zhang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145344526', 'name': 'Hui Fang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e439ff2a56b26e8839d894c1d82967b5a8816939,https://www.semanticscholar.org/paper/e439ff2a56b26e8839d894c1d82967b5a8816939,Latte-Mix: Measuring Sentence Semantic Similarity with Latent Categorical Mixtures,"Measuring sentence semantic similarity using pre-trained language models such as BERT generally yields unsatisfactory zero-shot performance, and one main reason is ineffective token aggregation methods such as mean pooling. In this paper, we demonstrate under a Bayesian framework that distance between primitive statistics such as the mean of word embeddings are fundamentally flawed for capturing sentence-level semantic similarity. To remedy this issue, we propose to learn a categorical variational autoencoder (VAE) based on off-the-shelf pre-trained language models. We theoretically prove that measuring the distance between the latent categorical mixtures, namely Latte-Mix, can better reflect the true sentence semantic similarity. In addition, our Bayesian framework provides explanations for why models finetuned on labelled sentence pairs have better zero-shot performance. We also empirically demonstrate that these finetuned models could be further improved by Latte-Mix. Our method not only yields the state-of-the-art zero-shot performance on semantic similarity datasets such as STS, but also enjoy the benefits of fast training and having small memory footprints.",arXiv.org,2020.0,66,0,"[{'authorId': '47629325', 'name': 'Minghan Li'}, {'authorId': '2152224577', 'name': 'He Bai'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e4cb6bfe88a8ed729d34d5a9ff74a992932b70ce,https://www.semanticscholar.org/paper/e4cb6bfe88a8ed729d34d5a9ff74a992932b70ce,Scientific Claim Verification with VerT5erini,"This work describes the adaptation of a pretrained sequence-to-sequence model to the task of scientific claim verification in the biomedical domain. We propose a system called VerT5erini that exploits T5 for abstract retrieval, sentence selection, and label prediction, which are three critical sub-tasks of claim verification. We evaluate our pipeline on SciFACT, a newly curated dataset that requires models to not just predict the veracity of claims but also provide relevant sentences from a corpus of scientific literature that support the prediction. Empirically, our system outperforms a strong baseline in each of the three sub-tasks. We further show VerT5erini‚Äôs ability to generalize to two new datasets of COVID-19 claims using evidence from the CORD-19 corpus.",International Workshop on Health Text Mining and Information Analysis,2020.0,32,48,"[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ea2690304b0f08cf298247bcc0d341e2a2981299,https://www.semanticscholar.org/paper/ea2690304b0f08cf298247bcc0d341e2a2981299,"Howl: A Deployed, Open-Source Wake Word Detection System","We describe Howl, an open-source wake word detection toolkit with native support for open speech datasets such as Mozilla Common Voice (MCV) and Google Speech Commands (GSC). We report benchmark results of various models supported by our toolkit on GSC and our own freely available wake word detection dataset, built from MCV. One of our models is deployed in Firefox Voice, a plugin enabling speech interactivity for the Firefox web browser. Howl represents, to the best of our knowledge, the first fully productionized, open-source wake word detection toolkit with a web browser deployment target. Our codebase is at howl.ai.",NLPOSS,2020.0,20,14,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '2082381757', 'name': 'Afsaneh Razi'}, {'authorId': '2828108', 'name': 'Julia Cambre'}, {'authorId': '102860006', 'name': 'Ian Bicking'}, {'authorId': '51921005', 'name': 'Jofish Kaye'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f6e0164466e827112fd415afdc28ddf8e0eb1ba3,https://www.semanticscholar.org/paper/f6e0164466e827112fd415afdc28ddf8e0eb1ba3,Document Ranking with a Pretrained Sequence-to-Sequence Model,"This work proposes the use of a pretrained sequence-to-sequence model for document ranking. Our approach is fundamentally different from a commonly adopted classification-based formulation based on encoder-only pretrained transformer architectures such as BERT. We show how a sequence-to-sequence model can be trained to generate relevance labels as ‚Äútarget tokens‚Äù, and how the underlying logits of these target tokens can be interpreted as relevance probabilities for ranking. Experimental results on the MS MARCO passage ranking task show that our ranking approach is superior to strong encoder-only models. On three other document retrieval test collections, we demonstrate a zero-shot transfer-based approach that outperforms previous state-of-the-art models requiring in-domain cross-validation. Furthermore, we find that our approach significantly outperforms an encoder-only architecture in a data-poor setting. We investigate this observation in more detail by varying target tokens to probe the model‚Äôs use of latent knowledge. Surprisingly, we find that the choice of target tokens impacts effectiveness, even for words that are closely related semantically. This finding sheds some light on why our sequence-to-sequence formulation for document ranking is effective. Code and models are available at pygaggle.ai.",Findings,2020.0,36,355,"[{'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '2197574931', 'name': 'Zhiying Jiang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f84bb7872052b0cc094d0750501635b466268bea,https://www.semanticscholar.org/paper/f84bb7872052b0cc094d0750501635b466268bea,Early Exiting BERT for Efficient Document Ranking,"Pre-trained language models such as BERT have shown their effectiveness in various tasks. Despite their power, they are known to be computationally intensive, which hinders real-world applications. In this paper, we introduce early exiting BERT for document ranking. With a slight modification, BERT becomes a model with multiple output paths, and each inference sample can exit early from these paths. In this way, computation can be effectively allocated among samples, and overall system latency is significantly reduced while the original quality is maintained. Our experiments on two document ranking datasets demonstrate up to 2.5x inference speedup with minimal quality degradation. The source code of our implementation can be found at https://github.com/castorini/earlyexiting-monobert.",SUSTAINLP,2020.0,23,39,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fb654cdfebd804a5485ef774da04537bf5c85536,https://www.semanticscholar.org/paper/fb654cdfebd804a5485ef774da04537bf5c85536,Cross-Lingual Training of Neural Models for Document Ranking,"We tackle the challenge of cross-lingual training of neural document ranking models for mono-lingual retrieval, specifically leveraging relevance judgments in English to improve search in non-English languages. Our work successfully applies multi-lingual BERT (mBERT) to document ranking and additionally compares against a number of alternatives: translating the training data, translating documents, multi-stage hybrids, and ensembles. Experiments on test collections in six different languages from diverse language families reveal many interesting findings: model-based relevance transfer using mBERT can significantly improve search quality in (non-English) mono-lingual retrieval, but other ‚Äúlow resource‚Äù approaches are competitive as well.",Findings,2020.0,17,19,"[{'authorId': '2055357849', 'name': 'Peng Shi'}, {'authorId': '37374479', 'name': 'Richard He Bai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fee8b4a4d59245d7d6cb1dc6b2853fee5324a701,https://www.semanticscholar.org/paper/fee8b4a4d59245d7d6cb1dc6b2853fee5324a701,Update Delivery Mechanisms for Prospective Information Needs: A Reproducibility Study,"Real-time summarization systems monitor continuous streams of documents with the goal of delivering relevant, novel, and timely updates to users. These updates can either be sent to users' mobile devices as push notifications or be silently deposited in an inbox to be consumed - the important difference is whether the user is interrupted by the delivery. Previously, a two-year study examining user attention under these different mechanisms revealed interesting findings about users' information consumption behavior, but the conclusions were marred by a few methodological shortcomings. We present a reproducibility study that follows the same design as the original evaluation, but corrects its flaws. We find that most conclusions from the original study are confirmed, although there are some surprising differences as well. Overall, the magnitude of the observed effects are not as strong as in the original study.",Conference on Human Information Interaction and Retrieval,2020.0,16,0,"[{'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '2108384019', 'name': 'Yinan Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
04044b5be5d99dea74289f17f30f98cf4918c069,https://www.semanticscholar.org/paper/04044b5be5d99dea74289f17f30f98cf4918c069,"Anserini at TREC 2018 : CENTRE , Common Core , and News Tracks",,,2019.0,4,10,"[{'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
0563230acc891263057e28bf4df21582c81ddfa8,https://www.semanticscholar.org/paper/0563230acc891263057e28bf4df21582c81ddfa8,Incorporating Contextual and Syntactic Structures Improves Semantic Similarity Modeling,"Semantic similarity modeling is central to many NLP problems such as natural language inference and question answering. Syntactic structures interact closely with semantics in learning compositional representations and alleviating long-range dependency issues. How-ever, such structure priors have not been well exploited in previous work for semantic mod-eling. To examine their effectiveness, we start with the Pairwise Word Interaction Model, one of the best models according to a recent reproducibility study, then introduce components for modeling context and structure using multi-layer BiLSTMs and TreeLSTMs. In addition, we introduce residual connections to the deep convolutional neural network component of the model. Extensive evaluations on eight benchmark datasets show that incorporating structural information contributes to consistent improvements over strong baselines.",Conference on Empirical Methods in Natural Language Processing,2019.0,29,11,"[{'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0f1a7429d835d742906fbd3d68282ba6aac16b9d,https://www.semanticscholar.org/paper/0f1a7429d835d742906fbd3d68282ba6aac16b9d,Yelling at Your TV: An Analysis of Speech Recognition Errors and Subsequent User Behavior on Entertainment Systems,"Millions of consumers issue voice queries through television-based entertainment systems such as the Comcast X1, the Amazon Fire TV, and Roku TV. Automatic speech recognition (ASR) systems are responsible for transcribing these voice queries into text to feed downstream natural language understanding modules. However, ASR is far from perfect, often producing incorrect transcriptions and forcing users to take corrective action. To better understand their impact on sessions, this paper characterizes speech recognition errors as well as subsequent user responses. We provide both quantitative and qualitative analyses, examining the acoustic as well as lexical attributes of the utterances. This work represents, to our knowledge, the first analysis of speech recognition errors from real users on a widely-deployed entertainment system.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,15,10,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
142cd4a2a1bf744836b2143d795742a3f5e33bae,https://www.semanticscholar.org/paper/142cd4a2a1bf744836b2143d795742a3f5e33bae,Cross-Domain Modeling of Sentence-Level Evidence for Document Retrieval,"This paper applies BERT to ad hoc document retrieval on news articles, which requires addressing two challenges: relevance judgments in existing test collections are typically provided only at the document level, and documents often exceed the length that BERT was designed to handle. Our solution is to aggregate sentence-level evidence to rank documents. Furthermore, we are able to leverage passage-level relevance judgments fortuitously available in other domains to fine-tune BERT models that are able to capture cross-domain notions of relevance, and can be directly used for ranking news articles. Our simple neural ranking models achieve state-of-the-art effectiveness on three standard test collections.",Conference on Empirical Methods in Natural Language Processing,2019.0,34,144,"[{'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1a9954d86466a7e4de6f98ddee452ceb50e15d86,https://www.semanticscholar.org/paper/1a9954d86466a7e4de6f98ddee452ceb50e15d86,DocBERT: BERT for Document Classification,"We present, to our knowledge, the first application of BERT to document classification. A few characteristics of the task might lead one to think that BERT is not the most appropriate model: syntactic structures matter less for content categories, documents can often be longer than typical BERT input, and documents often have multiple labels. Nevertheless, we show that a straightforward classification model using BERT is able to achieve the state of the art across four popular datasets. To address the computational expense associated with BERT inference, we distill knowledge from BERT-large to small bidirectional LSTMs, reaching BERT-base parity on multiple datasets using 30x fewer parameters. The primary contribution of our paper is improved baselines that can provide the foundation for future work.",arXiv.org,2019.0,24,267,"[{'authorId': '51941200', 'name': 'Ashutosh Adhikari'}, {'authorId': '46253949', 'name': 'Achyudh Ram'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1ea3380472e9b0f1b816b28e87059e279e1fd81b,https://www.semanticscholar.org/paper/1ea3380472e9b0f1b816b28e87059e279e1fd81b,Challenges and Opportunities in Understanding Spoken Queries Directed at Modern Entertainment Platforms,"Modern in-home entertainment platforms---representing the evolution of the humble television of yesteryear---are packed with features and content: they offer a dizzying array of programs spanning hundreds of channels as well as a catalog of on-demand programs offering tens of thousands of options. Furthermore, the entertainment platform may serve as an in-home hub, providing capabilities ranging from playing music to controlling the home security system. At a high level, our goal is to provide natural speech-based access to these myriad features as an alternative to physical button entry on a remote control.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,13,0,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1fef7197b2e57207e1b2daf4d66dbd500adc8603,https://www.semanticscholar.org/paper/1fef7197b2e57207e1b2daf4d66dbd500adc8603,Improved Baselines for Document Classification Using BERT,,,2019.0,0,0,"[{'authorId': '51941200', 'name': 'Ashutosh Adhikari'}, {'authorId': '46253949', 'name': 'Achyudh Ram'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
22d31d29606ca7c9617f249408f6b1d70c586862,https://www.semanticscholar.org/paper/22d31d29606ca7c9617f249408f6b1d70c586862,The Neural Hype and Comparisons Against Weak Baselines,"Recently, the machine learning community paused in a moment of self-reflection. In a widelydiscussed paper at ICLR 2018, Sculley et al. [13] wrote: ""We observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole."" Their primary complaint is the development of a ""research and publication culture that emphasizes wins"" (emphasis in original), which typically means ""demonstrating that a new method beats previous methods on a given task or benchmark"". An apt description might be ""leaderboard chasing""-and for many vision and NLP tasks, this isn't a metaphor. There are literally centralized leaderboards1 that track incremental progress, down to the fifth decimal point, some persisting over years, accumulating dozens of entries. Sculley et al. remind us that ""the goal of science is not wins, but knowledge"". The structure of the scientific enterprise today (pressure to publish, pace of progress, etc.) means that ""winning"" and ""doing good science"" are often not fully aligned. To wit, they cite a number of papers showing that recent advances in neural networks could very well be attributed to mundane issues like better hyperparameter optimization. Many results can't be reproduced, and some observed improvements might just be noise.",SIGIR Forum,2019.0,17,129,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
24cbc48bb0cb1c275fb88e50965dfe1af57fd784,https://www.semanticscholar.org/paper/24cbc48bb0cb1c275fb88e50965dfe1af57fd784,"Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data","A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures. In particular, several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks. In this work, we show that this is also the case for text generation from structured and unstructured data. We consider neural table-to-text generation and neural question generation (NQG) tasks for text generation from structured and unstructured data, respectively. Table-to-text generation aims to generate a description based on a given table, and NQG is the task of generating a question from a given passage where the generated question can be answered by a certain sub-span of the passage using NN models. Experimental results demonstrate that a basic attention-based seq2seq model trained with the exponential moving average technique achieves the state of the art in both tasks. Code is available at https://github.com/h-shahidi/2birds-gen.",Annual Meeting of the Association for Computational Linguistics,2019.0,43,14,"[{'authorId': '1387982258', 'name': 'H. Shahidi'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2fe7dba5a58aee5156594b4d78634ecd6c7dcabd,https://www.semanticscholar.org/paper/2fe7dba5a58aee5156594b4d78634ecd6c7dcabd,End-to-End Open-Domain Question Answering with BERTserini,"We demonstrate an end-to-end question answering system that integrates BERT with the open-source Anserini information retrieval toolkit. In contrast to most question answering and reading comprehension models today, which operate over small amounts of input text, our system integrates best practices from IR with a BERT-based reader to identify answers from a large corpus of Wikipedia articles in an end-to-end fashion. We report large improvements over previous results on a standard benchmark test collection, showing that fine-tuning pretrained BERT with SQuAD is sufficient to achieve high accuracy in identifying answer spans.",North American Chapter of the Association for Computational Linguistics,2019.0,21,448,"[{'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '2054897807', 'name': 'Aileen Lin'}, {'authorId': '2155446753', 'name': 'Xingyu Li'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
31fc159be43811170b9906c5809c1583e9778151,https://www.semanticscholar.org/paper/31fc159be43811170b9906c5809c1583e9778151,Solr Integration in the Anserini Information Retrieval Toolkit,"Anserini is an open-source information retrieval toolkit built around Lucene to facilitate replicable research. In this demonstration, we examine different architectures for Solr integration in order to address two current limitations of the system: the lack of an interactive search interface and support for distributed retrieval. Two architectures are explored: In the first approach, Anserini is used as a frontend to index directly into a running Solr instance. In the second approach, Lucene indexes built directly with Anserini can be copied into a Solr installation and placed under its management. We discuss the tradeoffs associated with each architecture and report the results of a performance evaluation comparing indexing throughput. To illustrate the additional capabilities enabled by Anserini/Solr integration, we present a search interface built using the open-source Blacklight discovery interface.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,8,5,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '2951862', 'name': 'Toke Eskildsen'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
361574d708f137a06d8f889b5531bd5383fa8aea,https://www.semanticscholar.org/paper/361574d708f137a06d8f889b5531bd5383fa8aea,Scalable Content-Based Analysis of Images in Web Archives with TensorFlow and the Archives Unleashed Toolkit,"We demonstrate the integration of the Archives Unleashed Toolkit, a scalable platform for exploring web archives, with Google's TensorFlow deep learning toolkit to provide scholars with content-based image analysis capabilities. By applying pretrained deep neural networks for object detection, we are able to extract images of common objects from a 4TB web archive of GeoCities, which we then compile into browsable collages. This case study illustrates the types of interesting analyses enabled by combining big data and deep learning capabilities.",ACM/IEEE Joint Conference on Digital Libraries,2019.0,6,4,"[{'authorId': '22171670', 'name': 'Hsiu-Wei Yang'}, {'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3a0b18510d20475f236edcae97da64a8039d2439,https://www.semanticscholar.org/paper/3a0b18510d20475f236edcae97da64a8039d2439,Query and Answer Expansion from Conversation History,"In this paper, we present our methods, experimental analysis, and final submissions for the Conversational Assistance Track (CAsT) at TREC 2019. In addition to language understanding, extracting knowledge from historical dialogues (e.g., previous queries, searching results) is a key to the conversational IR task. However, limited annotated data in the CAsT task makes machine learning or other data-driven approaches infeasible. Along this line, we propose two ad hoc and intuitive approaches: Historical Query Expansion and Historical Answer Expansion, to improve the performance of the conversational IR system with limited training data. Our empirical result on the CAsT training set shows that the proposed meth-ods significantly improve the quality of conversational search in terms of retrieval (recall@1000: 0 . 774 ‚Üí 0 . 844) and ranking (mAP: 0 . 187 ‚Üí 0 . 197) compared to our strong baseline. As a result, our submitted entries outperform the median performance of all the 21 teams.",Text Retrieval Conference,2019.0,11,27,"[{'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}]"
3f2514bf6bf1ca25112be036343e3cd5c3c2115b,https://www.semanticscholar.org/paper/3f2514bf6bf1ca25112be036343e3cd5c3c2115b,MKD: a Multi-Task Knowledge Distillation Approach for Pretrained Language Models,"Pretrained language models have led to significant performance gains in many NLP tasks. However, the intensive computing resources to train such models remain an issue. Knowledge distillation alleviates this problem by learning a light-weight student model. So far the distillation approaches are all task-specific. In this paper, we explore knowledge distillation under the multi-task learning setting. The student is jointly distilled across different tasks. It acquires more general representation capacity through multi-tasking distillation and can be further fine-tuned to improve the model in the target domain. Unlike other BERT distillation methods which specifically designed for Transformer-based architectures, we provide a general learning framework. Our approach is model agnostic and can be easily applied on different future teacher model architectures. We evaluate our approach on a Transformer-based and LSTM based student model. Compared to a strong, similarly LSTM-based approach, we achieve better quality under the same computational constraints. Compared to the present state of the art, we reach comparable results with much faster inference speed.",,2019.0,46,20,"[{'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '46507194', 'name': 'Haiquan Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}]"
45db2b7a9350ed3929bc96219f722efbec1f1720,https://www.semanticscholar.org/paper/45db2b7a9350ed3929bc96219f722efbec1f1720,Matching Entities Across Different Knowledge Graphs with Graph Embeddings,"This paper explores the problem of matching entities across different knowledge graphs. Given a query entity in one knowledge graph, we wish to find the corresponding real-world entity in another knowledge graph. We formalize this problem and present two large-scale datasets for this task based on exiting cross-ontology links between DBpedia and Wikidata, focused on several hundred thousand ambiguous entities. Using a classification-based approach, we find that a simple multi-layered perceptron based on representations derived from RDF2Vec graph embeddings of entities in each knowledge graph is sufficient to achieve high accuracy, with only small amounts of training data. The contributions of our work are datasets for examining this problem and strong baselines on which future work can be based.",arXiv.org,2019.0,17,15,"[{'authorId': '144189463', 'name': 'Michael Azmy'}, {'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1743316', 'name': 'Ihab F. Ilyas'}]"
4a4646a5ce6b57e369403e4efea1a2e4559fe9f1,https://www.semanticscholar.org/paper/4a4646a5ce6b57e369403e4efea1a2e4559fe9f1,What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning,"Pretrained transformer-based language models have achieved state of the art across countless tasks in natural language processing. These models are highly expressive, comprising at least a hundred million parameters and a dozen layers. Recent evidence suggests that only a few of the final layers need to be fine-tuned for high quality on downstream tasks. Naturally, a subsequent research question is, ""how many of the last layers do we need to fine-tune?"" In this paper, we precisely answer this question. We examine two recent pretrained language models, BERT and RoBERTa, across standard tasks in textual entailment, semantic similarity, sentiment analysis, and linguistic acceptability. We vary the number of final layers that are fine-tuned, then study the resulting change in task-specific effectiveness. We show that only a fourth of the final layers need to be fine-tuned to achieve 90% of the original quality. Surprisingly, we also find that fine-tuning all layers does not always help.",arXiv.org,2019.0,29,99,"[{'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
560b8e1dde0b38770ed29a07d4c3006164cd80f2,https://www.semanticscholar.org/paper/560b8e1dde0b38770ed29a07d4c3006164cd80f2,Attentive Student Meets Multi-Task Teacher: Improved Knowledge Distillation for Pretrained Models,"In this paper, we explore the knowledge distillation approach under the multi-task learning setting. We distill the BERT model refined by multi-task learning on seven datasets of the GLUE benchmark into a bidirectional LSTM with attention mechanism. Unlike other BERT distillation methods which specifically designed for Transformer-based architectures, we provide a general learning framework. Our approach is model agnostic and can be easily applied on different future teacher models. Compared to a strong, similarly BiLSTM-based approach, we achieve better quality under the same computational constraints. Compared to the present state of the art, we reach comparable results with much faster inference speed.",arXiv.org,2019.0,46,18,"[{'authorId': None, 'name': 'Linqing Liu'}, {'authorId': '46507194', 'name': 'Haiquan Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}]"
5f0d07f9e832c2e26b796de83c89c69eb72df2f2,https://www.semanticscholar.org/paper/5f0d07f9e832c2e26b796de83c89c69eb72df2f2,University of Waterloo Docker Images for OSIRRC at SIGIR 2019,"1 OVERVIEW The University of Waterloo team submitted a total of four Docker images to the Open-Source IR Replicability Challenge (OSIRRC) at SIGIR 2019. This short overview outlines the functionality of each image. As the READMEs in all our source repositories provide details on the technical design of our images and the retrieval models used in our runs, we intentionally do not duplicate this information here. Our primary submission is a packaging of Anserini [11, 12], an open-source information retrieval toolkit built around Lucene to facilitate replicable research. This anserini-docker image resides at the following URL:",OSIRRC@SIGIR,2019.0,14,0,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '2109576766', 'name': 'Z. Z. Wu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
63a2fabbe4b1615a84d5f4d90987733cf09e3ff8,https://www.semanticscholar.org/paper/63a2fabbe4b1615a84d5f4d90987733cf09e3ff8,Multi-Stage Document Ranking with BERT,"The advent of deep neural networks pre-trained via language modeling tasks has spurred a number of successful applications in natural language processing. This work explores one such popular model, BERT, in the context of document ranking. We propose two variants, called monoBERT and duoBERT, that formulate the ranking problem as pointwise and pairwise classification, respectively. These two models are arranged in a multi-stage ranking architecture to form an end-to-end search system. One major advantage of this design is the ability to trade off quality against latency by controlling the admission of candidates into each pipeline stage, and by doing so, we are able to find operating points that offer a good balance between these two competing metrics. On two large-scale datasets, MS MARCO and TREC CAR, experiments show that our model produces results that are either at or comparable to the state of the art. Ablation studies show the contributions of each component and characterize the latency/quality tradeoff space.",arXiv.org,2019.0,47,287,"[{'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6b556a6dd7221aa431941251555e52492a2878f5,https://www.semanticscholar.org/paper/6b556a6dd7221aa431941251555e52492a2878f5,Cross-Lingual Relevance Transfer for Document Retrieval,"Recent work has shown the surprising ability of multi-lingual BERT to serve as a zero-shot cross-lingual transfer model for a number of language processing tasks. We combine this finding with a similarly-recently proposal on sentence-level relevance modeling for document retrieval to demonstrate the ability of multi-lingual BERT to transfer models of relevance across languages. Experiments on test collections in five different languages from diverse language families (Chinese, Arabic, French, Hindi, and Bengali) show that models trained with English data improve ranking quality, without any special processing, both for (non-English) mono-lingual retrieval as well as cross-lingual retrieval.",arXiv.org,2019.0,11,13,"[{'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7d767f64e88fdec81a24190c629dcfe23c940793,https://www.semanticscholar.org/paper/7d767f64e88fdec81a24190c629dcfe23c940793,Natural Language Generation for Effective Knowledge Distillation,"Knowledge distillation can effectively transfer knowledge from BERT, a deep language representation model, to traditional, shallow word embedding-based neural networks, helping them approach or exceed the quality of other heavyweight language representation models. As shown in previous work, critical to this distillation procedure is the construction of an unlabeled transfer dataset, which enables effective knowledge transfer. To create transfer set examples, we propose to sample from pretrained language models fine-tuned on task-specific text. Unlike previous techniques, this directly captures the purpose of the transfer set. We hypothesize that this principled, general approach outperforms rule-based techniques. On four datasets in sentiment classification, sentence similarity, and linguistic acceptability, we show that our approach improves upon previous methods. We outperform OpenAI GPT, a deep pretrained transformer, on three of the datasets, while using a single-layer bidirectional LSTM that runs at least ten times faster.",Conference on Empirical Methods in Natural Language Processing,2019.0,26,26,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '40282678', 'name': 'Yao Lu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
872251f0e4a36dfba1b6493358edbdbf1ccbc09b,https://www.semanticscholar.org/paper/872251f0e4a36dfba1b6493358edbdbf1ccbc09b,Reproducing and Generalizing Semantic Term Matching in Axiomatic Information Retrieval,,European Conference on Information Retrieval,2019.0,12,6,"[{'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
89cab01ed15323e90abdf2a12fd3819836034aae,https://www.semanticscholar.org/paper/89cab01ed15323e90abdf2a12fd3819836034aae,Lucene for Approximate Nearest-Neighbors Search on Arbitrary Dense Vectors,"We demonstrate three approaches for adapting the open-source Lucene search library to perform approximate nearest-neighbor search on arbitrary dense vectors, using similarity search on word embeddings as a case study. At its core, Lucene is built around inverted indexes of a document collection's (sparse) term-document matrix, which is incompatible with the lower-dimensional dense vectors that are common in deep learning applications. We evaluate three techniques to overcome these challenges that can all be natively integrated into Lucene: the creation of documents populated with fake words, LSH applied to lexical realizations of dense vectors, and k-d trees coupled with dimensionality reduction. Experiments show that the ""fake words"" approach represents the best balance between effectiveness and efficiency. These techniques are integrated into the Anserini open-source toolkit and made available to the community.",arXiv.org,2019.0,14,4,"[{'authorId': '16973085', 'name': 'Tommaso Teofili'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8fd8b2a99388aab62d58538f883407b52600cccf,https://www.semanticscholar.org/paper/8fd8b2a99388aab62d58538f883407b52600cccf,"The neural hype, justified!","One year ago, in the SIGIR Forum issue of December 2018, I ranted about the ""neural hype"" [9]. One year later, I write again to publicly recant my heretical beliefs. What a difference a year makes! In accelerated ""deep learning"" time, a year seems like an eternity---so much exciting progress has been made in the previous months!",SIGIR Forum,2019.0,25,11,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
90820988957e74db0fbb1df79175610e08016ba4,https://www.semanticscholar.org/paper/90820988957e74db0fbb1df79175610e08016ba4,Bridging the Gap between Relevance Matching and Semantic Matching for Short Text Similarity Modeling,"A core problem of information retrieval (IR) is relevance matching, which is to rank documents by relevance to a user‚Äôs query. On the other hand, many NLP problems, such as question answering and paraphrase identification, can be considered variants of semantic matching, which is to measure the semantic distance between two pieces of short texts. While at a high level both relevance and semantic matching require modeling textual similarity, many existing techniques for one cannot be easily adapted to the other. To bridge this gap, we propose a novel model, HCAN (Hybrid Co-Attention Network), that comprises (1) a hybrid encoder module that includes ConvNet-based and LSTM-based encoders, (2) a relevance matching module that measures soft term matches with importance weighting at multiple granularities, and (3) a semantic matching module with co-attention mechanisms that capture context-aware semantic relatedness. Evaluations on multiple IR and NLP benchmarks demonstrate state-of-the-art effectiveness compared to approaches that do not exploit pretraining on external data. Extensive ablation studies suggest that relevance and semantic matching signals are complementary across many problem settings, regardless of the choice of underlying encoders.",Conference on Empirical Methods in Natural Language Processing,2019.0,43,48,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '144447820', 'name': 'Yi Tay'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
999df2c1d84096253a7ba5369ce3de0b47fe95f6,https://www.semanticscholar.org/paper/999df2c1d84096253a7ba5369ce3de0b47fe95f6,Information Retrieval Meets Scalable Text Analytics: Solr Integration with Spark,"Despite the broad adoption of both Apache Spark and Apache Solr, there is little integration between these two platforms to support scalable, end-to-end text analytics. We believe this is a missed opportunity, as there is substantial synergy in building analytical pipelines where the results of potentially complex faceted queries feed downstream text processing components. This demonstration explores exactly such an integration: we evaluate performance under different analytical scenarios and present three simple case studies that illustrate the range of possible analyses enabled by seamlessly connecting Spark to Solr.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,13,3,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9c88bbc2a867f9c139a2d52079f0333ca2bb7aaf,https://www.semanticscholar.org/paper/9c88bbc2a867f9c139a2d52079f0333ca2bb7aaf,Universal voice-enabled user interfaces using JavaScript,"Countless voice-enabled user interfaces rely on keyword spotting (KWS) systems for wake word detection and simple command recognition. As a practical matter, these applications run on ""edge"" devices, where dozens of different platforms exist; typically, platform-dependent implementation are required whenever keyword spotting capabilities are needed. This impedes the rapid deployment of voice-enabled interfaces. Fortunately, with the development of several recent frameworks, JavaScript enables us to deploy neural networks for keyword spotting to support a wide range of speech-based user interfaces. We present three voice-enabled applications that use a unified, JavaScript-based KWS system: an in-browser game, a desktop virtual assistant, and a smart lightbulb controller. We are, to the best of our knowledge, the first to demonstrate the feasibility of JavaScript-based keyword spotting for universal voice-enabled user interfaces.",IUI Companion,2019.0,5,3,"[{'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a08293b2c9c5bcddb023cc7eb3354d4d86bfae89,https://www.semanticscholar.org/paper/a08293b2c9c5bcddb023cc7eb3354d4d86bfae89,Distilling Task-Specific Knowledge from BERT into Simple Neural Networks,"In the natural language processing literature, neural networks are becoming increasingly deeper and complex. The recent poster child of this trend is the deep language representation model, which includes BERT, ELMo, and GPT. These developments have led to the conviction that previous-generation, shallower neural networks for language understanding are obsolete. In this paper, however, we demonstrate that rudimentary, lightweight neural networks can still be made competitive without architecture changes, external training data, or additional input features. We propose to distill knowledge from BERT, a state-of-the-art language representation model, into a single-layer BiLSTM, as well as its siamese counterpart for sentence-pair tasks. Across multiple datasets in paraphrasing, natural language inference, and sentiment classification, we achieve comparable results with ELMo, while using roughly 100 times fewer parameters and 15 times less inference time.",arXiv.org,2019.0,42,354,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '40282678', 'name': 'Yao Lu'}, {'authorId': '2111591', 'name': 'Linqing Liu'}, {'authorId': '38956216', 'name': 'Lili Mou'}, {'authorId': '1712417', 'name': 'Olga Vechtomova'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a200767587cd8e897f96b3f3aa36002d78a76f06,https://www.semanticscholar.org/paper/a200767587cd8e897f96b3f3aa36002d78a76f06,Explicit Pairwise Word Interaction Modeling Improves Pretrained Transformers for English Semantic Similarity Tasks,"In English semantic similarity tasks, classic word embedding-based approaches explicitly model pairwise ""interactions"" between the word representations of a sentence pair. Transformer-based pretrained language models disregard this notion, instead modeling pairwise word interactions globally and implicitly through their self-attention mechanism. In this paper, we hypothesize that introducing an explicit, constrained pairwise word interaction mechanism to pretrained language models improves their effectiveness on semantic similarity tasks. We validate our hypothesis using BERT on four tasks in semantic textual similarity and answer sentence selection. We demonstrate consistent improvements in quality by adding an explicit pairwise word interaction module to BERT.",arXiv.org,2019.0,23,5,"[{'authorId': '2108384019', 'name': 'Yinan Zhang'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ac3d6c311631fa6eb645d16c40f54b5465767888,https://www.semanticscholar.org/paper/ac3d6c311631fa6eb645d16c40f54b5465767888,What Part of the Neural Network Does This? Understanding LSTMs by Measuring and Dissecting Neurons,"Memory neurons of long short-term memory (LSTM) networks encode and process information in powerful yet mysterious ways. While there has been work to analyze their behavior in carrying low-level information such as linguistic properties, how they directly contribute to label prediction remains unclear. We find inspiration from biologists and study the affinity between individual neurons and labels, propose a novel metric to quantify the sensitivity of neurons to each label, and conduct experiments to show the validity of our proposed metric. We discover that some neurons are trained to specialize on a subset of labels, and while dropping an arbitrary neuron has little effect on the overall accuracy of the model, dropping label-specialized neurons predictably and significantly degrades prediction accuracy on the associated label. We further examine the consistency of neuron-label affinity across different models. These observations provide insight into the inner mechanisms of LSTMs.",Conference on Empirical Methods in Natural Language Processing,2019.0,22,5,"[{'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}]"
b092b6b843e9421bf42bf96f57ed4658a3e0bdf7,https://www.semanticscholar.org/paper/b092b6b843e9421bf42bf96f57ed4658a3e0bdf7,Document Expansion by Query Prediction,"One technique to improve the retrieval effectiveness of a search engine is to expand documents with terms that are related or representative of the documents' content.From the perspective of a question answering system, this might comprise questions the document can potentially answer. Following this observation, we propose a simple method that predicts which queries will be issued for a given document and then expands it with those predictions with a vanilla sequence-to-sequence model, trained using datasets consisting of pairs of query and relevant documents. By combining our method with a highly-effective re-ranking component, we achieve the state of the art in two retrieval tasks. In a latency-critical regime, retrieval results alone (without re-ranking) approach the effectiveness of more computationally expensive neural re-rankers but are much faster.",arXiv.org,2019.0,27,324,"[{'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1979489', 'name': 'Kyunghyun Cho'}]"
b2ca0a827ca86d515a0e378ef206323a86d5d2af,https://www.semanticscholar.org/paper/b2ca0a827ca86d515a0e378ef206323a86d5d2af,Detecting Customer Complaint Escalation with Recurrent Neural Networks and Manually-Engineered Features,"Consumers dissatisfied with the normal dispute resolution process provided by an e-commerce company‚Äôs customer service agents have the option of escalating their complaints by filing grievances with a government authority. This paper tackles the challenge of monitoring ongoing text chat dialogues to identify cases where the customer expresses such an intent, providing triage and prioritization for a separate pool of specialized agents specially trained to handle more complex situations. We describe a hybrid model that tackles this challenge by integrating recurrent neural networks with manually-engineered features. Experiments show that both components are complementary and contribute to overall recall, outperforming competitive baselines. A trial online deployment of our model demonstrates its business value in improving customer service.",North American Chapter of the Association for Computational Linguistics,2019.0,21,18,"[{'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '48165487', 'name': 'Chunwei Lu'}, {'authorId': '2339882', 'name': 'Anqi Cui'}, {'authorId': None, 'name': 'Han Li'}, {'authorId': '153773936', 'name': 'Xi Chen'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2108593510', 'name': 'Muzi Wang'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '2118206246', 'name': 'Jian Pei'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b55aff76a66a0432f399a9535f71269e1a85c154,https://www.semanticscholar.org/paper/b55aff76a66a0432f399a9535f71269e1a85c154,Building Community and Tools for Analyzing Web Archives Through Datathons,"Starting in March 2016, the Archives Unleashed team and our collaborators have brought together social scientists, humanists, archivists, librarians, computer scientists, and other stakeholders to explore web archives as research objects. Three objectives motivated our team to develop and organize these events: facilitating scholarly access, community building, and skills training. We believe that we have been successful on all three fronts. For each event, over the course of two to three days, participants formed interdisciplinary teams and explored web archives using a variety of methods and tools. This paper details our experiences in designing these ""datathons"", with an intent to share lessons learned, highlight interdisciplinary approaches to research and education on web archives, and describe future opportunities.",ACM/IEEE Joint Conference on Digital Libraries,2019.0,11,13,"[{'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3387598', 'name': 'Nathalie Casemajor'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '2110604214', 'name': 'Matthew S. Weber'}, {'authorId': '23003320', 'name': 'Nicholas Worby'}]"
b7bdf98ef84909d4ec0b2ebd5157ee3cb38522b8,https://www.semanticscholar.org/paper/b7bdf98ef84909d4ec0b2ebd5157ee3cb38522b8,Rethinking Complex Neural Network Architectures for Document Classification,"Neural network models for many NLP tasks have grown increasingly complex in recent years, making training and deployment more difficult. A number of recent papers have questioned the necessity of such architectures and found that well-executed, simpler models are quite effective. We show that this is also the case for document classification: in a large-scale reproducibility study of several recent neural models, we find that a simple BiLSTM architecture with appropriate regularization yields accuracy and F1 that are either competitive or exceed the state of the art on four standard benchmark datasets. Surprisingly, our simple model is able to achieve these results without attention mechanisms. While these regularization techniques, borrowed from language modeling, are not novel, to our knowledge we are the first to apply them in this context. Our work provides an open-source platform and the foundation for future work in document classification.",North American Chapter of the Association for Computational Linguistics,2019.0,25,81,"[{'authorId': '51941200', 'name': 'Ashutosh Adhikari'}, {'authorId': '46253949', 'name': 'Achyudh Ram'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c421a58239e681d4caa1afae13e84d5983a4b8ab,https://www.semanticscholar.org/paper/c421a58239e681d4caa1afae13e84d5983a4b8ab,The Simplest Thing That Can Possibly Work: Pseudo-Relevance Feedback Using Text Classification,"Motivated by recent commentary that has questioned today's pursuit of ever-more complex models and mathematical formalisms in applied machine learning and whether meaningful empirical progress is actually being made, this paper tries to tackle the decades-old problem of pseudo-relevance feedback with ""the simplest thing that can possibly work"". I present a technique based on training a document relevance classifier for each information need using pseudo-labels from an initial ranked list and then applying the classifier to rerank the retrieved documents. Experiments demonstrate significant improvements across a number of newswire collections, with initial rankings supplied by ""bag of words"" BM25 as well as from a well-tuned query expansion model. While this simple technique draws elements from several well-known threads in the literature, to my knowledge this exact combination has not previously been proposed and evaluated.",arXiv.org,2019.0,28,11,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c4ddd9c8eb0fa8e9d50a7fe1548e61af563f9a9c,https://www.semanticscholar.org/paper/c4ddd9c8eb0fa8e9d50a7fe1548e61af563f9a9c,Simple Techniques for Cross-Collection Relevance Feedback,,European Conference on Information Retrieval,2019.0,11,10,"[{'authorId': '52189929', 'name': 'Ruifan Yu'}, {'authorId': '94510137', 'name': 'Yuhao Xie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c9fb00ca4625c90e5d44ead3bd7e076a744ba169,https://www.semanticscholar.org/paper/c9fb00ca4625c90e5d44ead3bd7e076a744ba169,"Critically Examining the ""Neural Hype"": Weak Baselines and the Additivity of Effectiveness Gains from Neural Ranking Models","Is neural IR mostly hype? In a recent SIGIR Forum article, Lin expressed skepticism that neural ranking models were actually improving ad hoc retrieval effectiveness in limited data scenarios. He provided anecdotal evidence that authors of neural IR papers demonstrate ""wins"" by comparing against weak baselines. This paper provides a rigorous evaluation of those claims in two ways: First, we conducted a meta-analysis of papers that have reported experimental results on the TREC Robust04 test collection. We do not find evidence of an upward trend in effectiveness over time. In fact, the best reported results are from a decade ago and no recent neural approach comes close. Second, we applied five recent neural models to rerank the strong baselines that Lin used to make his arguments. A significant improvement was observed for one of the models, demonstrating additivity in gains. While there appears to be merit to neural IR approaches, at least some of the gains reported in the literature appear illusory.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,28,128,"[{'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '49245966', 'name': 'Kuang Lu'}, {'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ca4ddad3aff3c1808ade7b2cfbfc93ca36d01d70,https://www.semanticscholar.org/paper/ca4ddad3aff3c1808ade7b2cfbfc93ca36d01d70,Exploiting Token and Path-based Representations of Code for Identifying Security-Relevant Commits,"Public vulnerability databases such as CVE and NVD account for only 60% of security vulnerabilities present in open-source projects, and are known to suffer from inconsistent quality. Over the last two years, there has been considerable growth in the number of known vulnerabilities across projects available in various repositories such as NPM and Maven Central. Such an increasing risk calls for a mechanism to infer the presence of security threats in a timely manner. We propose novel hierarchical deep learning models for the identification of security-relevant commits from either the commit diff or the source code for the Java classes. By comparing the performance of our model against code2vec, a state-of-the-art model that learns from path-based representations of code, and a logistic regression baseline, we show that deep learning models show promising results in identifying security-related commits. We also conduct a comparative analysis of how various deep learning models learn across different input representations and the effect of regularization on the generalization of our models.",arXiv.org,2019.0,57,3,"[{'authorId': '46253949', 'name': 'Achyudh Ram'}, {'authorId': '2059016789', 'name': 'Ji Xin'}, {'authorId': '7274019', 'name': 'M. Nagappan'}, {'authorId': '40508553', 'name': 'Yaoliang Yu'}, {'authorId': '1971870', 'name': 'Roc√≠o Cabrera Lozoya'}, {'authorId': '1737833', 'name': 'A. Sabetta'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
cae9b657efe5c96c494eeb920930e8e2e879823b,https://www.semanticscholar.org/paper/cae9b657efe5c96c494eeb920930e8e2e879823b,Overview of the 2019 Open-Source IR Replicability Challenge (OSIRRC 2019),"The Open-Source IR Replicability Challenge (OSIRRC 2019), organized as a workshop at SIGIR 2019, aims to improve the replicability of ad hoc retrieval experiments in information retrieval by gathering a community of researchers to jointly develop a common Docker specification and build Docker images that encapsulate a diversity of systems and retrieval models. We articulate the goals of this workshop and describe the ‚Äújig‚Äù that encodes the Docker specification. In total, 13 teams from around the world submitted 17 images, most of which were designed to produce retrieval runs for the TREC 2004 Robust Track test collection. This exercise demonstrates the feasibility of orchestrating large, community-based replication experiments with Docker technology. We envision OSIRRC becoming an ongoing community-wide effort to ensure experimental replicability and sustained progress on standard test collections.",OSIRRC@SIGIR,2019.0,14,11,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '143612982', 'name': 'N. Ferro'}, {'authorId': '2731925', 'name': 'C. Hauff'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1725544', 'name': 'T. Sakai'}, {'authorId': '2109576766', 'name': 'Z. Z. Wu'}]"
cf4dcc7d67f0776ffe7aa5b4ee3217f9bd757282,https://www.semanticscholar.org/paper/cf4dcc7d67f0776ffe7aa5b4ee3217f9bd757282,Aligning Cross-Lingual Entities with Multi-Aspect Information,"Multilingual knowledge graphs (KGs), such as YAGO and DBpedia, represent entities in different languages. The task of cross-lingual entity alignment is to match entities in a source language with their counterparts in target languages. In this work, we investigate embedding-based approaches to encode entities from multilingual KGs into the same vector space, where equivalent entities are close to each other. Specifically, we apply graph convolutional networks (GCNs) to combine multi-aspect information of entities, including topological connections, relations, and attributes of entities, to learn entity embeddings. To exploit the literal descriptions of entities expressed in different languages, we propose two uses of a pretrained multilingual BERT model to bridge cross-lingual gaps. We further propose two strategies to integrate GCN-based and BERT-based modules to boost performance. Extensive experiments on two benchmark datasets demonstrate that our method significantly outperforms existing systems.",Conference on Empirical Methods in Natural Language Processing,2019.0,41,116,"[{'authorId': '22171670', 'name': 'Hsiu-Wei Yang'}, {'authorId': '2803468', 'name': 'Yanyan Zou'}, {'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '143844110', 'name': 'Wei Lu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '11774802', 'name': 'Xu Sun'}]"
d30316d94ab25e435946767d8036bf8bc8f68555,https://www.semanticscholar.org/paper/d30316d94ab25e435946767d8036bf8bc8f68555,Scalable Knowledge Graph Construction from Text Collections,"We present a scalable, open-source platform that ‚Äúdistills‚Äù a potentially large text collection into a knowledge graph. Our platform takes documents stored in Apache Solr and scales out the Stanford CoreNLP toolkit via Apache Spark integration to extract mentions and relations that are then ingested into the Neo4j graph database. The raw knowledge graph is then enriched with facts extracted from an external knowledge graph. The complete product can be manipulated by various applications using Neo4j‚Äôs native Cypher query language: We present a subgraph-matching approach to align extracted relations with external facts and show that fact verification, locating textual support for asserted facts, detecting inconsistent and missing facts, and extracting distantly-supervised training data can all be performed within the same framework.",Conference on Empirical Methods in Natural Language Processing,2019.0,18,14,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '1743316', 'name': 'Ihab F. Ilyas'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
dd4bc6c7b0c7505bc8fedaebdf0a1918eefd0376,https://www.semanticscholar.org/paper/dd4bc6c7b0c7505bc8fedaebdf0a1918eefd0376,The SIGIR 2019 Open-Source IR Replicability Challenge (OSIRRC 2019),"The importance of repeatability, replicability, and reproducibility is broadly recognized in the computational sciences, both in supporting desirable scientific methodology as well as sustaining empirical progress. This workshop tackles the replicability challenge for ad hoc document retrieval, via a common Docker interface specification to support images that capture systems performing ad hoc retrieval experiments on standard test collections.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2019.0,16,22,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '143612982', 'name': 'N. Ferro'}, {'authorId': '2731925', 'name': 'C. Hauff'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1725544', 'name': 'T. Sakai'}, {'authorId': '2109576766', 'name': 'Z. Z. Wu'}]"
df12d1d972708250f3769eaaa34f4b156cf695fe,https://www.semanticscholar.org/paper/df12d1d972708250f3769eaaa34f4b156cf695fe,Applying BERT to Document Retrieval with Birch,"We present Birch, a system that applies BERT to document retrieval via integration with the open-source Anserini information retrieval toolkit to demonstrate end-to-end search over large document collections. Birch implements simple ranking models that achieve state-of-the-art effectiveness on standard TREC newswire and social media test collections. This demonstration focuses on technical challenges in the integration of NLP and IR capabilities, along with the design rationale behind our approach to tightly-coupled integration between Python (to support neural networks) and the Java Virtual Machine (to support document retrieval using the open-source Lucene search library). We demonstrate integration of Birch with an existing search interface as well as interactive notebooks that highlight its capabilities in an easy-to-understand manner.",Conference on Empirical Methods in Natural Language Processing,2019.0,27,105,"[{'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '1678689', 'name': 'Shengjin Wang'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e21022fee9d581f9b4680f9510ccbaea8a1cea94,https://www.semanticscholar.org/paper/e21022fee9d581f9b4680f9510ccbaea8a1cea94,The Performance Envelope of Inverted Indexing on Modern Hardware,"This paper explores the performance envelope of ""traditional"" inverted indexing on modern hardware using the implementation in the open-source Lucene search library. We benchmark indexing throughput on a single high-end multi-core commodity server in a number of configurations varying the media of the source collection and target index, examining a network-attacked store, a direct-attached disk array, and an SSD. Experiments show that the largest determinants of performance are the physical characteristics of the source and target media, and that physically isolating the two yields the highest indexing throughput. Results suggest that current indexing techniques have reached physical device limits, and that further algorithmic improvements in performance are unlikely without rethinking the inverted indexing pipeline in light of observed bottlenecks.",arXiv.org,2019.0,12,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1382652458', 'name': 'Lori Paniak'}, {'authorId': '1382652470', 'name': 'Gordon Boerke'}]"
e3d240b2de9e76ea0134beaaff4a868ded2602f2,https://www.semanticscholar.org/paper/e3d240b2de9e76ea0134beaaff4a868ded2602f2,osirrc/indri-docker: Indri Docker Image for OSIRRC at SIGIR 2019 (v0.2.1),,,2019.0,0,0,"[{'authorId': '150008160', 'name': 'R. Clancy'}, {'authorId': '2731925', 'name': 'C. Hauff'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '133572799', 'name': 'A. C√¢mara'}]"
ea57734824426a427f8b9139da1ae574cc929543,https://www.semanticscholar.org/paper/ea57734824426a427f8b9139da1ae574cc929543,Simple Applications of BERT for Ad Hoc Document Retrieval,"Following recent successes in applying BERT to question answering, we explore simple applications to ad hoc document retrieval. This required confronting the challenge posed by documents that are typically longer than the length of input BERT was designed to handle. We address this issue by applying inference on sentences individually, and then aggregating sentence scores to produce document scores. Experiments on TREC microblog and newswire test collections show that our approach is simple yet effective, as we report the highest average precision on these datasets by neural approaches that we are aware of.",arXiv.org,2019.0,27,181,"[{'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
efc4146087f83573e5b27aab9011d01d7c2126ca,https://www.semanticscholar.org/paper/efc4146087f83573e5b27aab9011d01d7c2126ca,The Cost of a WARC: Analyzing Web Archives in the Cloud,"The value of web archives to support scholarship in the humanities and social sciences is slowly being realized by the increasing availability of scalable tools and platforms. The cost of providing scholarly access is a critical component of developing a long-term sustainability strategy. This paper attempts to answer a straightforward question: How much does it cost to analyze web archives in the cloud? To make this question more concrete, we examine the creation of three derivatives (extraction of collection statistics, full text, and the webgraph) that serve as the starting points of many scholarly inquiries. Our analysis shows that these typical derivatives costs around US$7 per TB using our Archives Unleashed Toolkit. We describe in detail the methodology and assumptions made to arrive at this figure. To our knowledge, we are the first to quantify the economics of scholarly access to web archives, and we believe that this information is valuable for service planning by archives, libraries, and other institutions.",ACM/IEEE Joint Conference on Digital Libraries,2019.0,7,9,"[{'authorId': '28929508', 'name': 'Ryan Deschamps'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}]"
f5eaf727b80240a13e9f631211c9ecec7e3b9feb,https://www.semanticscholar.org/paper/f5eaf727b80240a13e9f631211c9ecec7e3b9feb,Data Augmentation for BERT Fine-Tuning in Open-Domain Question Answering,"Recently, a simple combination of passage retrieval using off-the-shelf IR techniques and a BERT reader was found to be very effective for question answering directly on Wikipedia, yielding a large improvement over the previous state of the art on a standard benchmark dataset. In this paper, we present a data augmentation technique using distant supervision that exploits positive as well as negative examples. We apply a stage-wise approach to fine tuning BERT on multiple datasets, starting with data that is ""furthest"" from the test data and ending with the ""closest"". Experimental results show large gains in effectiveness over previous approaches on English QA datasets, and we establish new baselines on two recent Chinese QA datasets.",arXiv.org,2019.0,24,58,"[{'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '49291108', 'name': 'Yuqing Xie'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '50033756', 'name': 'Kun Xiong'}, {'authorId': '2150652992', 'name': 'Ming Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fcf9f980a1f0f24d7234bf0b026e30d7fe5a1843,https://www.semanticscholar.org/paper/fcf9f980a1f0f24d7234bf0b026e30d7fe5a1843,Honkling: In-Browser Personalization for Ubiquitous Keyword Spotting,"Used for simple commands recognition on devices from smart speakers to mobile phones, keyword spotting systems are everywhere. Ubiquitous as well are web applications, which have grown in popularity and complexity over the last decade. However, despite their obvious advantages in natural language interaction, voice-enabled web applications are still few and far between. We attempt to bridge this gap with Honkling, a novel, JavaScript-based keyword spotting system. Purely client-side and cross-device compatible, Honkling can be deployed directly on user devices. Our in-browser implementation enables seamless personalization, which can greatly improve model quality; in the presence of underrepresented, non-American user accents, we can achieve up to an absolute 10% increase in accuracy in the personalized model with only a few examples.",Conference on Empirical Methods in Natural Language Processing,2019.0,70,3,"[{'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fd2ef4000b36e942985343964d098ed84f2ef7c3,https://www.semanticscholar.org/paper/fd2ef4000b36e942985343964d098ed84f2ef7c3,The Archives Unleashed Notebook: Madlibs for Jumpstarting Scholarly Exploration of Web Archives,"This paper introduces the Archives Unleashed Notebook, which is designed to work with derivative datasets from the Archives Unleashed Cloud, a platform for analyzing web archives. These datasets contain common starting points for scholarly inquiry, including full text content and the domain-level webgraph. Our notebooks interactively walk a scholar through the process of interrogating a collection using a fill-in-the-blanks 'madlibs' approach to promote engagement. Scholars start with a notebook populated with common analyses, in which they can make minor changes to variables to alter the subject of study in systematic ways.",ACM/IEEE Joint Conference on Digital Libraries,2019.0,4,7,"[{'authorId': '28929508', 'name': 'Ryan Deschamps'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}, {'authorId': '144703130', 'name': 'Ian Milligan'}]"
fddbcabe0fc9be0684855ae3dd059fb525a69e5b,https://www.semanticscholar.org/paper/fddbcabe0fc9be0684855ae3dd059fb525a69e5b,Simple BERT Models for Relation Extraction and Semantic Role Labeling,"We present simple BERT-based models for relation extraction and semantic role labeling. In recent years, state-of-the-art performance has been achieved using neural models by incorporating lexical and syntactic features such as part-of-speech tags and dependency trees. In this paper, extensive experiments on datasets for these two tasks show that without using any external features, a simple BERT-based model can achieve state-of-the-art performance. To our knowledge, we are the first to successfully apply BERT in this manner. Our models provide strong baselines for future research.",arXiv.org,2019.0,24,384,"[{'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ff7de3e6a7a8ed962162665561dc0738e45c73fc,https://www.semanticscholar.org/paper/ff7de3e6a7a8ed962162665561dc0738e45c73fc,Warclight: A Rails Engine for Web Archive Discovery,"This paper describes the development of Warclight, a portmanteau of the open-source Blacklight platform and the ISO-standard Web ARChive file format. Warclight allows users to explore web archives that have been indexed into Apache Solr using the UK Web Archive's Web Archive Discovery tool. Referencing previous work, we explain how the standard search engine results page is inadequate to support scholarly inquiries. Instead, Warclight provides full-text and faceted search, as well as faceted browsing, to enable exploration and discovery. Given the large sizes of many web archives, we share experiences with deploying our tool at scale using a federated architecture.",ACM/IEEE Joint Conference on Digital Libraries,2019.0,5,2,"[{'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1d9115701fae7050e92ac46152819d403f2ea6f9,https://www.semanticscholar.org/paper/1d9115701fae7050e92ac46152819d403f2ea6f9,In-Browser Split-Execution Support for Interactive Analytics in the Cloud,"The canonical analytics architecture today consists of a browser connected to a backend in the cloud. In all deployments that we are aware of, the browser is simply a dumb rendering endpoint. As an alternative, this paper explores split-execution architectures that push analytics capabilities into the browser. We show that, by taking advantage of typed arrays and asm.js, it is possible to build an analytical RDBMS in JavaScript that runs in a browser, achieving performance rivaling native databases. To support interactive data exploration, our Afterburner prototype automatically generates local materialized views from a backend database that are then shipped to the browser to facilitate subsequent interactions seamlessly and efficiently. We compare this architecture to several alternative deployments, experimentally demonstrating performance parity, while at the same time providing additional advantages in terms of administrative and operational simplicity.",arXiv.org,2018.0,30,1,"[{'authorId': '2531258', 'name': 'Kareem El Gebaly'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
28a5eb484459eac210c055d07fb0e9fbbd4b7f33,https://www.semanticscholar.org/paper/28a5eb484459eac210c055d07fb0e9fbbd4b7f33,Scale Up or Scale Out for Graph Processing?,"This column explores a simple question: scale up or scale out for graph processing? Should we simply throw beefier individual multi-core, large-memory machines at graph processing tasks and focus on developing more efficient multi-threaded algorithms, or are investments in distributed graph processing frameworks and accompanying algorithms worthwhile? For rhetorical convenience, I adopt customary definitions, referring to the former as scale up and the latter as scale out. Under what circumstances should we prefer one approach over the other?",IEEE Internet Computing,2018.0,9,7,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2f61e9f3cf90b42db2571efd19c2c7513c3be09b,https://www.semanticscholar.org/paper/2f61e9f3cf90b42db2571efd19c2c7513c3be09b,Multi-Perspective Relevance Matching with Hierarchical ConvNets for Social Media Search,"Despite substantial interest in applications of neural networks to information retrieval, neural ranking models have mostly been applied to ‚Äústandard‚Äù ad hoc retrieval tasks over web pages and newswire articles. This paper proposes MP-HCNN (Multi-Perspective Hierarchical Convolutional Neural Network), a novel neural ranking model specifically designed for ranking short social media posts. We identify document length, informal language, and heterogeneous relevance signals as features that distinguish documents in our domain, and present a model specifically designed with these characteristics in mind. Our model uses hierarchical convolutional layers to learn latent semantic soft-match relevance signals at the character, word, and phrase levels. A poolingbased similarity measurement layer integrates evidence from multiple types of matches between the query, the social media post, as well as URLs contained in the post. Extensive experiments using Twitter data from the TREC Microblog Tracks 2011‚Äì2014 show that our model significantly outperforms prior feature-based as well as existing neural ranking models. To our best knowledge, this paper presents the first substantial work tackling search over social media posts using neural ranking models. Our code and data are publicly available.1",AAAI Conference on Artificial Intelligence,2018.0,48,35,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '144205297', 'name': 'Wei Yang'}, {'authorId': '49889487', 'name': 'Yuhao Zhang'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
309e4a8d1ac0a32832447ac0ffb09df8da9894c7,https://www.semanticscholar.org/paper/309e4a8d1ac0a32832447ac0ffb09df8da9894c7,FLOPs as a Direct Optimization Objective for Learning Sparse Neural Networks,"There exists a plethora of techniques for inducing structured sparsity in parametric models during the optimization process, with the final goal of resource-efficient inference. However, few methods target a specific number of floating-point operations (FLOPs) as part of the optimization objective, despite many reporting FLOPs as part of the results. Furthermore, a one-size-fits-all approach ignores realistic system constraints, which differ significantly between, say, a GPU and a mobile phone -- FLOPs on the former incur less latency than on the latter; thus, it is important for practitioners to be able to specify a target number of FLOPs during model compression. In this work, we extend a state-of-the-art technique to directly incorporate FLOPs as part of the optimization objective and show that, given a desired FLOPs requirement, different neural networks can be successfully trained for image classification.",arXiv.org,2018.0,20,26,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '51941200', 'name': 'Ashutosh Adhikari'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
39dd6d4e9c70a268816d18a5762bd0101cd830f0,https://www.semanticscholar.org/paper/39dd6d4e9c70a268816d18a5762bd0101cd830f0,Adaptive Pruning of Neural Language Models for Mobile Devices,"Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space where better perplexity typically comes at the cost of greater computation complexity. In a software keyboard application on mobile devices, this translates into higher power consumption and shorter battery life. This paper represents the first attempt, to our knowledge, in exploring accuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neural networks (QRNNs), we apply pruning techniques to provide a ""knob"" to select different operating points. In addition, we propose a simple technique to recover some perplexity using a negligible amount of memory. Our empirical evaluations consider both perplexity as well as energy consumption on a Raspberry Pi, where we demonstrate which methods provide the best perplexity-power consumption operating point. At one operating point, one of the techniques is able to provide energy savings of 40% over the state of the art with only a 17% relative increase in perplexity.",arXiv.org,2018.0,25,5,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3e9629366f3f2ddf48122b9d6ad973bca212037e,https://www.semanticscholar.org/paper/3e9629366f3f2ddf48122b9d6ad973bca212037e,Serverless Data Analytics with Flint,"Serverless architectures organized around loosely-coupled function invocations represent an emerging design for many applications. Recent work mostly focuses on user-facing products and event-driven processing pipelines. In this paper, we explore a completely different part of the application space and examine the feasibility of analytical processing on big data using a serverless architecture. We present Flint, a prototype Spark execution engine that takes advantage of AWS Lambda to provide a pure pay-as-you-go cost model. With Flint, a developer uses PySpark exactly as before, but without needing an actual Spark cluster. We describe the design, implementation, and performance of Flint, along with the challenges associated with serverless analytics.",IEEE International Conference on Cloud Computing,2018.0,14,71,"[{'authorId': '2116196224', 'name': 'Youngbin Kim'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
54befeedfaa980bd40f0df8fb9e091fcb81b592a,https://www.semanticscholar.org/paper/54befeedfaa980bd40f0df8fb9e091fcb81b592a,"Robust, Scalable, Real-Time Event Time Series Aggregation at Twitter","Twitter's data engineering team is faced with the challenge of processing billions of events every day in batch and in real time, and we have built various tools to meet these demands. In this paper, we describe TSAR (TimeSeries AggregatoR), a robust, scalable, real-time event time series aggregation framework built primarily for engagement monitoring: aggregating interactions with Tweets, segmented along a multitude of dimensions such as device, engagement type, etc. TSAR is built on top of Summingbird, an open-source framework for integrating batch and online MapReduce computations, and removes much of the tedium associated with building end-to-end aggregation pipelines---from the ingestion and processing of events to the publication of results in heterogeneous datastores. Clients are provided a query interface that powers dashboards and supports downstream ad hoc analytics.",SIGMOD Conference,2018.0,22,6,"[{'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '151223399', 'name': 'S. Thiagarajan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
643f0e50a1cd3ab04aa3ab664e329ebbc886842f,https://www.semanticscholar.org/paper/643f0e50a1cd3ab04aa3ab664e329ebbc886842f,Anserini,"This work tackles the perennial problem of reproducible baselines in information retrieval research, focusing on bag-of-words ranking models. Although academic information retrieval researchers have a long history of building and sharing systems, they are primarily designed to facilitate the publication of research papers. As such, these systems are often incomplete, inflexible, poorly documented, difficult to use, and slow, particularly in the context of modern web-scale collections. Furthermore, the growing complexity of modern software ecosystems and the resource constraints most academic research groups operate under make maintaining open-source systems a constant struggle. However, except for a small number of companies (mostly commercial web search engines) that deploy custom infrastructure, Lucene has become the de facto platform in industry for building search applications. Lucene has an active developer base, a large audience of users, and diverse capabilities to work with heterogeneous collections at scale. However, it lacks systematic support for ad hoc experimentation using standard test collections. We describe Anserini, an information retrieval toolkit built on Lucene that fills this gap. Our goal is to simplify ad hoc experimentation and allow researchers to easily reproduce results with modern bag-of-words ranking models on diverse test collections. With Anserini, we demonstrate that Lucene provides a suitable framework for supporting information retrieval research. Experiments show that our system efficiently indexes large web collections, provides modern ranking models that are on par with research implementations in terms of effectiveness, and supports low-latency query evaluation to facilitate rapid experimentation",ACM Journal of Data and Information Quality,2018.0,69,170,"[{'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '145344526', 'name': 'Hui Fang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6e22f27b65093cc2d24a49b281e7b782ad06c4d4,https://www.semanticscholar.org/paper/6e22f27b65093cc2d24a49b281e7b782ad06c4d4,Simple Attention-Based Representation Learning for Ranking Short Social Media Posts,"This paper explores the problem of ranking short social media posts with respect to user queries using neural networks. Instead of starting with a complex architecture, we proceed from the bottom up and examine the effectiveness of a simple, word-level Siamese architecture augmented with attention-based mechanisms for capturing semantic ‚Äúsoft‚Äù matches between query and post tokens. Extensive experiments on datasets from the TREC Microblog Tracks show that our simple models not only achieve better effectiveness than existing approaches that are far more complex or exploit a more diverse set of relevance signals, but are also much faster.",North American Chapter of the Association for Computational Linguistics,2018.0,35,7,"[{'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
71a6c7e16f9461bba32d9b90fb7ec67664a7426c,https://www.semanticscholar.org/paper/71a6c7e16f9461bba32d9b90fb7ec67664a7426c,Update Delivery Mechanisms for Prospective Information Needs: An Analysis of Attention in Mobile Users,"Real-time summarization systems that monitor document streams to identify relevant content have a few options for delivering system updates to users. In a mobile context, systems could send push notifications to users' mobile devices, hoping to grab their attention immediately. Alternatively, systems could silently deposit updates into ""inboxes"" that users can access at their leisure. We refer to these mechanisms as push-based vs. pull-based, and present a two-year contrastive study that attempts to understand the effects of the delivery mechanism on mobile user behavior, in the context of the TREC Real-Time Summarization Tracks. Through a cluster analysis, we are able to identify three distinct and coherent patterns of behavior. As expected, we find that users are likely to ignore push notifications, but for those updates that users do pay attention to, content is consumed within a short amount of time. Interestingly, users bombarded with push notifications are less likely to consume updates on their own initiative and less likely to engage in long reading sessions---which is a common pattern for users who pull content from their inboxes. We characterize users as exhibiting ""eager"" or ""apathetic"" information consumption behavior as an explanation of these observations, and attempt to operationalize our findings into design recommendations.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2018.0,23,7,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '40379164', 'name': 'Luchen Tan'}]"
729b50951bac8640fa0de0bb6aec2affabc64d1a,https://www.semanticscholar.org/paper/729b50951bac8640fa0de0bb6aec2affabc64d1a,JavaScript Convolutional Neural Networks for Keyword Spotting in the Browser: An Experimental Analysis,"Used for simple commands recognition on devices from smart routers to mobile phones, keyword spotting systems are everywhere. Ubiquitous as well are web applications, which have grown in popularity and complexity over the last decade with significant improvements in usability under cross-platform conditions. However, despite their obvious advantage in natural language interaction, voice-enabled web applications are still far and few between. In this work, we attempt to bridge this gap by bringing keyword spotting capabilities directly into the browser. To our knowledge, we are the first to demonstrate a fully-functional implementation of convolutional neural networks in pure JavaScript that runs in any standards-compliant browser. We also apply network slimming, a model compression technique, to explore the accuracy-efficiency tradeoffs, reporting latency measurements on a range of devices and software. Overall, our robust, cross-device implementation for keyword spotting realizes a new paradigm for serving neural network applications, and one of our slim models reduces latency by 66% with a minimal decrease in accuracy of 4% from 94% to 90%.",arXiv.org,2018.0,17,2,"[{'authorId': '2108395397', 'name': 'Jaejun Lee'}, {'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
836ca0698fca9bd9064db242273fd03714782eb8,https://www.semanticscholar.org/paper/836ca0698fca9bd9064db242273fd03714782eb8,What Do Viewers Say to Their TVs?: An Analysis of Voice Queries to Entertainment Systems,"A recently-introduced product of Comcast, a large cable company in the United States, is a ""voice remote"" that accepts spoken queries from viewers. We present an analysis of a large query log from this service to answer the question: ""What do viewers say to their TVs?"" In addition to a descriptive characterization of queries and sessions, we describe two complementary types of analyses to support query understanding. First, we propose a domain-specific intent taxonomy to characterize viewer behavior: as expected, most intents revolve around watching programs---both direct navigation as well as browsing---but there is a non-trivial fraction of non-viewing intents as well. Second, we propose a domain-specific tagging scheme for labeling query tokens, that when combined with intent and program prediction, provides a multi-faceted approach to understand voice queries directed at entertainment systems.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2018.0,13,5,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
87d4e7caaa5940aee1bff826bd4b702d72e189c9,https://www.semanticscholar.org/paper/87d4e7caaa5940aee1bff826bd4b702d72e189c9,Streaming Voice Query Recognition using Causal Convolutional Recurrent Neural Networks,"Voice-enabled commercial products are ubiquitous, typically enabled by lightweight on-device keyword spotting (KWS) and full automatic speech recognition (ASR) in the cloud. ASR systems require significant computational resources in training and for inference, not to mention copious amounts of annotated speech data. KWS systems, on the other hand, are less resource-intensive but have limited capabilities. On the Comcast Xfinity X1 entertainment platform, we explore a middle ground between ASR and KWS: We introduce a novel, resource-efficient neural network for voice query recognition that is much more accurate than state-of-the-art CNNs for KWS, yet can be easily trained and deployed with limited resources. On an evaluation dataset representing the top 200 voice queries, we achieve a low false alarm rate of 1% and a query error rate of 6%. Our model performs inference 8.24x faster than the current ASR system.",arXiv.org,2018.0,16,3,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '47125226', 'name': 'Gefei Yang'}, {'authorId': '2115313105', 'name': 'H. Wei'}, {'authorId': '49600216', 'name': 'Yajie Mao'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a208e6e70f47753bc6319d851f26978425ed3d24,https://www.semanticscholar.org/paper/a208e6e70f47753bc6319d851f26978425ed3d24,Progress and Tradeoffs in Neural Language Models,"In recent years, we have witnessed a dramatic shift towards techniques driven by neural networks for a variety of NLP tasks. Undoubtedly, neural language models (NLMs) have reduced perplexity by impressive amounts. This progress, however, comes at a substantial cost in performance, in terms of inference latency and energy consumption, which is particularly of concern in deployments on mobile devices. This paper, which examines the quality-performance tradeoff of various language modeling techniques, represents to our knowledge the first to make this observation. We compare state-of-the-art NLMs with ""classic"" Kneser-Ney (KN) LMs in terms of energy usage, latency, perplexity, and prediction accuracy using two standard benchmarks. On a Raspberry Pi, we find that orders of increase in latency and energy usage correspond to less change in perplexity, while the difference is much less pronounced on a desktop.",arXiv.org,2018.0,24,5,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b0723029fab0b3b5deb904ea0b8c96c660fc92ef,https://www.semanticscholar.org/paper/b0723029fab0b3b5deb904ea0b8c96c660fc92ef,CNNs for NLP in the Browser: Client-Side Deployment and Visualization Opportunities,"We demonstrate a JavaScript implementation of a convolutional neural network that performs feedforward inference completely in the browser. Such a deployment means that models can run completely on the client, on a wide range of devices, without making backend server requests. This design is useful for applications with stringent latency requirements or low connectivity. Our evaluations show the feasibility of JavaScript as a deployment target. Furthermore, an in-browser implementation enables seamless integration with the JavaScript ecosystem for information visualization, providing opportunities to visually inspect neural networks and better understand their inner workings.",North American Chapter of the Association for Computational Linguistics,2018.0,11,3,"[{'authorId': '2119122975', 'name': 'Yiyun Liang'}, {'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '46217011', 'name': 'Laetitia Huang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
beccae35572827f1ddffc50c0bba7be612bb80bf,https://www.semanticscholar.org/paper/beccae35572827f1ddffc50c0bba7be612bb80bf,Multi-Task Learning with Neural Networks for Voice Query Understanding on an Entertainment Platform,"We tackle the challenge of understanding voice queries posed against the Comcast Xfinity X1 entertainment platform, where consumers direct speech input at their ""voice remotes"". Such queries range from specific program navigation (i.e., watch a movie) to requests with vague intents and even queries that have nothing to do with watching TV. We present successively richer neural network architectures to tackle this challenge based on two key insights: The first is that session context can be exploited to disambiguate queries and recover from ASR errors, which we operationalize with hierarchical recurrent neural networks. The second insight is that query understanding requires evidence integration across multiple related tasks, which we identify as program prediction, intent classification, and query tagging. We present a novel multi-task neural architecture that jointly learns to accomplish all three tasks. Our initial model, already deployed in production, serves millions of queries daily with an improved customer experience. The novel multi-task learning model, first described here, is evaluated through carefully-controlled laboratory experiments, which demonstrates further gains in effectiveness and increased system capabilities.",Knowledge Discovery and Data Mining,2018.0,38,20,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
bf6bc1cb32c15fccb20c9d0f57a8f52056be5948,https://www.semanticscholar.org/paper/bf6bc1cb32c15fccb20c9d0f57a8f52056be5948,Farewell Freebase: Migrating the SimpleQuestions Dataset to DBpedia,"Question answering over knowledge graphs is an important problem of interest both commercially and academically. There is substantial interest in the class of natural language questions that can be answered via the lookup of a single fact, driven by the availability of the popular SimpleQuestions dataset. The problem with this dataset, however, is that answer triples are provided from Freebase, which has been defunct for several years. As a result, it is difficult to build ‚Äúreal-world‚Äù question answering systems that are operationally deployable. Furthermore, a defunct knowledge graph means that much of the infrastructure for querying, browsing, and manipulating triples no longer exists. To address this problem, we present SimpleDBpediaQA, a new benchmark dataset for simple question answering over knowledge graphs that was created by mapping SimpleQuestions entities and predicates from Freebase to DBpedia. Although this mapping is conceptually straightforward, there are a number of nuances that make the task non-trivial, owing to the different conceptual organizations of the two knowledge graphs. To lay the foundation for future research using this dataset, we leverage recent work to provide simple yet strong baselines with and without neural networks.",International Conference on Computational Linguistics,2018.0,13,30,"[{'authorId': '144189463', 'name': 'Michael Azmy'}, {'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1743316', 'name': 'Ihab F. Ilyas'}]"
c4f64976777c94b04291a305b8e5a573605d04fa,https://www.semanticscholar.org/paper/c4f64976777c94b04291a305b8e5a573605d04fa,The Evolution of Content Analysis for Personalized Recommendations at Twitter,"We present a broad overview of personalized content recommendations at Twitter, discussing how our approach has evolved over the years, represented by several generations of systems. Historically, content analysis of Tweets has not been a priority, and instead engineering efforts have focused on graph-based recommendation techniques that exploit structural properties of the follow graph and engagement signals from users. These represent ""low hanging fruits"" that have enabled high-quality recommendations using simple algorithms. As deployed systems have grown in maturity and our understanding of the problem space has become more refined, we have begun to look for other opportunities to further improve recommendation quality. We overview recent investments in content analysis, particularly named-entity recognition techniques built around recurrent neural networks, and discuss how they integrate with existing graph-based capabilities to open up the design space of content recommendation algorithms.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2018.0,5,4,"[{'authorId': '2982669', 'name': 'A. Grewal'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ca9c3f29f9d10ba4a69cb6871e0edb01bb7b68a2,https://www.semanticscholar.org/paper/ca9c3f29f9d10ba4a69cb6871e0edb01bb7b68a2,The Impact of Score Ties on Repeatability in Document Ranking,"Document ranking experiments should be repeatable. However, the interaction between multi-threaded indexing and score ties during retrieval may yield non-deterministic rankings, making repeatability not as trivial as one might imagine. In the context of the open-source Lucene search engine, score ties are broken by internal document ids, which are assigned at index time. Due to multi-threaded indexing, which makes experimentation with large modern document collections practical, internal document ids are not assigned consistently between different index instances of the same collection, and thus score ties are broken unpredictably. This short paper examines the effectiveness impact of such score ties, quantifying the variability that can be attributed to this phenomenon. The obvious solution to this non-determinism and to ensure repeatable document ranking is to break score ties using external collection document ids. This approach, however, comes with measurable efficiency costs due to the necessity of consulting external identifiers during query evaluation.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2018.0,13,17,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2377909', 'name': 'Peilin Yang'}]"
cbbf21a41b7779f64008a2720480d46223c8d615,https://www.semanticscholar.org/paper/cbbf21a41b7779f64008a2720480d46223c8d615,Pay-Per-Request Deployment of Neural Network Models Using Serverless Architectures,"We demonstrate the serverless deployment of neural networks for model inferencing in NLP applications using Amazon‚Äôs Lambda service for feedforward evaluation and DynamoDB for storing word embeddings. Our architecture realizes a pay-per-request pricing model, requiring zero ongoing costs for maintaining server instances. All virtual machine management is handled behind the scenes by the cloud provider without any direct developer intervention. We describe a number of techniques that allow efficient use of serverless resources, and evaluations confirm that our design is both scalable and inexpensive.",North American Chapter of the Association for Computational Linguistics,2018.0,8,25,"[{'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '145802648', 'name': 'Mengping Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
cf084450b2a8bbc88bf0e1c316ccdf95efe5bb62,https://www.semanticscholar.org/paper/cf084450b2a8bbc88bf0e1c316ccdf95efe5bb62,RecService: Distributed Real-Time Graph Processing at Twitter,"We present RecService, a distributed real-time graph processing engine that drives billions of recommendations on Twitter. Real-time recommendations are framed in terms of a user‚Äôs social context and real-time events incident on that social context, generated from ad hoc point queries and long-lived standing queries. Results form the basis of downstream processes that power a variety of recommendation products. A noteworthy aspect of the system‚Äôs design is a partitioning scheme whereby manipulations of graph adjacency lists are local to a cluster node. This eliminates cross-node network traffic in query execution, enabling horizontal scalability and avoiding ‚Äúhot spots‚Äù caused by vertices with large degrees.",USENIX Workshop on Hot Topics in Cloud Computing,2018.0,12,8,"[{'authorId': '2982669', 'name': 'A. Grewal'}, {'authorId': '2116635559', 'name': 'Jerry Jiang'}, {'authorId': '2526400', 'name': 'G. Lam'}, {'authorId': '51113376', 'name': 'Tristan Jung'}, {'authorId': '51114194', 'name': 'Lohith Vuddemarri'}, {'authorId': '2108645975', 'name': 'Quannan Li'}, {'authorId': '2170270', 'name': 'Aaditya G. Landge'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d6cafee46ac303099d95d6bcd68d65042f62661b,https://www.semanticscholar.org/paper/d6cafee46ac303099d95d6bcd68d65042f62661b,Evaluation-as-a-Service for the Computational Sciences,"Evaluation in empirical computer science is essential to show progress and assess technologies developed. Several research domains such as information retrieval have long relied on systematic evaluation to measure progress: here, the Cranfield paradigm of creating shared test collections, defining search tasks, and collecting ground truth for these tasks has persisted up until now. In recent years, however, several new challenges have emerged that do not fit this paradigm very well: extremely large data sets, confidential data sets as found in the medical domain, and rapidly changing data sets as often encountered in industry. Crowdsourcing has also changed the way in which industry approaches problem-solving with companies now organizing challenges and handing out monetary awards to incentivize people to work on their challenges, particularly in the field of machine learning. This article is based on discussions at a workshop on Evaluation-as-a-Service (EaaS). EaaS is the paradigm of not providing data sets to participants and have them work on the data locally, but keeping the data central and allowing access via Application Programming Interfaces (API), Virtual Machines (VM), or other possibilities to ship executables. The objectives of this article are to summarize and compare the current approaches and consolidate the experiences of these approaches to outline the next steps of EaaS, particularly toward sustainable research infrastructures. The article summarizes several existing approaches to EaaS and analyzes their usage scenarios and also the advantages and disadvantages. The many factors influencing EaaS are summarized, and the environment in terms of motivations for the various stakeholders, from funding agencies to challenge organizers, researchers and participants, to industry interested in supplying real-world problems for which they require solutions. EaaS solves many problems of the current research environment, where data sets are often not accessible to many researchers. Executables of published tools are equally often not available making the reproducibility of results impossible. EaaS, however, creates reusable/citable data sets as well as available executables. Many challenges remain, but such a framework for research can also foster more collaboration between researchers, potentially increasing the speed of obtaining research results.",ACM Journal of Data and Information Quality,2018.0,93,20,"[{'authorId': '1699657', 'name': 'A. Hanbury'}, {'authorId': '2151194032', 'name': 'H. M√ºller'}, {'authorId': '1680484', 'name': 'K. Balog'}, {'authorId': '2437825', 'name': 'Torben Brodt'}, {'authorId': '3114123', 'name': 'G. Cormack'}, {'authorId': '1724386', 'name': 'Ivan Eggel'}, {'authorId': '2734888', 'name': 'Tim Gollub'}, {'authorId': '1759761', 'name': 'F. Hopfgartner'}, {'authorId': '1401724111', 'name': 'Jayashree Kalpathy-Cramer'}, {'authorId': '1678892', 'name': 'N. Kando'}, {'authorId': '1927081', 'name': 'Anastasia Krithara'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2066268952', 'name': 'Simon Mercer'}, {'authorId': '3046200', 'name': 'Martin Potthast'}]"
dc3f342803766ed68bf80da6ec0f380d0b59cb76,https://www.semanticscholar.org/paper/dc3f342803766ed68bf80da6ec0f380d0b59cb76,Evaluation-as-a-Service for the Computational Sciences: Overview and Outlook,"ing with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciic permission and/or a fee. Request permissions from permissions@acm.org. ¬© 2018 Association for Computing Machinery. 1936-1955/2018/7-ART1 $15.00 https://doi.org/0000001.0000001 ACM Journal of Data and Information Quality, Vol. 1, No. 1, Article 1. Publication date: July 2018. 1:2 Hopfgartner et al. EaaS solves many problems of the current research environment, where data sets are often not accessible to many researchers. Executables of published tools are equally often not available making the reproducibility of results impossible. EaaS on the other hand creates reusable/citable data sets as well as available executables. Many challenges remain but such a framework for research can also foster more collaboration between researchers, potentially increasing the speed of obtaining research results. CCS Concepts: ¬∑ Information systems ‚Üí Data management systems; Information systems applications; Information retrieval; Additional",,2018.0,61,21,"[{'authorId': '1759761', 'name': 'F. Hopfgartner'}, {'authorId': '1699657', 'name': 'A. Hanbury'}, {'authorId': '2151194032', 'name': 'H. M√ºller'}, {'authorId': '1724386', 'name': 'Ivan Eggel'}, {'authorId': '1680484', 'name': 'K. Balog'}, {'authorId': '2437825', 'name': 'Torben Brodt'}, {'authorId': '3114123', 'name': 'G. Cormack'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1401724111', 'name': 'Jayashree Kalpathy-Cramer'}, {'authorId': '1678892', 'name': 'N. Kando'}, {'authorId': '32878737', 'name': 'Makoto P. Kato'}, {'authorId': '1927081', 'name': 'Anastasia Krithara'}, {'authorId': '2734888', 'name': 'Tim Gollub'}, {'authorId': '3046200', 'name': 'Martin Potthast'}, {'authorId': '2832706', 'name': 'E. Viegas'}, {'authorId': '2066268952', 'name': 'Simon Mercer'}]"
dfbe3538750137fad45673a0ec84b054ee2956d8,https://www.semanticscholar.org/paper/dfbe3538750137fad45673a0ec84b054ee2956d8,H2oloo at TREC 2018: Cross-Collection Relevance Transfer for the Common Core Track,,Text Retrieval Conference,2018.0,15,4,"[{'authorId': '52189929', 'name': 'Ruifan Yu'}, {'authorId': '94510137', 'name': 'Yuhao Xie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e1c0b76d725ba260564177c83b6a7ed46882ab3d,https://www.semanticscholar.org/paper/e1c0b76d725ba260564177c83b6a7ed46882ab3d,Derivative data for Web Archives for Longitudinal Knowledge (WALK),"These are derivative files generated by the Web Archives for Longitudinal Knowledge (WALK) project, which ran between 2016 and 2018. WALK was an interdisciplinary project spearheaded by scholars at York University, the University of Waterloo, and the University of Alberta. The project's goal was to bring together major Canadian web archive holdings and provide researcher access to search indexes and derivative files, including plain text, network diagrams, and domain frequency information. These will be useful to digital humanists who want to work with text at scale or the hyperlink networks of large parts of the archived Web. 
 
Six universities participated: the University of Toronto, University of Alberta, University of Victoria, University of Winnipeg, Dalhousie University, and Simon Fraser University. These files reflect the state of their public web archives in late-2017 to mid-2018. 
 
Each xz file contains: derivative files for a given collection, a GraphML file which you can load with Gephi (it will not have any basic layouts or transformations done to it, requiring you to do so manually), a csv file that explains the distribution of domains within the web archive, and a txt file that contains the plain text extracted from HTML documents within the web archive. You can find the crawl date, full URL, and the plain text of each page within the txt file. It may also contain a GEXF file which you can load with Gephi. It will have a basic layout courtesy of our GraphPass program, allowing you to see major nodes and communities in the network. 
 
This project has evolved into the Archives Unleashed Project. Information on Archives Unleashed and the WALK project can be found at https://archivesunleashed.org and on our blog at https://news.archivesunleashed.org.",,2018.0,0,0,"[{'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '28929508', 'name': 'Ryan Deschamps'}, {'authorId': '48029163', 'name': 'Samantha Fritz'}]"
081d6cf68ab29a71286d8bd8fd774546b1073ef8,https://www.semanticscholar.org/paper/081d6cf68ab29a71286d8bd8fd774546b1073ef8,Query Driven Algorithm Selection in Early Stage Retrieval,"Large scale retrieval systems often employ cascaded ranking architectures, in which an initial set of candidate documents are iteratively refined and re-ranked by increasingly sophisticated and expensive ranking models. In this paper, we propose a unified framework for predicting a range of performance-sensitive parameters based on minimizing end-to-end effectiveness loss. The framework does not require relevance judgments for training, is amenable to predicting a wide range of parameters, allows for fine tuned efficiency-effectiveness trade-offs, and can be easily deployed in large scale search systems with minimal overhead. As a proof of concept, we show that the framework can accurately predict a number of performance parameters on a query-by-query basis, allowing efficient and effective retrieval, while simultaneously minimizing the tail latency of an early-stage candidate generation system. On the 50 million document ClueWeb09B collection, and across 25,000 queries, our hybrid system can achieve superior early-stage efficiency to fixed parameter systems without loss of effectiveness, and allows more finely-grained efficiency-effectiveness trade-offs across the multiple stages of the retrieval system.",Web Search and Data Mining,2017.0,69,47,"[{'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '144159418', 'name': 'J. Culpepper'}, {'authorId': '144367841', 'name': 'Roi Blanco'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0a6d2eeaa0b75b5a21583fbd75637a1541f30487,https://www.semanticscholar.org/paper/0a6d2eeaa0b75b5a21583fbd75637a1541f30487,Online In-Situ Interleaved Evaluation of Real-Time Push Notification Systems,"Real-time push notification systems monitor continuous document streams such as social media posts and alert users to relevant content directly on their mobile devices. We describe a user study of such systems in the context of the TREC 2016 Real-Time Summarization Track, where system updates are immediately delivered as push notifications to the mobile devices of a cohort of users. Our study represents, to our knowledge, the first deployment of an interleaved evaluation framework for prospective information needs, and also provides an opportunity to examine user behavior in a realistic setting. Results of our online in-situ evaluation are correlated against the results a more traditional post-hoc batch evaluation. We observe substantial correlations between many online and batch evaluation metrics, especially for those that share the same basic design (e.g., are utility-based). For some metrics, we observe little correlation, but are able to identify the volume of messages that a system pushes as one major source of differences.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,33,15,"[{'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0b6a659f8647053340d0505f5e3369698b5f5ce9,https://www.semanticscholar.org/paper/0b6a659f8647053340d0505f5e3369698b5f5ce9,In-Browser Interactive SQL Analytics with Afterburner,"This demonstration explores the novel and unconventional idea of implementing an analytical RDBMS in pure JavaScript so that it runs completely inside a browser with no external dependencies. Our prototype, called Afterburner, generates compiled query plans that exploit two JavaScript features: typed arrays and asm.js. On the TPC-H benchmark, we show that Afterburner achieves comparable performance to MonetDB running natively on the same machine. This is an interesting finding in that it shows how far JavaScript has come as an efficient execution platform. Beyond a mere technical curiosity, we demonstrate how our techniques can support interactive data exploration by automatically generating materialized views from a backend that is then shipped to the browser to facilitate subsequent interactions seamlessly and efficiently.",SIGMOD Conference,2017.0,11,10,"[{'authorId': '2531258', 'name': 'Kareem El Gebaly'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1154add9af6c19c8b264331308ec99776583c52d,https://www.semanticscholar.org/paper/1154add9af6c19c8b264331308ec99776583c52d,Strong Baselines for Simple Question Answering over Knowledge Graphs with and without Neural Networks,"We examine the problem of question answering over knowledge graphs, focusing on simple questions that can be answered by the lookup of a single fact. Adopting a straightforward decomposition of the problem into entity detection, entity linking, relation prediction, and evidence combination, we explore simple yet strong baselines. On the popular SimpleQuestions dataset, we find that basic LSTMs and GRUs plus a few heuristics yield accuracies that approach the state of the art, and techniques that do not use neural networks also perform reasonably well. These results show that gains from sophisticated deep learning techniques proposed in the literature are quite modest and that some previous models exhibit unnecessary complexity.",North American Chapter of the Association for Computational Linguistics,2017.0,24,92,"[{'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '1884766', 'name': 'Peng Shi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1b0a3fca046dc667f425e0375cc3e5ded76bee49,https://www.semanticscholar.org/paper/1b0a3fca046dc667f425e0375cc3e5ded76bee49,A Comparison of Nuggets and Clusters for Evaluating Timeline Summaries,"There is growing interest in systems that generate timeline summaries by filtering high-volume streams of documents to retain only those that are relevant to a particular event or topic. Continued advances in algorithms and techniques for this task depend on standardized and reproducible evaluation methodologies for comparing systems. However, timeline summary evaluation is still in its infancy, with competing methodologies currently being explored in international evaluation forums such as TREC. One area of active exploration is how to explicitly represent the units of information that should appear in a ""good"" summary. Currently, there are two main approaches, one based on identifying nuggets in an external ""ground truth"", and the other based on clustering system outputs. In this paper, by building test collections that have both nugget and cluster annotations, we are able to compare these two approaches. Specifically, we address questions related to evaluation effort, differences in the final evaluation products, and correlations between scores and rankings generated by both approaches. We summarize advantages and disadvantages of nuggets and clusters to offer recommendations for future system evaluations.",International Conference on Information and Knowledge Management,2017.0,29,4,"[{'authorId': '143801279', 'name': 'G. Baruah'}, {'authorId': '1740893', 'name': 'R. McCreadie'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1dc4a7e9ec13929ddab26a58e105231cec3c81da,https://www.semanticscholar.org/paper/1dc4a7e9ec13929ddab26a58e105231cec3c81da,Quantization in Append-Only Collections,"Quantization, the pre-calculation and conversion to integers of term/document weights in an inverted index, is a well studied aspect of search engines that substantially improves retrieval efficiency. Previous work has considered the impact of quantization on effectiveness-efficiency tradeoffs in retrieval, for example, exploring the relationship between collection size and quantization range in static web collections. We extend previous work to append-only collections and examine whether quantization settings derived from prior time periods can be applied to future time periods. Experiments confirm that previous results generalize to a collection with different characteristics and with a different ranking function, and that in an append-only collection, we can use previous quantization settings in future time periods without substantial losses in either effectiveness or efficiency.",International Conference on the Theory of Information Retrieval,2017.0,17,2,"[{'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2911979850e027732118bf98a6e5b0408e859bb7,https://www.semanticscholar.org/paper/2911979850e027732118bf98a6e5b0408e859bb7,Efficient and Effective Tail Latency Minimization in Multi-Stage Retrieval Systems,,arXiv.org,2017.0,0,2,"[{'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '144159418', 'name': 'J. Culpepper'}, {'authorId': '144367841', 'name': 'Roi Blanco'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2d851f1f5e34e915b4b7e91add282238098ee2da,https://www.semanticscholar.org/paper/2d851f1f5e34e915b4b7e91add282238098ee2da,Mining the Temporal Statistics of Query Terms for Searching Social Media Posts,"There is an emerging consensus that time is an important indicator of relevance for searching streams of social media posts. In a process similar to pseudo-relevance feedback, the distribution of document timestamps from the results of an initial query can be leveraged to infer the distribution of relevant documents, for example, using kernel density estimation. In this paper, we explore an alternative approach to mining relevance signals directly from the temporal statistics of query terms in the collection, without the need to perform an initial retrieval. We propose two approaches: a linear ranking model that combines features derived from temporal collection statistics of query terms and a regression-based method that attempts to directly predict the distribution of relevant documents from query term statistics. Experiments on standard tweet test collections show that our proposed methods significantly outperform competitive baselines. Furthermore, studies of different feature combinations show the extent to which different types of temporal signals impact retrieval effectiveness.",International Conference on the Theory of Information Retrieval,2017.0,22,10,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145523874', 'name': 'Xing Niu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3080ec6f388e2a6dfa9504ed9d0a149995099fe0,https://www.semanticscholar.org/paper/3080ec6f388e2a6dfa9504ed9d0a149995099fe0,Warcbase: Scalable Analytics Infrastructure for Exploring Web Archives,"Web archiving initiatives around the world capture ephemeral Web content to preserve our collective digital memory. However, unlocking the potential of Web archives for humanities scholars and social scientists requires a scalable analytics infrastructure to support exploration of captured content. We present Warcbase, an open-source Web archiving platform that aims to fill this need. Our platform takes advantage of modern open-source ‚Äúbig data‚Äù infrastructure, namely Hadoop, HBase, and Spark, that has been widely deployed in industry. Warcbase provides two main capabilities: support for temporal browsing and a domain-specific language that allows scholars to interrogate Web archives in several different ways. This work represents a collaboration between computer scientists and historians, where we have engaged in iterative codesign to build tools for scholars with no formal computer science training. To provide guidance, we propose a process model for scholarly interactions with Web archives that begins with a question and proceeds iteratively through four main steps: filter, analyze, aggregate, and visualize. We call this the FAAV cycle for short and illustrate with three prototypical case studies. This article presents the current state of the project and discusses future directions.",ACM Journal on Computing and Cultural Heritage,2017.0,54,26,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '36149375', 'name': 'Jeremy Wiebe'}, {'authorId': '2064473584', 'name': 'Alice Zhou'}]"
346a0ff5743e36f227f1a3df0fafb43c8631c559,https://www.semanticscholar.org/paper/346a0ff5743e36f227f1a3df0fafb43c8631c559,The Pareto Frontier of Utility Models as a Framework for Evaluating Push Notification Systems,"We propose a utility-based framework for the evaluation of push notification systems that monitor document streams for users' topics of interest. Our starting point is that users derive either positive utility (i.e., ""gain"") or negative utility (i.e., ""pain"") from consuming system updates. By separately keeping track of these quantities, we can measure system effectiveness in a gain vs. pain tradeoff space. The Pareto Frontier of evaluated systems represents the state of the art: for each system on the frontier, no other system can offer more gain without more pain. Our framework has several advantages: it unifies three previous TREC evaluations, subsumes existing metrics, and provides more insightful analyses. Furthermore, our approach can easily accommodate more refined user models and is extensible to different information-seeking modalities.",International Conference on the Theory of Information Retrieval,2017.0,20,1,"[{'authorId': '143801279', 'name': 'G. Baruah'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3b70f47daef52168f3a6b743ad729cc8b25f5736,https://www.semanticscholar.org/paper/3b70f47daef52168f3a6b743ad729cc8b25f5736,The role of index compression in score-at-a-time query evaluation,,Information Retrieval Journal,2017.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}]"
3c3e27872d7f1a0f783c49b809a58d3ad4b8d904,https://www.semanticscholar.org/paper/3c3e27872d7f1a0f783c49b809a58d3ad4b8d904,Exploring the Effectiveness of Convolutional Neural Networks for Answer Selection in End-to-End Question Answering,"Most work on natural language question answering today focuses on answer selection: given a candidate list of sentences, determine which contains the answer. Although important, answer selection is only one stage in a standard end-to-end question answering pipeline. This paper explores the effectiveness of convolutional neural networks (CNNs) for answer selection in an end-to-end context using the standard TrecQA dataset. We observe that a simple idf-weighted word overlap algorithm forms a very strong baseline, and that despite substantial efforts by the community in applying deep learning to tackle answer selection, the gains are modest at best on this dataset. Furthermore, it is unclear if a CNN is more effective than the baseline in an end-to-end context based on standard retrieval metrics. To further explore this finding, we conducted a manual user evaluation, which confirms that answers from the CNN are detectably better than those from idf-weighted word overlap. This result suggests that users are sensitive to relatively small differences in answer selection quality.",arXiv.org,2017.0,30,21,"[{'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '143801279', 'name': 'G. Baruah'}, {'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3d418dcdc92948867a0b2597ffeca9cae29d2f51,https://www.semanticscholar.org/paper/3d418dcdc92948867a0b2597ffeca9cae29d2f51,Warcbase,"Web archiving initiatives around the world capture ephemeral Web content to preserve our collective digital memory. However, unlocking the potential of Web archives for humanities scholars and social scientists requires a scalable analytics infrastructure to support exploration of captured content. We present Warcbase, an open-source Web archiving platform that aims to fill this need. Our platform takes advantage of modern open-source ‚Äúbig data‚Äù infrastructure, namely Hadoop, HBase, and Spark, that has been widely deployed in industry. Warcbase provides two main capabilities: support for temporal browsing and a domain-specific language that allows scholars to interrogate Web archives in several different ways. This work represents a collaboration between computer scientists and historians, where we have engaged in iterative codesign to build tools for scholars with no formal computer science training. To provide guidance, we propose a process model for scholarly interactions with Web archives that begins with a question and proceeds iteratively through four main steps: filter, analyze, aggregate, and visualize. We call this the FAAV cycle for short and illustrate with three prototypical case studies. This article presents the current state of the project and discusses future directions.",,2017.0,0,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '36149375', 'name': 'Jeremy Wiebe'}, {'authorId': '2064473584', 'name': 'Alice Zhou'}]"
497ebc6faeca695740a402ba5ee974f3d3a6ee38,https://www.semanticscholar.org/paper/497ebc6faeca695740a402ba5ee974f3d3a6ee38,The Lucene for Information Access and Retrieval Research (LIARR) Workshop at SIGIR 2017,"As an empirical discipline, information access and retrieval research requires substantial software infrastructure to index and search large collections. This workshop is motivated by the desire to better align information retrieval research with the practice of building search applications from the perspective of open-source information retrieval systems. Our goal is to promote the use of Lucene for information access and retrieval research.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,23,16,"[{'authorId': '1716332', 'name': 'L. Azzopardi'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145344526', 'name': 'Hui Fang'}, {'authorId': '49667583', 'name': 'Grant Ingersoll'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2678472', 'name': 'Yashar Moshfeghi'}, {'authorId': '8842143', 'name': 'Harrisen Scells'}, {'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]"
4d7485c4837ebe75d2b94b6aa1f91e8e84f95998,https://www.semanticscholar.org/paper/4d7485c4837ebe75d2b94b6aa1f91e8e84f95998,Experiments with Convolutional Neural Network Models for Answer Selection,"In recent years, neural networks have been applied to many text processing problems. One example is learning a similarity function between pairs of text, which has applications to paraphrase extraction, plagiarism detection, question answering, and ad hoc retrieval. Within the information retrieval community, the convolutional neural network model proposed by Severyn and Moschitti in a SIGIR 2015 paper has gained prominence. This paper focuses on the problem of answer selection for question answering: we attempt to replicate the results of Severyn and Moschitti using their open-source code as well as to reproduce their results via a de novo (i.e., from scratch) implementation using a completely different deep learning toolkit. Our de novo implementation is instructive in ascertaining whether reported results generalize across toolkits, each of which have their idiosyncrasies. We were able to successfully replicate and reproduce the reported results of Severyn and Moschitti, albeit with minor differences in effectiveness, but affirming the overall design of their model. Additional ablation experiments break down the components of the model to show their contributions to overall effectiveness. Interestingly, we find that removing one component actually increases effectiveness and that a simplified model with only four word overlap features performs surprisingly well, even better than convolution feature maps alone.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,23,27,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4e9ab80136a61eb7f76fa3d41cd77cb8ceabe003,https://www.semanticscholar.org/paper/4e9ab80136a61eb7f76fa3d41cd77cb8ceabe003,Honk: A PyTorch Reimplementation of Convolutional Neural Networks for Keyword Spotting,"We describe Honk, an open-source PyTorch reimplementation of convolutional neural networks for keyword spotting that are included as examples in TensorFlow. These models are useful for recognizing ""command triggers"" in speech-based interfaces (e.g., ""Hey Siri""), which serve as explicit cues for audio recordings of utterances that are sent to the cloud for full speech recognition. Evaluation on Google's recently released Speech Commands Dataset shows that our reimplementation is comparable in accuracy and provides a starting point for future work on the keyword spotting task.",arXiv.org,2017.0,3,33,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4ee8622f5dacb44e4af6bc9ee1c8f48a48983d9a,https://www.semanticscholar.org/paper/4ee8622f5dacb44e4af6bc9ee1c8f48a48983d9a,Deep Residual Learning for Small-Footprint Keyword Spotting,"We explore the application of deep residual learning and dilated convolutions to the keyword spotting task, using the recently-released Google Speech Commands Dataset as our benchmark. Our best residual network (ResNet) implementation significantly outperforms Google's previous convolutional neural networks in terms of accuracy. By varying model depth and width, we can achieve compact models that also outperform previous small-footprint variants. To our knowledge, we are the first to examine these approaches for keyword spotting, and our results establish an open-source state-of-the-art reference to support the development of future speech-based interfaces.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2017.0,12,207,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5e913bc0ae97d94b8fe099b950e0421b0f2e199d,https://www.semanticscholar.org/paper/5e913bc0ae97d94b8fe099b950e0421b0f2e199d,Event Detection on Curated Tweet Streams,"We present a system for identifying interesting social media posts on Twitter and delivering them to users' mobile devices in real time as push notifications. In our problem formulation, users are interested in broad topics such as politics, sports, and entertainment: our system processes tweets in real time to identify relevant, novel, and salient content. There are three interesting aspects to our work: First, instead of attempting to tame the cacophony of unfiltered tweets, we exploit a smaller, but still sizeable, collection of curated tweet streams corresponding to the Twitter accounts of different media outlets. Second, we apply distant supervision to extract topic labels from curated streams that have a specific focus, which can then be leveraged to build high-quality topic classifiers essentially ""for free"". Finally, our system delivers content via Twitter direct messages, supporting in situ interactions modeled after conversations with intelligent agents. These ideas are demonstrated in an end-to-end working prototype.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,16,2,"[{'authorId': '3404697', 'name': 'Nimesh Ghelani'}, {'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '2108547731', 'name': 'Shine Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5fbe4fe2f27d458c5f0208de18d036445d45b4a2,https://www.semanticscholar.org/paper/5fbe4fe2f27d458c5f0208de18d036445d45b4a2,A Comparison of Document-at-a-Time and Score-at-a-Time Query Evaluation,"We present an empirical comparison between document-at-a-time (DaaT) and score-at-a-time (SaaT) document ranking strategies within a common framework. Although both strategies have been extensively explored, the literature lacks a fair, direct comparison: such a study has been difficult due to vastly different query evaluation mechanics and index organizations. Our work controls for score quantization, document processing, compression, implementation language, implementation effort, and a number of details, arriving at an empirical evaluation that fairly characterizes the performance of three specific techniques: WAND (DaaT), BMW (DaaT), and JASS (SaaT). Experiments reveal a number of interesting findings. The performance gap between WAND and BMW is not as clear as the literature suggests, and both methods are susceptible to tail queries that may take orders of magnitude longer than the median query to execute. Surprisingly, approximate query evaluation in WAND and BMW does not significantly reduce the risk of these tail queries. Overall, JASS is slightly slower than either WAND or BMW, but exhibits much lower variance in query latencies and is much less susceptible to tail query effects. Furthermore, JASS query latency is not particularly sensitive to the retrieval depth, making it an appealing solution for performance-sensitive applications where bounds on query latencies are desirable.",Web Search and Data Mining,2017.0,41,52,"[{'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '144159418', 'name': 'J. Culpepper'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '47470313', 'name': 'J. Mackenzie'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
60980635db288e287ae58e60f4e7b47d87768e5e,https://www.semanticscholar.org/paper/60980635db288e287ae58e60f4e7b47d87768e5e,An Exploration of Serverless Architectures for Information Retrieval,"Serverless architectures represent a new approach to designing applications in the cloud without having to explicitly provision or manage servers. The developer specifies functions with well-defined entry and exit points, and the cloud provider handles all other aspects of execution. In this paper, we explore a novel application of serverless architectures to information retrieval and describe a search engine built in this manner with Amazon Web Services: postings lists are stored in the DynamoDB NoSQL store and the postings traversal algorithm for query evaluation is implemented in the Lambda service. The result is a search engine that scales elastically with a pay-per-request model, in contrast to a server-based model that requires paying for running instances even if there are no requests. We empirically assess the performance and economics of our serverless architecture. While our implementation is currently too slow for interactive searching, analysis shows that the pay-per-request model is economically compelling, and future infrastructure improvements will increase the attractiveness of serverless designs over time.",International Conference on the Theory of Information Retrieval,2017.0,15,24,"[{'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
61344ba701960b3d16e4792216e4b2ef9bc7c570,https://www.semanticscholar.org/paper/61344ba701960b3d16e4792216e4b2ef9bc7c570,Anserini: Enabling the Use of Lucene for Information Retrieval Research,"Software toolkits play an essential role in information retrieval research. Most open-source toolkits developed by academics are designed to facilitate the evaluation of retrieval models over standard test collections. Efforts are generally directed toward better ranking and less attention is usually given to scalability and other operational considerations. On the other hand, Lucene has become the de facto platform in industry for building search applications (outside a small number of companies that deploy custom infrastructure). Compared to academic IR toolkits, Lucene can handle heterogeneous web collections at scale, but lacks systematic support for evaluation over standard test collections. This paper introduces Anserini, a new information retrieval toolkit that aims to provide the best of both worlds, to better align information retrieval practice and research. Anserini provides wrappers and extensions on top of core Lucene libraries that allow researchers to use more intuitive APIs to accomplish common research tasks. Our initial efforts have focused on three functionalities: scalable, multi-threaded inverted indexing to handle modern web-scale collections, streamlined IR evaluation for ad hoc retrieval on standard test collections, and an extensible architecture for multi-stage ranking. Anserini ships with support for many TREC test collections, providing a convenient way to replicate competitive baselines right out of the box. Experiments verify that our system is both efficient and effective, providing a solid foundation to support future research.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,19,344,"[{'authorId': '2377909', 'name': 'Peilin Yang'}, {'authorId': '145344526', 'name': 'Hui Fang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6fac336ba0ce1e1fa40e2e7a0086dc79af96c5de,https://www.semanticscholar.org/paper/6fac336ba0ce1e1fa40e2e7a0086dc79af96c5de,"On the Reusability of ""Living Labs"" Test Collections: A Case Study of Real-Time Summarization","Information retrieval test collections are typically built using data from large-scale evaluations in international forums such as TREC, CLEF, and NTCIR. Previous validation studies on pool-based test collections for ad hoc retrieval have examined their reusability to accurately assess the effectiveness of systems that did not participate in the original evaluation. To our knowledge, the reusability of test collections derived from ""living labs"" evaluations, based on logs of user activity, has not been explored. In this paper, we performed a ""leave-one-out"" analysis of human judgment data derived from the TREC 2016 Real-Time Summarization Track and show that those judgments do not appear to be reusable. While this finding is limited to one specific evaluation, it does call into question the reusability of test collections built from living labs in general, and at the very least suggests the need for additional work in validating such experimental instruments.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,15,6,"[{'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '143801279', 'name': 'G. Baruah'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
714c220aa528771f39c67cbff2b5ecdba7d4182b,https://www.semanticscholar.org/paper/714c220aa528771f39c67cbff2b5ecdba7d4182b,An Exploration of Approaches to Integrating Neural Reranking Models in Multi-Stage Ranking Architectures,"We explore different approaches to integrating a simple convolutional neural network (CNN) with the Lucene search engine in a multi-stage ranking architecture. Our models are trained using the PyTorch deep learning toolkit, which is implemented in C/C++ with a Python frontend. One obvious integration strategy is to expose the neural network directly as a service. For this, we use Apache Thrift, a software framework for building scalable cross-language services. In exploring alternative architectures, we observe that once trained, the feedforward evaluation of neural networks is quite straightforward. Therefore, we can extract the parameters of a trained CNN from PyTorch and import the model into Java, taking advantage of the Java Deeplearning4J library for feedforward evaluation. This has the advantage that the entire end-to-end system can be implemented in Java. As a third approach, we can extract the neural network from PyTorch and ""compile"" it into a C++ program that exposes a Thrift service. We evaluate these alternatives in terms of performance (latency and throughput) as well as ease of integration. Experiments show that feedforward evaluation of the convolutional neural network is significantly slower in Java, while the performance of the compiled C++ network does not consistently beat the PyTorch implementation.",arXiv.org,2017.0,27,7,"[{'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '2142322143', 'name': 'Junchen Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
729c23cd07b23a9dfdb1b4c733d0b710efcb7a68,https://www.semanticscholar.org/paper/729c23cd07b23a9dfdb1b4c733d0b710efcb7a68,"Finally, a Downloadable Test Collection of Tweets","Due to Twitter's terms of service that forbid redistribution of content, creating publicly downloadable collections of tweets for research purposes has been a perpetual problem for the research community. Some collections are distributed by making available the ids of the tweets that comprise the collection and providing tools to fetch the actual content; this approach has scalability limitations. In other cases, evaluation organizers have set up APIs that provide access to collections for specific tasks, without exposing the underlying content. This is a workable solution, but difficult to sustain over the long term since someone has to maintain the APIs. We have noticed that the non-profit Internet Archive has been making available for public download captures of the so-called Twitter ""spritzer"" stream, which is the same source as the Tweets2013 collection used in the TREC 2013 and 2014 Microblog Tracks. We analyzed both datasets in terms of content overlap and retrieval baselines to show that the Internet Archive data can serve as a drop-in replacement for the Tweets2013 collection, thereby providing the research community with, finally, a downloadable collection of tweets. Beyond this finding, we also study the impact of tweet deletions over time and how they affect the test collections.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,10,17,"[{'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7549a6e03afdd42ae94c19235db076319eeb34f8,https://www.semanticscholar.org/paper/7549a6e03afdd42ae94c19235db076319eeb34f8,Do We Need Specialized Graph Databases?: Benchmarking Real-Time Social Networking Applications,"With the advent of online social networks, there is an increasing demand for storage and processing of graph-structured data. Social networking applications pose new challenges to data management systems due to demand for real-time querying and manipulation of the graph structure. Recently, several systems specialized systems for graph-structured data have been introduced. However, whether we should abandon mature RDBMS technology for graph databases remains an ongoing discussion. In this paper we present an graph database benchmarking architecture built on the existing LDBC Social Network Benchmark. Our proposed architecture stresses the systems with an interactive transactional workload to better simulate the real-time nature of social networking applications. Using this improved architecture, we evaluated a selection of specialized graph databases, RDF stores, and RDBMSes adapted for graphs. We do not find that specialized graph databases provide definitively better performance.",GRADES@SIGMOD/PODS,2017.0,11,32,"[{'authorId': '4047075', 'name': 'Anil Pacaci'}, {'authorId': '2064473584', 'name': 'Alice Zhou'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1705151', 'name': 'M. Tamer √ñzsu'}]"
7b54c5bcd4f79e06b441dc650feb2cc581cd1f1e,https://www.semanticscholar.org/paper/7b54c5bcd4f79e06b441dc650feb2cc581cd1f1e,Integrating Lexical and Temporal Signals in Neural Ranking Models for Searching Social Media Streams,"Time is an important relevance signal when searching streams of social media posts. The distribution of document timestamps from the results of an initial query can be leveraged to infer the distribution of relevant documents, which can then be used to rerank the initial results. Previous experiments have shown that kernel density estimation is a simple yet effective implementation of this idea. This paper explores an alternative approach to mining temporal signals with recurrent neural networks. Our intuition is that neural networks provide a more expressive framework to capture the temporal coherence of neighboring documents in time. To our knowledge, we are the first to integrate lexical and temporal signals in an end-to-end neural network architecture, in which existing neural ranking models are used to generate query-document similarity vectors that feed into a bidirectional LSTM layer for temporal modeling. Our results are mixed: existing neural models for document ranking alone yield limited improvements over simple baselines, but the integration of lexical and temporal signals yield significant improvements over competitive temporal baselines.",arXiv.org,2017.0,39,7,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '2249980', 'name': 'R. Sequiera'}, {'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c1c350ff5dc1cec4f0336656457cd4b8d345eeb2,https://www.semanticscholar.org/paper/c1c350ff5dc1cec4f0336656457cd4b8d345eeb2,Distant Supervision for Topic Classification of Tweets in Curated Streams,"We tackle the challenge of topic classification of tweets in the context of analyzing a large collection of curated streams by news outlets and other organizations to deliver relevant content to users. Our approach is novel in applying distant supervision based on semi-automatically identifying curated streams that are topically focused (for example, on politics, entertainment, or sports). These streams provide a source of labeled data to train topic classifiers that can then be applied to categorize tweets from more topically-diffuse streams. Experiments on both noisy labels and human ground-truth judgments demonstrate that our approach yields good topic classifiers essentially ""for free"", and that topic classifiers trained in this manner are able to dynamically adjust for topic drift as news on Twitter evolves.",arXiv.org,2017.0,12,4,"[{'authorId': '10677993', 'name': 'Salman Mohammed'}, {'authorId': '3404697', 'name': 'Nimesh Ghelani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c95cb204a9b45a81fc8b12eec57ae6f421730d2c,https://www.semanticscholar.org/paper/c95cb204a9b45a81fc8b12eec57ae6f421730d2c,An Experimental Analysis of the Power Consumption of Convolutional Neural Networks for Keyword Spotting,"Nearly all previous work on small-footprint keyword spotting with neural networks quantify model footprint in terms of the number of parameters and multiply operations for a feedforward inference pass. These values are, however, proxy measures since empirical performance in actual deployments is determined by many factors. In this paper, we study the power consumption of a family of convolutional neural networks for keyword spotting on a Raspberry Pi. We find that both proxies are good predictors of energy usage, although the number of multiplies is more predictive than the number of model parameters. We also confirm that models with the highest accuracies are, unsurprisingly, the most power hungry.","IEEE International Conference on Acoustics, Speech, and Signal Processing",2017.0,7,44,"[{'authorId': '26917433', 'name': 'Raphael Tang'}, {'authorId': '2210946166', 'name': 'Weijie Wang'}, {'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ce9d6d26cb46c512519d77265a538c1ed6138da6,https://www.semanticscholar.org/paper/ce9d6d26cb46c512519d77265a538c1ed6138da6,Portable In-Browser Data Cube Exploration,"Data cubes, which summarize data across multiple dimensions, have been a staple of On Line Analytical Processing (OLAP) for well over a decade. While users typically access data cubes through data warehouse systems or business intelligence tools, we demonstrate that data cubes can be explored effectively and efficiently inside a browser. We provide an overview of the two recent technologies that enable our portable data cube exploration approach: 1) Afterburner, an in-browser relational database management system, and 2) explanation tables, an information-theoretic technique for guided data cube exploration.",,2017.0,14,1,"[{'authorId': '2531258', 'name': 'Kareem El Gebaly'}, {'authorId': '2285679174', 'name': 'Lukasz Golab'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d70e934197efdd5dc1da13442049c31e0790d167,https://www.semanticscholar.org/paper/d70e934197efdd5dc1da13442049c31e0790d167,An Insight Extraction System on BioMedical Literature with Deep Neural Networks,"Mining biomedical text offers an opportunity to automatically discover important facts and infer associations among them. As new scientific findings appear across a large collection of biomedical publications, our aim is to tap into this literature to automate biomedical knowledge extraction and identify important insights from them. Towards that goal, we develop a system with novel deep neural networks to extract insights on biomedical literature. Evaluation shows our system is able to provide insights with competitive accuracy of human acceptance and its relation extraction component outperforms previous work.",Conference on Empirical Methods in Natural Language Processing,2017.0,43,9,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '1680568', 'name': 'Kris Ganjam'}, {'authorId': '1678877', 'name': 'Navendu Jain'}, {'authorId': '2099527432', 'name': 'J. Lundin'}, {'authorId': '34286525', 'name': 'Ryen W. White'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e15541855ed6b514b62ba70e308b4865c305da35,https://www.semanticscholar.org/paper/e15541855ed6b514b62ba70e308b4865c305da35,In Defense of MapReduce,Don't throw the MapReduce baby out with the bath water!,IEEE Internet Computing,2017.0,13,2,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ea2adc520181056f41419d14ed2c0a4926821ff7,https://www.semanticscholar.org/paper/ea2adc520181056f41419d14ed2c0a4926821ff7,Talking to Your TV: Context-Aware Voice Search with Hierarchical Recurrent Neural Networks,"We tackle the novel problem of navigational voice queries posed against an entertainment system, where viewers interact with a voice-enabled remote controller to specify the TV program to watch. This is a difficult problem for several reasons: such queries are short, even shorter than comparable voice queries in other domains, which offers fewer opportunities for deciphering user intent. Furthermore, ambiguity is exacerbated by underlying speech recognition errors. We address these challenges by integrating word- and character-level query representations and by modeling voice search sessions to capture the contextual dependencies in query sequences. Both are accomplished with a probabilistic framework in which recurrent and feedforward neural network modules are organized in a hierarchical manner. From a raw dataset of 32M voice queries from 2.5M viewers on the Comcast Xfinity X1 entertainment system, we extracted data to train and test our models. We demonstrate the benefits of our hybrid representation and context-aware model, which significantly outperforms competitive baselines that use learning to rank as well as neural networks.",International Conference on Information and Knowledge Management,2017.0,49,17,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '2226722', 'name': 'O. Jojic'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ea70aefddcd70b0f63e3588468453790cfc9e598,https://www.semanticscholar.org/paper/ea70aefddcd70b0f63e3588468453790cfc9e598,Automatically Extracting High-Quality Negative Examples for Answer Selection in Question Answering,"We propose a heuristic called ""one answer per document"" for automatically extracting high-quality negative examples for answer selection in question answering. Starting with a collection of question-answer pairs from the popular TrecQA dataset, we identify the original documents from which the answers were drawn. Sentences from these source documents that contain query terms (aside from the answers) are selected as negative examples. Training on the original data plus these negative examples yields improvements in effectiveness by a margin that is comparable to successive recent publications on this dataset. Our technique is completely unsupervised, which means that the gains come essentially for free. We confirm that the improvements can be directly attributed to our heuristic, as other approaches to extracting comparable amounts of training data are not effective. Beyond the empirical validation of this heuristic, we also share our improved TrecQA dataset with the community to support further work in answer selection.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2017.0,17,10,"[{'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1689089', 'name': 'Mark D. Smucker'}]"
f2f0befc0b8798364734be1a840eef8ed7c0ea96,https://www.semanticscholar.org/paper/f2f0befc0b8798364734be1a840eef8ed7c0ea96,The Lambda and the Kappa,"Whether lambda or kappa, there‚Äôs no free lunch!",IEEE Internet Computing,2017.0,13,47,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f8a45eb4737a63b774b56b378e17ae197a33d103,https://www.semanticscholar.org/paper/f8a45eb4737a63b774b56b378e17ae197a33d103,Partitioning and Segment Organization Strategies for Real-Time Selective Search on Document Streams,"The basic idea behind selective search is to partition a collection into topical clusters, and for each query, consider only a subset of the clusters that are likely to contain relevant documents. Previous work on web collections has shown that it is possible to retain high-quality results while considering only a small fraction of the collection. These studies, however, assume static collections where it is feasible to run batch clustering algorithms for partitioning. In this work, we consider the novel formulation of selective search on document streams (specifically, tweets), where partitioning must be performed incrementally. In our approach, documents are partitioned into temporal segments and selective search is performed within each segment: these segments can either be clustered using batch or online algorithms, and at different temporal granularities. For efficiency, we take advantage of word embeddings to reduce the dimensionality of the document vectors. Experiments with test collections from the TREC Microblog Tracks show that we are able to achieve precision indistinguishable from exhaustive search while considering only around 5% of the collection. Interestingly, we observe no significant effectiveness differences between batch vs. online clustering and between hourly vs. daily temporal segments, despite them being very different index organizations. This suggests that architectural choices should be primarily guided by efficiency considerations.",Web Search and Data Mining,2017.0,50,1,"[{'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
fb36a5c9975d6468873fc0b279a6d08b77e20e4d,https://www.semanticscholar.org/paper/fb36a5c9975d6468873fc0b279a6d08b77e20e4d,The role of index compression in score-at-a-time query evaluation,,Information Retrieval Journal,2017.0,52,12,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}]"
00b874f8346cedadc2a6366c4b72e60140f99556,https://www.semanticscholar.org/paper/00b874f8346cedadc2a6366c4b72e60140f99556,UMD-TTIC-UW at SemEval-2016 Task 1: Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement,"We describe an attention-based convolutional neural network for the English semantic textual similarity (STS) task in the SemEval2016 competition (Agirre et al., 2016). We develop an attention-based input interaction layer and incorporate it into our multiperspective convolutional neural network (He et al., 2015), using the PARAGRAM-PHRASE word embeddings (Wieting et al., 2016) trained on paraphrase pairs. Without using any sparse features, our final model outperforms the winning entry in STS2015 when evaluated on the STS2015 data.",International Workshop on Semantic Evaluation,2016.0,34,30,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '1771118', 'name': 'J. Wieting'}, {'authorId': '1700980', 'name': 'Kevin Gimpel'}, {'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0503db9c16df658b63e9c75a50261e03c5b4bceb,https://www.semanticscholar.org/paper/0503db9c16df658b63e9c75a50261e03c5b4bceb,Sampling Strategies and Active Learning for Volume Estimation,"This paper tackles the challenge of accurately and efficiently estimating the number of relevant documents in a collection for a particular topic. One real-world application is estimating the volume of social media posts (e.g., tweets) pertaining to a topic, which is fundamental to tracking the popularity of politicians and brands, the potential sales of a product, etc. Our insight is to leverage active learning techniques to find all the ""easy"" documents, and then to use sampling techniques to infer the number of relevant documents in the residual collection. We propose a simple yet effective technique for determining this ""switchover"" point, which intuitively can be understood as the ""knee"" in an effort vs. recall gain curve, as well as alternative sampling strategies beyond the knee. We show on several TREC datasets and a collection of tweets that our best technique yields more accurate estimates (with the same effort) than several alternatives.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2016.0,9,12,"[{'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3114123', 'name': 'G. Cormack'}, {'authorId': '1689089', 'name': 'Mark D. Smucker'}]"
0806321b65562ea4e5ef037be5fd9c754fc23298,https://www.semanticscholar.org/paper/0806321b65562ea4e5ef037be5fd9c754fc23298,Interleaved Evaluation for Retrospective Summarization and Prospective Notification on Document Streams,"We propose and validate a novel interleaved evaluation methodology for two complementary information seeking tasks on document streams: retrospective summarization and prospective notification. In the first, the user desires relevant and non-redundant documents that capture important aspects of an information need. In the second, the user wishes to receive timely, relevant, and non-redundant update notifications for a standing information need. Despite superficial similarities, interleaved evaluation methods for web ranking cannot be directly applied to these tasks; for example, existing techniques do not account for temporality or redundancy. Our proposed evaluation methodology consists of two components: a temporal interleaving strategy and a heuristic for credit assignment to handle redundancy. By simulating user interactions with interleaved results on submitted runs to the TREC 2014 tweet timeline generation (TTG) task and the TREC 2015 real-time filtering task, we demonstrate that our methodology yields system comparisons that accurately match the result of batch evaluations. Analysis further reveals weaknesses in current batch evaluation methodologies to suggest future directions for research.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2016.0,23,13,"[{'authorId': '103365891', 'name': 'Xin Qian'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}]"
184198994820da09e00ae51f954b67400ffbf985,https://www.semanticscholar.org/paper/184198994820da09e00ae51f954b67400ffbf985,Toward Reproducible Baselines: The Open-Source IR Reproducibility Challenge,,European Conference on Information Retrieval,2016.0,19,105,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '144987107', 'name': 'Jamie Callan'}, {'authorId': '50434807', 'name': 'Ishan Chattopadhyaya'}, {'authorId': '144078659', 'name': 'John Foley'}, {'authorId': '49667583', 'name': 'Grant Ingersoll'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '1737624', 'name': 'S. Vigna'}]"
29006d8c9c2247fca4cd3a22822c2b042e85572d,https://www.semanticscholar.org/paper/29006d8c9c2247fca4cd3a22822c2b042e85572d,Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement,"Textual similarity measurement is a challenging problem, as it requires understanding the semantics of input sentences. Most previous neural network models use coarse-grained sentence modeling, which has difficulty capturing fine-grained word-level information for semantic comparisons. As an alternative, we propose to explicitly model pairwise word interactions and present a novel similarity focus mechanism to identify important correspondences for better similarity measurement. Our ideas are implemented in a novel neural network architecture that demonstrates state-ofthe-art accuracy on three SemEval tasks and two answer selection tasks.",North American Chapter of the Association for Computational Linguistics,2016.0,73,233,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2b1a28417592fa3091e261401d0f93c7d08597f8,https://www.semanticscholar.org/paper/2b1a28417592fa3091e261401d0f93c7d08597f8,An Exploration of Evaluation Metrics for Mobile Push Notifications,"How do we evaluate systems that filter social media streams and send users updates via push notifications on their mobile phones? Such notifications must be relevant, timely, and novel. In this paper, we explore various evaluation metrics for this task, focusing specifically on measuring relevance. We begin with an analysis of metrics deployed at the TREC 2015 Microblog evaluations. A simple change to the metrics, reflecting a different assumption, dramatically alters system rankings. Applying another metric, previously used in the TREC Microblog evaluations, again yields different system rankings. We find little correlation between a number of ""reasonable"" evaluation metrics, which suggests that system effectiveness depends on how you measure it---an undesirable state in IR evaluation. However, we argue that existing evaluation metrics can be generalized into a framework that uses the same underlying contingency table, but places different weights and penalties. Although we stop short of proposing the ""one true metric"", this framework can guide the future development of a family of metrics that more accurately models user needs.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2016.0,5,23,"[{'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1751287', 'name': 'C. Clarke'}]"
2e4078ec4ee2ab3d3fb583f1b1761d8d6c576e30,https://www.semanticscholar.org/paper/2e4078ec4ee2ab3d3fb583f1b1761d8d6c576e30,"Retrievability in API-Based ""Evaluation as a Service""","""Evaluation as a service"" (EaaS) refers to a family of related evaluation methodologies that enables community-wide evaluations and the construction of test collections on documents that cannot be easily distributed. In the API-based approach, the basic idea is that evaluation organizers provide a service API through which the evaluation task can be completed, without providing access to the raw collection. One concern with this evaluation approach is that the API introduces biases and limits the diversity of techniques that can be brought to bear on the problem. In this paper, we tackle the question of API bias using the concept of retrievability. The raw data for our analyses come from a naturally-occurring experiment where we observed the same groups completing the same task with the API and also with access to the raw collection. We find that the retrievability bias of runs generated in both cases are comparable. Moreover, the fraction of relevant tweets retrieved through the API by the participating groups is at least as high as when they had access to the raw collection.",International Conference on the Theory of Information Retrieval,2016.0,8,7,"[{'authorId': '2071527', 'name': 'Jiaul H. Paik'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
30add08eff92b58003a9e6cfe13ff5659edd36d6,https://www.semanticscholar.org/paper/30add08eff92b58003a9e6cfe13ff5659edd36d6,Exploring and Discovering Archive-It Collections with Warcbase,,Digital Humanities Conference,2016.0,0,0,"[{'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '36149375', 'name': 'Jeremy Wiebe'}, {'authorId': '2064473584', 'name': 'Alice Zhou'}]"
336ce21be76879f19c01b68726558269907ea02b,https://www.semanticscholar.org/paper/336ce21be76879f19c01b68726558269907ea02b,Noise-Contrastive Estimation for Answer Selection with Deep Neural Networks,"We study answer selection for question answering, in which given a question and a set of candidate answer sentences, the goal is to identify the subset that contains the answer. Unlike previous work which treats this task as a straightforward pointwise classification problem, we model this problem as a ranking task and propose a pairwise ranking approach that can directly exploit existing pointwise neural network models as base components. We extend the Noise-Contrastive Estimation approach with a triplet ranking loss function to exploit interactions in triplet inputs over the question paired with positive and negative examples. Experiments on TrecQA and WikiQA datasets show that our approach achieves state-of-the-art effectiveness without the need for external knowledge sources or feature engineering.",International Conference on Information and Knowledge Management,2016.0,24,159,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
343500e0052eb1b683f32b00efbbd1331c94184a,https://www.semanticscholar.org/paper/343500e0052eb1b683f32b00efbbd1331c94184a,Sapphire: Querying RDF Data Made Simple,"There is currently a large amount of publicly accessible structured data available as RDF data sets. For example, the Linked Open Data (LOD) cloud now consists of thousands of RDF data sets with over 30 billion triples, and the number and size of the data sets is continuously growing. Many of the data sets in the LOD cloud provide public SPARQL endpoints to allow issuing queries over them. These end-points enable users to retrieve data using precise and highly expressive SPARQL queries. However, in order to do so, the user must have sufficient knowledge about the data sets that she wishes to query, that is, the structure of data, the vocabulary used within the data set, the exact values of literals, their data types, etc. Thus, while SPARQL is powerful, it is not easy to use. An alternative to SPARQL that does not require as much prior knowledge of the data is some form of keyword search over the structured data. Keyword search queries are easy to use, but inherently ambiguous in describing structured queries. 
 
This demonstration introduces Sapphire, a system for querying RDF data that strikes a middle ground between ambiguous keyword search and difficult-to-use SPARQL. Our system does not replace either, but utilizes both where they are most effective. Sapphire helps the user construct expressive SPARQL queries that represent her information needs without requiring detailed knowledge about the queried data sets. These queries are then executed over public SPARQL endpoints from the LOD cloud. Sapphire guides the user in the query writing process by showing suggestions of query terms based on the queried data, and by recommending changes to the query based on a predictive user model.",Proceedings of the VLDB Endowment,2016.0,44,14,"[{'authorId': '90981528', 'name': 'Ahmed El-Roby'}, {'authorId': '2073283133', 'name': 'Khalid Ammar'}, {'authorId': '1704622', 'name': 'Ashraf Aboulnaga'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
36932d8f648bb39a65ea8ac2d1d982db864136de,https://www.semanticscholar.org/paper/36932d8f648bb39a65ea8ac2d1d982db864136de,Desiderata for exploratory search interfaces to Web archives in support of scholarly activities,"Web archiving initiatives around the world capture ephemeral web content to preserve our collective digital memory. In this paper, we describe initial experiences in providing an exploratory search interface to web archives for humanities scholars and social scientists. We describe our initial implementation and discuss our findings in terms of desiderata for such a system. It is clear that the standard organization of a search engine results page (SERP), consisting of an ordered list of hits, is inadequate to support the needs of scholars. Shneiderman's mantra for visual information seeking (‚Äúoverview first, zoom and filter, then details-on-demand‚Äù) provides a nice organizing principle for interface design, to which we propose an addendum: ‚ÄúMake everything transparent‚Äù. We elaborate on this by highlighting the importance of the temporal dimension of web pages as well as issues surrounding metadata and veracity.",ACM/IEEE Joint Conference on Digital Libraries,2016.0,16,26,"[{'authorId': '33630124', 'name': 'Andrew N. Jackson'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}]"
3c022b208240a711ae465454c93fad516a4e48cb,https://www.semanticscholar.org/paper/3c022b208240a711ae465454c93fad516a4e48cb,Afterburner: The Case for In-Browser Analytics,"This paper explores the novel and unconventional idea of implementing an analytical RDBMS in pure JavaScript so that it runs completely inside a browser with no external dependencies. Our prototype, called Afterburner, generates compiled query plans that exploit typed arrays and asm.js, two relatively recent advances in JavaScript. On a few simple queries, we show that Afterburner achieves comparable performance to MonetDB running natively on the same machine. This is an interesting finding in that it shows how far JavaScript has come as an efficient execution platform. Beyond a mere technical curiosity, we discuss how our techniques could support ubiquitous in-browser interactive analytics (potentially integrating with browser-based notebooks) and also present interesting opportunities for split-execution strategies where query operators are distributed between the browser and backend servers.",arXiv.org,2016.0,7,5,"[{'authorId': '2531258', 'name': 'Kareem El Gebaly'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3e030850b2dded6def4e9c157fc4d1c82cdcbcd1,https://www.semanticscholar.org/paper/3e030850b2dded6def4e9c157fc4d1c82cdcbcd1,Prizm: A Wireless Access Point for Proxy-Based Web Lifelogging,"We present Prizm, a prototype lifelogging device that comprehensively records a user's web activity. Prizm is a wireless access point deployed on a Raspberry Pi that is designed to be a substitute for the user's normal wireless access point. Prizm proxies all HTTP(S) requests from devices connected to it and records all activity it observes. Although this particular design is not entirely novel, there are a few features that are unique to our approach, most notably the physical deployment as a wireless access point. Such a package allows capture of activity from multiple devices, integration with web archiving for preservation, and support for offline operation. This paper describes the design of Prizm, the current status of our project, and future plans.",LTA@MM,2016.0,17,2,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '9548668', 'name': 'Zhucheng Tu'}, {'authorId': '120542794', 'name': 'M. Rose'}, {'authorId': '2093255870', 'name': 'Patrick White'}]"
43520ba60eb643f21494dac152002b650d808f09,https://www.semanticscholar.org/paper/43520ba60eb643f21494dac152002b650d808f09,Optimizing Nugget Annotations with Active Learning,"Nugget-based evaluations, such as those deployed in the TREC Temporal Summarization and Question Answering tracks, require human assessors to determine whether a nugget is present in a given piece of text. This process, known as nugget annotation, is labor-intensive. In this paper, we present two active learning techniques that prioritize the sequence in which candidate nugget/sentence pairs are presented to an assessor, based on the likelihood that the sentence contains a nugget. Our approach builds on the recognition that nugget annotation is similar to high-recall retrieval, and we adapt proven existing solutions. Simulation experiments with four existing TREC test collections show that our techniques yield far more matches for a given level of effort than baselines that are typically deployed in previous nugget-based evaluations.",International Conference on Information and Knowledge Management,2016.0,22,6,"[{'authorId': '143801279', 'name': 'G. Baruah'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '2025665', 'name': 'Rakesh Guttikonda'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1689089', 'name': 'Mark D. Smucker'}, {'authorId': '1712417', 'name': 'Olga Vechtomova'}]"
5d77fe775365a8a34909ddf2f155e423efe2e47b,https://www.semanticscholar.org/paper/5d77fe775365a8a34909ddf2f155e423efe2e47b,Ten Blue Links on Mars,"This paper explores a simple question: How would we provide a high-quality search experience on Mars, where the fundamental physical limit is speed-of-light propagation delays on the order of tens of minutes? On Earth, users are accustomed to nearly instantaneous responses from web services. Is it possible to overcome orders-of-magnitude longer latency to provide a tolerable user experience on Mars? In this paper, we formulate the searching from Mars problem as a tradeoff between ""effort"" (waiting for responses from Earth) and ""data transfer"" (pre-fetching or caching data on Mars). The contribution of our work is articulating this design space and presenting two case studies that explore the effectiveness of baseline techniques, using publicly available data from the TREC Total Recall and Sessions Tracks. We intend for this research problem to be aspirational as well as inspirational---even if one is not convinced by the premise of Mars colonization, there are Earth-based scenarios such as searching from rural villages in India that share similar constraints, thus making the problem worthy of exploration and attention from researchers.",The Web Conference,2016.0,30,0,"[{'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '3114123', 'name': 'G. Cormack'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}]"
66366b320038f637befd760626cc15b1362a92ca,https://www.semanticscholar.org/paper/66366b320038f637befd760626cc15b1362a92ca,The Effects of Latency Penalties in Evaluating Push Notification Systems,"We examine the effects of different latency penalties in the evaluation of push notification systems, as operationalized in the TREC 2015 Microblog track evaluation. The purpose of this study is to inform the design of metrics for the TREC 2016 Real-Time Summarization track, which is largely modeled after the TREC 2015 evaluation design.",arXiv.org,2016.0,3,2,"[{'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '1751287', 'name': 'C. Clarke'}]"
712f45af0a205bcdabd9605c9af7d307dd34d493,https://www.semanticscholar.org/paper/712f45af0a205bcdabd9605c9af7d307dd34d493,Overview of the TREC 2016 Real-Time Summarization Track,"Jimmy Lin, Adam Roegiest, Luchen Tan, Richard McCreadie, Ellen Voorhees, and Fernando Diaz 1 David R. Cheriton School of Computer Science, University of Waterloo, Ontario, Canada 2 School of Computing Science, University of Glasgow, Scotland, the United Kingdom 3 National Institute for Standards and Technology, Maryland, USA 4 Microsoft Research, New York, USA {jimmylin, aroegies, luchen.tan}@uwaterloo.ca richard.mccreadie@glasgow.ac.uk, ellen.voorhees@nist.gov, fdiaz@microsoft.com",Text Retrieval Conference,2016.0,20,73,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '1740893', 'name': 'R. McCreadie'}, {'authorId': '1746656', 'name': 'E. Voorhees'}, {'authorId': '2257864804', 'name': 'Fernando Diaz'}]"
726da0a56d118eb8e7708688d74e0a2836a8118c,https://www.semanticscholar.org/paper/726da0a56d118eb8e7708688d74e0a2836a8118c,Dynamic Trade-Off Prediction in Multi-Stage Retrieval Systems,"Modern multi-stage retrieval systems are comprised of a candidate generation stage followed by one or more reranking stages. In such an architecture, the quality of the final ranked list may not be sensitive to the quality of initial candidate pool, especially in terms of early precision. This provides several opportunities to increase retrieval efficiency without significantly sacrificing effectiveness. In this paper, we explore a new approach to dynamically predicting two different parameters in the candidate generation stage which can directly affect the overall efficiency and effectiveness of the entire system. Previous work exploring this tradeoff has focused on global parameter settings that apply to all queries, even though optimal settings vary across queries. In contrast, we propose a technique which makes a parameter prediction that maximizes efficiency within a effectiveness envelope on a per query basis, using only static pre-retrieval features. The query-specific tradeoff point between effectiveness and efficiency is decided using a classifier cascade that weighs possible efficiency gains against effectiveness losses over a range of possible parameter cutoffs to make the prediction. The interesting twist in our new approach is to train classifiers without requiring explicit relevance judgments. We show that our framework is generalizable by applying it to two different retrieval parameters - selecting k in common top-k query retrieval algorithms, and setting a quality threshold, $\rho$, for score-at-a-time approximate query evaluation algorithms. Experimental results show that substantial efficiency gains are achievable depending on the dynamic parameter choice. In addition, our framework provides a versatile tool that can be used to estimate the effectiveness-efficiency tradeoffs that are possible before selecting and tuning algorithms to make machine learned predictions.",arXiv.org,2016.0,40,1,"[{'authorId': '144159418', 'name': 'J. Culpepper'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7fe4e82231cf7293c2706fabe3b8ed533c89f498,https://www.semanticscholar.org/paper/7fe4e82231cf7293c2706fabe3b8ed533c89f498,A Platform for Streaming Push Notifications to Mobile Assessors,"We present an assessment platform for gathering online relevance judgments for mobile push notifications that will be deployed in the newly-created TREC 2016 Real-Time Summarization (RTS) track. There is emerging interest in building systems that filter social media streams such as tweets to identify interesting and novel content in real time, putatively for delivery to users' mobile phones. In our evaluation design, all participants subscribe to the Twitter streaming API to identify relevant tweets with respect to a set of interest profiles. As the systems generate results, they are pushed in real time to our evaluation broker via a REST API. The broker then ""routes"" the tweets to assessors who have installed a custom app on their mobile phones. We detail the design of this platform and discuss a number of challenges that need to be tackled in this type of ""Living Labs"" setup. It is our goal that such an evaluation design will mitigate any issues that have arisen in traditional batch-style evaluations of this type of task.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2016.0,12,8,"[{'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1751287', 'name': 'C. Clarke'}]"
9663a8d8365cbee4dd7c49b20edf11781a086c9a,https://www.semanticscholar.org/paper/9663a8d8365cbee4dd7c49b20edf11781a086c9a,Estimating topical volume in social media streams,"This paper tackles the problem of estimating the volume of social media posts (e.g., tweets) that pertain to a particular topic. This task differs from related filtering and event detection applications in that the filtered content isn't meant for direct human consumption, but rather we are primarily interested in estimating the cardinality of relevant posts. We present a simple yet effective technique for generating and curating keywords to create what we call ""overlap filters"", which can be applied to a stream of social media posts. Our approach leverages human labeling and thus a crucial element of the work involves minimizing the cost of human computation. On top of a ""day zero"" cold start algorithm, we describe a number of optimizations that take advantage of history to further reduce labeling costs. Experimental results show that our overlap filters produce accurate volume estimates at low costs, and our method is simple enough to deploy in practice.",ACM Symposium on Applied Computing,2016.0,15,8,"[{'authorId': '3083186', 'name': 'Praveen Bommannavar'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '69484854', 'name': 'A. Rajaraman'}]"
973ee7ce764dd3045f9545211f3c7a756f4fa823,https://www.semanticscholar.org/paper/973ee7ce764dd3045f9545211f3c7a756f4fa823,Burst Detection in Social Media Streams for Tracking Interest Profiles in Real Time,"This work presents RTTBurst, an end-to-end system for ingesting descriptions of user interest profiles and discovering new and relevant tweets based on those interest profiles using a simple model for identifying bursts in token usage. Our approach differs from standard retrieval-based techniques in that it primarily focuses on identifying noteworthy moments in the tweet stream, and ?summarizes? those moments using selected tweets. We lay out the architecture of RTTBurst, our participation in and performance at the TREC 2015 Microblog track, and a method for combining and potentially improving existing TREC systems. Official results and post hoc experiments show that our simple targeted burst detection technique is competitive with existing systems. Furthermore, we demonstrate that our burst detection mechanism can be used to improve the performance of other systems for the same task.",Text Retrieval Conference,2016.0,27,7,"[{'authorId': '145919650', 'name': 'C. Buntain'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9ce51ead885bf107f7725fa1d0461422e12d24c5,https://www.semanticscholar.org/paper/9ce51ead885bf107f7725fa1d0461422e12d24c5,Compressing and Decoding Term Statistics Time Series,,European Conference on Information Retrieval,2016.0,9,8,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145523874', 'name': 'Xing Niu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9df5ca4a2eb574c57fefd76b5e3e25d0e4da7f06,https://www.semanticscholar.org/paper/9df5ca4a2eb574c57fefd76b5e3e25d0e4da7f06,Evaluating Search Among Secrets,"Today‚Äôs search engines are designed with a single fundamental goal: to help us find the things we want to see. Paradoxically, the very fact that they do this well means that there are many collections that we are not allowed to search. Citizens are not allowed to search some government records because there may be intermixed information that needs to be protected. Scholars are not yet allowed to see much of the growing backlog of unprocessed archival collections for similar reasons. These limitations, and many more, are direct consequences of the fact that today‚Äôs search engines are not designed to protect sensitive information. We need to change that by creating a new class of search algorithms designed to effectively ‚Äúsearch among secrets‚Äù by balancing the user‚Äôs interest in finding relevant content with the provider‚Äôs interest in protecting sensitive content. This paper describes some first thoughts on evaluation for that task.",EVIA@NTCIR,2016.0,25,2,"[{'authorId': '1737250', 'name': 'Douglas W. Oard'}, {'authorId': '3214594', 'name': 'Katie Shilton'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9eb55f9a6aff2a70415cba21a23a538ee46a36fe,https://www.semanticscholar.org/paper/9eb55f9a6aff2a70415cba21a23a538ee46a36fe,GraphJet: Real-Time Content Recommendations at Twitter,"This paper presents GraphJet, a new graph-based system for generating content recommendations at Twitter. As motivation, we trace the evolution of our formulation and approach to the graph recommendation problem, embodied in successive generations of systems. Two trends can be identified: supplementing batch with real-time processing and a broadening of the scope of recommendations from users to content. Both of these trends come together in Graph-Jet, an in-memory graph processing engine that maintains a real-time bipartite interaction graph between users and tweets. The storage engine implements a simple API, but one that is sufficiently expressive to support a range of recommendation algorithms based on random walks that we have refined over the years. Similar to Cassovary, a previous graph recommendation engine developed at Twitter, GraphJet assumes that the entire graph can be held in memory on a single server. The system organizes the interaction graph into temporally-partitioned index segments that hold adjacency lists. GraphJet is able to support rapid ingestion of edges while concurrently serving lookup queries through a combination of compact edge encoding and a dynamic memory allocation scheme that exploits power-law characteristics of the graph. Each GraphJet server ingests up to one million graph edges per second, and in steady state, computes up to 500 recommendations per second, which translates into several million edge read operations per second.",Proceedings of the VLDB Endowment,2016.0,45,65,"[{'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '2116635559', 'name': 'Jerry Jiang'}, {'authorId': '3083186', 'name': 'Praveen Bommannavar'}, {'authorId': '2054132231', 'name': 'B. Larson'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a11869915e2618af61ae3eb785badd2c9caf2950,https://www.semanticscholar.org/paper/a11869915e2618af61ae3eb785badd2c9caf2950,Rank-at-a-Time Query Processing,"Query processing strategies for ranked retrieval have been studied for decades. In this paper we propose a new strategy, which we call rank-at-a-time query processing, that evaluates documents in descending order of quantized scores and is able to directly compute the final document ranking via a sequence of boolean intersections. We show that such a strategy is equivalent to a second-order restricted composition of per-term scores. Rank-at-a-time query processing has the advantage that it is anytime score-safe, which means that the retrieval algorithm can self-adapt to produce an exact ranking given an arbitrary latency constraint. Due to the combinatorial nature of compositions, however, a naive implementation is too slow to be of practical use. To address this issue, we introduce a hybrid variant that is able to reduce query latency to a point that is on par with state-of-the-art retrieval engines.",International Conference on the Theory of Information Retrieval,2016.0,17,1,"[{'authorId': '1911619', 'name': 'Ahmed Elbagoury'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
bb8af4ef931dbf4b1c59522c355f03746cc2c2fb,https://www.semanticscholar.org/paper/bb8af4ef931dbf4b1c59522c355f03746cc2c2fb,Simple Dynamic Emission Strategies for Microblog Filtering,"Push notifications from social media provide a method to keep up-to-date on topics of personal interest. To be effective, notifications must achieve a balance between pushing too much and pushing too little. Push too little and the user misses important updates; push too much and the user is overwhelmed by unwanted information. Using data from the TREC 2015 Microblog track, we explore simple dynamic emission strategies for microblog push notifications. The key to effective notifications lies in establishing and maintaining appropriate thresholds for pushing updates. We explore and evaluate multiple threshold setting strategies, including purely static thresholds, dynamic thresholds without user feedback, and dynamic thresholds with daily feedback. Our best technique takes advantage of daily feedback in a simple yet effective manner, achieving the best known result reported in the literature to date.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2016.0,13,25,"[{'authorId': '40379164', 'name': 'Luchen Tan'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
bce351f456d4c2cd9595d9fe0de49ec9f8fdccbf,https://www.semanticscholar.org/paper/bce351f456d4c2cd9595d9fe0de49ec9f8fdccbf,Computational Linguistics for Metadata Building (CLiMB) Text Mining for the Automatic Extraction of Subject Terms for Image Metadata,"In this paper, we present a fully-implemented system using computational linguistic techniques to apply automatic text mining for the extraction of metadata for image access. We describe the implementation of a workbench created for, and evaluated by, image catalogers. We discuss the current functionality and future goals for this image catalogers‚Äô toolkit, developed under the Computational Linguistics for Metadata Building (CLiMB) research project.1 Our primary user group for initial phases of the project is the cataloger expert; in future work we address applications for end users. 1 The Problem: Insufficient Subject Access to Images The CLiMB project addresses the existing gap in subject description in metadata for image collections, particularly for the domains of art history, architecture and landscape architecture. Within each of these domains, image collections are increasingly available online yet the availability of subject-oriented access points for these images remains minimal, at best. In an initial observational study conducted with six image catalogers, we found that typically between one and eight subject terms are added to catalog records for images and many legacy records lack subject entries altogether. The literature on end users‚Äô image searching practices indicates that this level of subject description may be insufficient for some user groups. In a study of the imagesearching behaviors of faculty and graduate students in the domain of American history [3], found that 92% of the thirty-eight participants considered the textual information associated with the images inadequate for the images searched in the Library of Congress‚Äô American Memory Collection. The individual records in this collection typically contain quantities of subject descriptors comparable to‚Äîor exceedingthose found in the exploratory CLiMB studies. Furthermore, this study found that this 1 This project was first funded by the Mellon Foundation to the Center for Research on Information Access at Columbia University. L. Klavans J., Sidhu T., Sheffield C., Soergel D., Lin J., Abels E. and Passonneau R. (2008). Computational Linguistics for Metadata Building (CLiMB) Text Mining for the Automatic Extraction of Subject Terms for Image Metadata. In Metadata Mining for Image Understanding, pages 3-12 DOI: 10.5220/0002338100030012 Copyright c ¬© SciTePress group of searchers submitted more subject-oriented queries than known author and title searches. Similar results demonstrating the importance of subject retrieval have been reported in other studies including [6], [4] and [2].",,2016.0,15,0,"[{'authorId': '1761739', 'name': 'Judith L. Klavans'}, {'authorId': '2060625143', 'name': 'Tandeep Sidhu'}, {'authorId': '145295358', 'name': 'Carolyn Sheffield'}, {'authorId': '1695420', 'name': 'D. Soergel'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '1703046', 'name': 'R. Passonneau'}]"
bdd91ae391925034980618daea7c3926240fcbc9,https://www.semanticscholar.org/paper/bdd91ae391925034980618daea7c3926240fcbc9,The Future of Big Data Is ... JavaScript?,"JavaScript has already made serious inroads as an integrated technology stack for building user-facing applications. In this article, the authors explore the idea of using JavaScript in Big Data platforms. Could the future be ... JavaScript everywhere?",IEEE Internet Computing,2016.0,19,8,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2531258', 'name': 'Kareem El Gebaly'}]"
d541f91aa0df5a0f012ab0bbc76b6c29664049bc,https://www.semanticscholar.org/paper/d541f91aa0df5a0f012ab0bbc76b6c29664049bc,In Vacuo and In Situ Evaluation of SIMD Codecs,"The size of a search engine index and the time to search are inextricably related through the compression codec. This investigation examines this tradeoff using several relatively unexplored SIMD-based codecs including QMX, TurboPackV, and TurboPFor. It uses (the non-SIMD) OPTPFor as a baseline. Four new variants of QMX are introduced and also compared. Those variants include optimizations for space and for time. Experiments were conducted on the TREC .gov2 collection using topics 701-850, in crawl order and in URL order. The results suggest that there is very little difference between these codecs, but that the reference implementation of QMX performs well.",Australasian Document Computing Symposium,2016.0,23,13,"[{'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ddfaa2f0d88e647bff64fc4b045b73d8cdbf5829,https://www.semanticscholar.org/paper/ddfaa2f0d88e647bff64fc4b045b73d8cdbf5829,Searching from Mars,"How would you search from Mars? It's the user model, stupid!",IEEE Internet Computing,2016.0,22,3,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '143801279', 'name': 'G. Baruah'}]"
dffc4ae0f2b1609ec9bea071e13fec1f4997f319,https://www.semanticscholar.org/paper/dffc4ae0f2b1609ec9bea071e13fec1f4997f319,Content selection and curation for web archiving: The gatekeepers vs. the masses,"Any preservation effort must begin with an assessment of what content to preserve, and web archiving is no different. There have historically been two answers to the question ‚Äúwhat should we archive?‚Äù The Internet Archive's broad entire-web crawls have been supplemented by narrower domain-or topic-specific collections gathered by numerous libraries. We can characterize this as content selection and curation by ‚Äúgatekeepers‚Äù. In contrast, we have witnessed the emergence of another approach driven by ‚Äúthe masses‚Äù - we can archive pages that are contained in social media streams such as Twitter. The interesting question, of course, is how these approaches differ. We provide an answer to this question in the context of a case study about the 2015 Canadian federal elections. Based on our analysis, we recommend a hybrid approach that combines an effort driven by social media and more traditional curatorial methods.",ACM/IEEE Joint Conference on Digital Libraries,2016.0,11,25,"[{'authorId': '144703130', 'name': 'Ian Milligan'}, {'authorId': '3412792', 'name': 'Nick Ruest'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e451c15fc62f8fdbf29741688b3f4f649dc4d058,https://www.semanticscholar.org/paper/e451c15fc62f8fdbf29741688b3f4f649dc4d058,Total Recall: Blue Sky on Mars,"There are presently plans to create permanent colonies on Mars so that humanity will have a second home. These colonists will need search, email, entertainment, and indeed most services provided on the modern web. The primary challenge is network latencies, since the two planets are anywhere from 4 to 24 light minutes apart. A recent article sketches out how we might develop search technologies for Mars based on physically transporting a cache of the web to Mars, to which updates are applied via predictive models. Within this general framework, we explore the problem of high-recall retrieval, such as conducting a scientific survey. We explore simple techniques for masking speed-of-light delays and find that ""priming"" the search process with a small Martian cache is sufficient to mask a moderate amount of network latency. Simulation experiments show that it is possible to engineer high-recall search from Mars to be quite similar to the experience on Earth.",International Conference on the Theory of Information Retrieval,2016.0,19,1,"[{'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '3114123', 'name': 'G. Cormack'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3198911', 'name': 'Adam Roegiest'}]"
e6800e4e647dffda7ee155872e8cf50e16fd1438,https://www.semanticscholar.org/paper/e6800e4e647dffda7ee155872e8cf50e16fd1438,Temporal Query Expansion Using a Continuous Hidden Markov Model,"In standard formulations of pseudo-relevance feedback, document timestamps do not play a role in identifying expansion terms. Yet we know that when searching social media posts such as tweets, relevant documents are bursty and usually occur in temporal clusters. The main insight of our work is that term expansions should be biased to draw from documents that occur in bursty temporal clusters. This is formally captured by a continuous hidden Markov model (cHMM), for which we derive an EM algorithm for parameter estimation. Given a query, we estimate the parameters for a cHMM that best explains the observed distribution of an initial set of retrieved documents, and then use Viterbi decoding to compute the most likely state sequence. In identifying expansion terms, we only select documents from bursty states. Experiments on test collections from the TREC 2011 and 2012 Microblog tracks show that our approach is significantly more effective than the popular RM3 pseudo-relevance feedback model.",International Conference on the Theory of Information Retrieval,2016.0,15,8,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e98eacb6be571eb9eca0df96630c9d75a0375f96,https://www.semanticscholar.org/paper/e98eacb6be571eb9eca0df96630c9d75a0375f96,Discovering key moments in social media streams,"This paper introduces a general technique, called LABurst, for identifying key moments, or moments of high impact, in social media streams without the need for domain-specific information or seed keywords. We leverage machine learning to model temporal patterns around bursts in Twitter's unfiltered public sample stream and build a classifier to identify tokens experiencing these bursts. We show LABurst performs competitively with existing burst detection techniques while simultaneously providing insight into and detection of unanticipated moments. To demonstrate our approach's potential, we compare two baseline event-detection algorithms with our language-agnostic algorithm to detect key moments across three major sporting competitions: 2013 World Series, 2014 Super Bowl, and 2014 World Cup. Our results show LABurst outperforms a time series analysis baseline and is competitive with a domain-specific baseline even though we operate without any domain knowledge. We then go further by transferring LABurst's models learned in the sports domain to the task of identifying earthquakes in Japan and show our method detects large spikes in earthquake-related tokens within two minutes of the actual event.",Consumer Communications and Networking Conference,2016.0,28,10,"[{'authorId': '145919650', 'name': 'C. Buntain'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1713898', 'name': 'J. Golbeck'}]"
f7a34579f122b240707874b6b76dc71af23ddb0f,https://www.semanticscholar.org/paper/f7a34579f122b240707874b6b76dc71af23ddb0f,Dynamic Cutoff Prediction in Multi-Stage Retrieval Systems,"Modern multi-stage retrieval systems are comprised of a candidate generation stage followed by one or more reranking stages. In such an architecture, the quality of the final ranked list may not be sensitive to the quality of the initial candidate pool, especially in terms of early precision. This provides several opportunities to increase retrieval efficiency without significantly sacrificing effectiveness. In this paper, we explore a new approach to dynamically predicting the size of an initial result set in the candidate generation stage, which can directly affect the overall efficiency and effectiveness of the entire system. Previous work exploring this tradeoff has focused on global parameter settings that apply to all queries, even though optimal settings vary across queries. In contrast, we propose a technique that makes a parameter prediction to maximize efficiency within an effectiveness envelope on a per query basis, using only static pre-retrieval features. Experimental results show that substantial efficiency gains are achievable. In addition, our framework provides a versatile tool that can be used to estimate the effectiveness-efficiency tradeoffs that are possible before selecting and tuning algorithms to make machine-learned predictions.",Australasian Document Computing Symposium,2016.0,34,47,"[{'authorId': '2259136389', 'name': 'J. S. Culpepper'}, {'authorId': '2285063964', 'name': 'Charles L. A. Clarke'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ffb4f43303b43c8a2b82709fa12c279c91512862,https://www.semanticscholar.org/paper/ffb4f43303b43c8a2b82709fa12c279c91512862,"Report on the SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR)","The SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR) took place on Thursday, August 13, 2015 in Santiago, Chile. The goal of the workshop was two fold. The first to provide a venue for the publication and presentation of negative results. The second was to provide a venue through which the authors of open source search engines could compare performance of indexing and searching on the same collections and on the same machines - encouraging the sharing of ideas and discoveries in a like-to-like environment. In total three papers were presented and seven systems participated.",SIGF,2016.0,7,62,"[{'authorId': '145096384', 'name': 'Jaime Arguello'}, {'authorId': '48221273', 'name': 'Matt Crane'}, {'authorId': '145472333', 'name': 'Fernando Diaz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}]"
021bd501daec77e139a932849ed2a5d14b3082f6,https://www.semanticscholar.org/paper/021bd501daec77e139a932849ed2a5d14b3082f6,Similar Sentences from English Wikipedia 20150304,,,2015.0,0,0,"[{'authorId': '47093806', 'name': 'Sarah Weissman'}, {'authorId': '2086592914', 'name': 'Joshua Bradley'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1691974', 'name': 'S. Ayhan'}]"
0bd9bd0ebcd371ab8c6a3137fa5df190816193f1,https://www.semanticscholar.org/paper/0bd9bd0ebcd371ab8c6a3137fa5df190816193f1,"SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR)","Many, if not most, published research papers in Information Retrieval (IR) describe the following process: the authors identify an opportunity to improve on a particular IR task, implement an experimental system, and compare its performance against one or more baselines (or a control condition, in the case of a user study). The quality of the research is judged based on the magnitude of the improvement and whether the methodological choices suggest external validity and generalizability, for example, whether the experimental setup is ‚Äúrealistic‚Äù or whether the baseline methods reflect the state of the art. Unfortunately, research demonstrating the failure to reproduce or generalize previous results does not have a similar publication venue. This sort of result‚Äîoften referred to as a ‚Äònegative result‚Äô‚Äîserves to control the quality of published research in a scientific discipline and to better understand the limits of previously published methods. Publication venues for such research exist in fields such as ecology, biomedicine, pharmacy,, and social science. The SIGIR 2015 Workshop on Reproducibility, Inexplicability, and Generalizability of Results (RIGOR) aims to provide a venue for publication and discussion of IR research that fails to reproduce a previously published result under the same or similar experimental conditions (e.g., same test collection and system configuration) and research that demonstrates the failure to generalize an existing approach to a new domain. To this end, we have developed a set of categories covering different ways in which a result may",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2015.0,2,14,"[{'authorId': '145096384', 'name': 'Jaime Arguello'}, {'authorId': '145472333', 'name': 'Fernando Diaz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}]"
17bf46324674f7d9b7ad5368b8d0469201865547,https://www.semanticscholar.org/paper/17bf46324674f7d9b7ad5368b8d0469201865547,On Building Better Mousetraps and Understanding the Human Condition,"Over the past few years, we have seen the emergence of ‚Äúbig data‚Äù: disruptive technologies that have transformed commerce, science, and many aspects of society. Despite the tremendous enthusiasm for big data, there is no shortage of detractors. This article argues that many criticisms stem from a fundamental confusion over goals: whether the desired outcome of big data use is ‚Äúbetter science‚Äù or ‚Äúbetter engineering.‚Äù Critics point to the rejection of traditional data collection and analysis methods, confusion between correlation and causation, and an indifference to models with explanatory power. From the perspective of advancing social science, these are valid reservations. I contend, however, that if the end goal of big data use is to engineer computational artifacts that are more effective according to well-defined metrics, then whatever improves those metrics should be exploited without prejudice. Sound scientific reasoning, while helpful, is not necessary to improve engineering. Understanding the distinction between science and engineering resolves many of the apparent controversies surrounding big data and helps to clarify the criteria by which contributions should be assessed.",,2015.0,28,26,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1cc405a70b35129ce387ced5144298d09d07c3cf,https://www.semanticscholar.org/paper/1cc405a70b35129ce387ced5144298d09d07c3cf,Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks,"Modeling sentence similarity is complicated by the ambiguity and variability of linguistic expression. To cope with these challenges, we propose a model for comparing sentences that uses a multiplicity of perspectives. We first model each sentence using a convolutional neural network that extracts features at multiple levels of granularity and uses multiple types of pooling. We then compare our sentence representations at several granularities using multiple similarity metrics. We apply our model to three tasks, including the Microsoft Research paraphrase identification task and two SemEval semantic textual similarity tasks. We obtain strong performance on all tasks, rivaling or exceeding the state of the art without using external resources such as WordNet or parsers.",Conference on Empirical Methods in Natural Language Processing,2015.0,46,363,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '1700980', 'name': 'Kevin Gimpel'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2a31f2de7aeebffba5722d27b1f3b855ab91e61e,https://www.semanticscholar.org/paper/2a31f2de7aeebffba5722d27b1f3b855ab91e61e,Is Big Data a Transient Problem?,"What does the future hold for Big Data? The author states that it could be the same qualitatively, just bigger and better, or there might be fundamentally disruptive forces that completely reshape the computing landscape. Trying to predict the future, of course, is a perilous exercise. At best, this article provides some deep insight on future developments in Big Data. At worst, it makes for an interesting cocktail conversation. Either way, it's worth the rumination.",IEEE Internet Computing,2015.0,26,5,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2dcfbab048b397b42e955982b0fff94e4f64620d,https://www.semanticscholar.org/paper/2dcfbab048b397b42e955982b0fff94e4f64620d,Assessor Differences and User Preferences in Tweet Timeline Generation,"In information retrieval evaluation, when presented with an effectiveness difference between two systems, there are three relevant questions one might ask. First, are the differences statistically significant? Second, is the comparison stable with respect to assessor differences? Finally, is the difference actually meaningful to a user? This paper tackles the last two questions about assessor differences and user preferences in the context of the newly-introduced tweet timeline generation task in the TREC 2014 Microblog track, where the system's goal is to construct an informative summary of non-redundant tweets that addresses the user's information need. Central to the evaluation methodology is human-generated semantic clusters of tweets that contain substantively similar information. We show that the evaluation is stable with respect to assessor differences in clustering and that user preferences generally correlate with effectiveness metrics even though users are not explicitly aware of the semantic clustering being performed by the systems. Although our analyses are limited to this particular task, we believe that lessons learned could generalize to other evaluations based on establishing semantic equivalence between information units, such as nugget-based evaluations in question answering and temporal summarization.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2015.0,36,29,"[{'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '17010256', 'name': 'G. Sherman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
34d3b49077286effde890d7d08a1129152491eb6,https://www.semanticscholar.org/paper/34d3b49077286effde890d7d08a1129152491eb6,Ranking for Impact-Ordered Indexes,"The ability for a ranking function to control its own execution time is useful for managing load, reigning in outliers, and adapting to different types of queries. We propose a simple yet effective anytime algorithm for impact-ordered indexes that builds on a score-at-a-time query evaluation strategy. In our approach, postings segments are processed in decreasing order of their impact scores, and the algorithm early terminates when a specified number of postings have been processed. With a simple linear model and a few training topics, we can determine this threshold given a time budget in milliseconds. Experiments on two web test collections show that our approach can accurately control query evaluation latency and that aggressive limits on execution time lead to minimal decreases in effectiveness.",,2015.0,21,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}, {'authorId': '1759787', 'name': 'D. Cheriton'}]"
397bb1461a955ea34b4fe58230dd715b5675fca2,https://www.semanticscholar.org/paper/397bb1461a955ea34b4fe58230dd715b5675fca2,Do Multiple Listeners to the Public Twitter Sample Stream Receive the Same Tweets ?,"Do multiple listeners to the public Twitter sample stream receive the same tweets? Due to limitations on redistribution of Twitter data, the answer to this question is important for the replicability and reproducibility of research findings. A negative answer creates barriers for different research groups to evaluate algorithms and systems on the same collection of tweets. We describe a pilot experiment in preparation for the TREC 2015 Microblog track that answers this question in the affirmative, which means that an evaluation methodology built on geographically dispersed research groups independently crawling the Twitter streaming API is feasible.",,2015.0,6,12,"[{'authorId': '2071527', 'name': 'Jiaul H. Paik'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4ddcbb0919833b16466a9661b0f6e9553b77cbf2,https://www.semanticscholar.org/paper/4ddcbb0919833b16466a9661b0f6e9553b77cbf2,Scaling Down Distributed Infrastructure on Wimpy Machines for Personal Web Archiving,"Warcbase is an open-source platform for storing, managing, and analyzing web archives using modern ""big data"" infrastructure on commodity clusters---specifically, HBase for storage and Hadoop for data analytics. This paper describes an effort to scale ""down"" Warcbase onto a Raspberry Pi, an inexpensive single-board computer about the size of a deck of playing cards. Apart from an interesting technology demonstration, such a design presents new opportunities for personal web archiving, in enabling a low-cost, low-power, portable device that is able to continuously capture a user's web browsing history---not only the URLs of the pages that a user has visited, but the contents of those pages---and allowing the user to revisit any previously-encountered page, as it appeared at that time. Experiments show that data ingestion throughput and temporal browsing latency are adequate with existing hardware, which means that such capabilities are already feasible today.",The Web Conference,2015.0,19,10,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
730b04a84f71a9abd5531ebf3ca61caa5844b3e8,https://www.semanticscholar.org/paper/730b04a84f71a9abd5531ebf3ca61caa5844b3e8,The Sum of All Human Knowledge in Your Pocket: Full-Text Searchable Wikipedia on a Raspberry Pi,"We demonstrate a prototype that takes advantage of open-source software to put a full-text searchable copy of Wikipedia on a Raspberry Pi, providing nearby devices access to content via wifi or bluetooth without requiring internet connectivity. This short paper articulates the advantages of such a form factor and provides an evaluation of browsing and search capabilities. We believe that personal digital libraries on lightweight mobile computing devices represent an interesting research direction to pursue.",ACM/IEEE Joint Conference on Digital Libraries,2015.0,4,29,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
73346a8af61eddaf442fac1f53029822273377fb,https://www.semanticscholar.org/paper/73346a8af61eddaf442fac1f53029822273377fb,Developing an Open-Source Bibliometric Ranking Website Using Google Scholar Citation Profiles for Researchers in the Field of Biomedical Informatics,"We developed the Biomedical Informatics Researchers ranking website (rank.informatics-review.com) to overcome many of the limitations of previous scientific productivity ranking strategies. The website is composed of four key components that work together to create an automatically updating ranking website: (1) list of biomedical informatics researchers, (2) Google Scholar scraper, (3) display page, and (4) updater. The site has been useful to other groups in evaluating researchers, such as tenure and promotions committees in interpreting the various citation statistics reported by candidates. Creation of the Biomedical Informatics Researchers ranking website highlights the vast differences in scholarly productivity among members of the biomedical informatics research community.",Medinfo,2015.0,0,2,"[{'authorId': '1690314', 'name': 'Dean F. Sittig'}, {'authorId': '13983559', 'name': 'A. McCoy'}, {'authorId': '143731512', 'name': 'A. Wright'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
834d577e31f5b51210f6caa84236b2db4f99dce8,https://www.semanticscholar.org/paper/834d577e31f5b51210f6caa84236b2db4f99dce8,The Feasibility of Brute Force Scans for Real-Time Tweet Search,"The real-time search problem requires making ingested documents immediately searchable, which presents architectural challenges for systems built around inverted indexing. In this paper, we explore a radical proposition: What if we abandon document inversion and instead adopt an architecture based on brute force scans of document representations? In such a design, ""indexing"" simply involves appending the parsed representation of an ingested document to an existing buffer, which is simple and fast. Quite surprisingly, experiments with TREC Microblog test collections show that query evaluation with brute force scans is feasible and performance compares favorably to a traditional search architecture based on an inverted index, especially if we take advantage of vectorized SIMD instructions and multiple cores in modern processor architectures. We believe that such a novel design is worth further exploration by IR researchers and practitioners.",International Conference on the Theory of Information Retrieval,2015.0,9,2,"[{'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
860f07c970acb58fa093c6b961be05b39ab7f0fa,https://www.semanticscholar.org/paper/860f07c970acb58fa093c6b961be05b39ab7f0fa,Overview of the TREC-2015 Microblog Track,,Text Retrieval Conference,2015.0,7,62,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}, {'authorId': '17010256', 'name': 'G. Sherman'}, {'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '1746656', 'name': 'E. Voorhees'}]"
9a1337813b3e6df21a8b44e418bb77d80aceb16b,https://www.semanticscholar.org/paper/9a1337813b3e6df21a8b44e418bb77d80aceb16b,Warcbase: Building a Scalable Web Archiving Platform on Hadoop and HBase,,,2015.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a3fc2700d3ddff04136f90ad21aff305af89a191,https://www.semanticscholar.org/paper/a3fc2700d3ddff04136f90ad21aff305af89a191,Gappy Pattern Matching on GPUs for On-Demand Extraction of Hierarchical Translation Grammars,"Grammars for machine translation can be materialized on demand by finding source phrases in an indexed parallel corpus and extracting their translations. This approach is limited in practical applications by the computational expense of online lookup and extraction. For phrase-based models, recent work has shown that on-demand grammar extraction can be greatly accelerated by parallelization on general purpose graphics processing units (GPUs), but these algorithms do not work for hierarchical models, which require matching patterns that contain gaps. We address this limitation by presenting a novel GPU algorithm for on-demand hierarchical grammar extraction that is at least an order of magnitude faster than a comparable CPU algorithm when processing large batches of sentences. In terms of end-to-end translation, with decoding on the CPU, we increase throughput by roughly two thirds on a standard MT evaluation dataset. The GPU necessary to achieve these improvements increases the cost of a server by about a third. We believe that GPU-based extraction of hierarchical grammars is an attractive proposition, particularly for MT applications that demand high throughput.",Transactions of the Association for Computational Linguistics,2015.0,41,5,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144871732', 'name': 'Adam Lopez'}]"
a8ed33b244a94f032437fc6f0d7e52d5aad19133,https://www.semanticscholar.org/paper/a8ed33b244a94f032437fc6f0d7e52d5aad19133,Reproducible Experiments on Lexical and Temporal Feedback for Tweet Search,,European Conference on Information Retrieval,2015.0,26,18,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
af4ddcd6b33b9b843c8cffd503f72e1b4930b016,https://www.semanticscholar.org/paper/af4ddcd6b33b9b843c8cffd503f72e1b4930b016,Web Archiving Incentive Program : Final Report Warcbase : An Open-Source Platform for Managing Web Archives,"This final report is organized in terms of the four project goals. The first three goals were part of the original award (April 1, 2014 to December 31, 2014); the final goal was part of a continuation award (January 1, 2015 to November 15, 2015). This document is written in a cumulative fashion, describing accomplishments throughout the entire project (including progress already reported in a interim report dated November 14, 2014). The Warcbase homepage is located at http://warcbase.org/, which redirects to a GitHub repository that holds the Warcbase codebase and all associated documentation. All material is released under the Apache License, per terms of the original award. Development of this project has taken place (and will continue to take place beyond this award) in a completely open environment: anyone can inspect our code at any point in time, follow progress in our issues tracker,1 open new tickets requesting features or bug fixes, or contribute patches if they feel inclined. At the beginning of the award, the PI was a faculty member at the University of Maryland, but as of August 2015, the PI moved to the University of Waterloo. During the course of this project, the PI developed a collaboration with Ian Milligan, Assistant Professor in History at the University of Waterloo. Some of the accomplishments reported here are the direct result of this fruitful collaboration.",,2015.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b005d880638d69a7a7d1e4ae941884d9cbccbb16,https://www.semanticscholar.org/paper/b005d880638d69a7a7d1e4ae941884d9cbccbb16,Anytime Ranking for Impact-Ordered Indexes,"The ability for a ranking function to control its own execution time is useful for managing load, reigning in outliers, and adapting to different types of queries. We propose a simple yet effective anytime algorithm for impact-ordered indexes that builds on a score-at-a-time query evaluation strategy. In our approach, postings segments are processed in decreasing order of their impact scores, and the algorithm early terminates when a specified number of postings have been processed. With a simple linear model and a few training topics, we can determine this threshold given a time budget in milliseconds. Experiments on two web test collections show that our approach can accurately control query evaluation latency and that aggressive limits on execution time lead to minimal decreases in effectiveness.",International Conference on the Theory of Information Retrieval,2015.0,23,48,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145980720', 'name': 'A. Trotman'}]"
b4538c7778be366a023bc8ba6a28c5fc3686e826,https://www.semanticscholar.org/paper/b4538c7778be366a023bc8ba6a28c5fc3686e826,Report on the Evaluation-as-a-Service (EaaS) Expert Workshop,"In this report, we summarize the outcome of the ""Evaluation-as-a-Service"" workshop that was held on the 5th and 6th March 2015 in Sierre, Switzerland. The objective of the meeting was to bring together initiatives that use cloud infrastructures, virtual machines, APIs (Application Programming Interface) and related projects that provide evaluation of information retrieval or machine learning tools as a service.",SIGIR Forum,2015.0,18,26,"[{'authorId': '1759761', 'name': 'F. Hopfgartner'}, {'authorId': '1699657', 'name': 'A. Hanbury'}, {'authorId': '2151194032', 'name': 'H. M√ºller'}, {'authorId': '1678892', 'name': 'N. Kando'}, {'authorId': '2066268952', 'name': 'Simon Mercer'}, {'authorId': '1401724111', 'name': 'Jayashree Kalpathy-Cramer'}, {'authorId': '3046200', 'name': 'Martin Potthast'}, {'authorId': '2734888', 'name': 'Tim Gollub'}, {'authorId': '1927081', 'name': 'Anastasia Krithara'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680484', 'name': 'K. Balog'}, {'authorId': '1724386', 'name': 'Ivan Eggel'}]"
bbf0f58fd7eb54efd8054d90546d86fa8c9d0378,https://www.semanticscholar.org/paper/bbf0f58fd7eb54efd8054d90546d86fa8c9d0378,Building a Self-Contained Search Engine in the Browser,"JavaScript engines inside modern web browsers are capable of running sophisticated multi-player games, rendering impressive 3D scenes, and supporting complex, interactive visualizations. Can this processing power be harnessed for information retrieval? This paper explores the feasibility of building a JavaScript search engine that runs completely self-contained on the client side within the browser - this includes building the inverted index, gathering terms statistics for scoring, and performing query evaluation. The design takes advantage of the IndexDB API, which is implemented by the LevelDB key{value store inside Google's Chrome browser. Experiments show that although the performance of the JavaScript prototype falls far short of the open-source Lucene search engine, it is sufficiently responsive for interactive applications. This feasibility demonstration opens the door to interesting applications and architectures.",International Conference on the Theory of Information Retrieval,2015.0,11,8,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e9f0cb252b092ddd03c452587d9f175912937dbf,https://www.semanticscholar.org/paper/e9f0cb252b092ddd03c452587d9f175912937dbf,Learning to Discover Key Moments in Social Media Streams,"This paper introduces LABurst, a general technique for identifying key moments, or moments of high impact, in social media streams without the need for domain-specific information or seed keywords. We leverage machine learning to model temporal patterns around bursts in Twitter's unfiltered public sample stream and build a classifier to identify tokens experiencing these bursts. We show LABurst performs competitively with existing burst detection techniques while simultaneously providing insight into and detection of unanticipated moments. To demonstrate our approach's potential, we compare two baseline event-detection algorithms with our language-agnostic algorithm to detect key moments across three major sporting competitions: 2013 World Series, 2014 Super Bowl, and 2014 World Cup. Our results show LABurst outperforms a time series analysis baseline and is competitive with a domain-specific baseline even though we operate without any domain knowledge. We then go further by transferring LABurst's models learned in the sports domain to the task of identifying earthquakes in Japan and show our method detects large spikes in earthquake-related tokens within two minutes of the actual event.",arXiv.org,2015.0,30,4,"[{'authorId': '145919650', 'name': 'C. Buntain'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1713898', 'name': 'J. Golbeck'}]"
00dbfff335e9ccca20e342194a3fae90c6fb9bc5,https://www.semanticscholar.org/paper/00dbfff335e9ccca20e342194a3fae90c6fb9bc5,NScale: neighborhood-centric large-scale graph analytics in the cloud,,The VLDB journal,2014.0,51,65,"[{'authorId': '1949818', 'name': 'A. Quamar'}, {'authorId': '144520191', 'name': 'A. Deshpande'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
058f2abb194f579408c14afc26cb12cce698ba3c,https://www.semanticscholar.org/paper/058f2abb194f579408c14afc26cb12cce698ba3c,On the Feasibility and Implications of Self-Contained Search Engines in the Browser,"JavaScript engines inside modern browsers are capable of running sophisticated multi-player games, rendering impressive 3D scenes, and supporting complex, interactive visualizations. Can this processing power be harnessed for information retrieval? This paper explores the feasibility of building a JavaScript search engine that runs completely self-contained on the client side within the browser---this includes building the inverted index, gathering terms statistics for scoring, and performing query evaluation. The design takes advantage of the IndexDB API, which is implemented by the LevelDB key-value store inside Google's Chrome browser. Experiments show that although the performance of the JavaScript prototype falls far short of the open-source Lucene search engine, it is sufficiently responsive for interactive applications. This feasibility demonstration opens the door to interesting applications in offline and private search across multiple platforms as well as hybrid split-execution architectures whereby clients and servers collaboratively perform query evaluation. One possible future scenario is the rise of an online search marketplace in which commercial search engine companies and individual users participate as rational economic actors, balancing privacy, resource usage, latency, and other factors based on customizable utility profiles.",arXiv.org,2014.0,16,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0a4b1e6f12e4b205ae8004dd3f5b7c522c0b4950,https://www.semanticscholar.org/paper/0a4b1e6f12e4b205ae8004dd3f5b7c522c0b4950,"Optimization Techniques for ""Scaling Down"" Hadoop on Multi-Core, Shared-Memory Systems","The underlying assumption behind Hadoop and, more generally, the need for distributed processing is that the data to be analyzed cannot be held in memory on a single machine. Today, this assumption needs to be re-evaluated. Although petabyte-scale datastores are increasingly common, it is unclear whether ‚Äútypical‚Äù analytics tasks require more than a single high-end server. Additionally, we are seeing increased sophistication in analytics, e.g., machine learning, where we process smaller and more refined datasets. To address these trends, we propose ‚Äúscaling down‚Äù Hadoop to run on multi-core, shared-memory machines. This paper presents a prototype runtime called Hone (‚ÄúHadoop One‚Äù) that is API compatible with Hadoop. With Hone, we can take an existing Hadoop application and run it efficiently on a single server. This allows us to take existing MapReduce algorithms and find the most suitable runtime environment for execution on datasets of varying sizes. For dataset sizes that fit into memory on a single machine, our experiments show that Hone is substantially faster than Hadoop running in pseudo-distributed mode. In some cases, Hone running on a single machine outperforms a 16-node Hadoop cluster.",International Conference on Extending Database Technology,2014.0,27,9,"[{'authorId': '144080313', 'name': 'K. A. Kumar'}, {'authorId': '1755760', 'name': 'J. Gluck'}, {'authorId': '144520191', 'name': 'A. Deshpande'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
0adc23fdd59b13afe9872d6d77b62d1318120015,https://www.semanticscholar.org/paper/0adc23fdd59b13afe9872d6d77b62d1318120015,Infrastructure support for evaluation as a service,"How do we conduct large-scale community-wide evaluations for information retrieval if we are unable to distribute the document collection? This was the challenge we faced in organizing a task on searching tweets at the Text Retrieval Conference (TREC), since Twitter's terms of service forbid redistribution of tweets. Our solution, which we call ""evaluation as a service"", was to provide an API through which the collection can be accessed for completing the evaluation task. This paper describes the infrastructure underlying the service and its deployment at TREC 2013. We discuss the merits of the approach and potential applicability to other evaluation scenarios.",The Web Conference,2014.0,10,4,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
1e390cf4ecfeae3c8f22ac73411792e06fb3eb66,https://www.semanticscholar.org/paper/1e390cf4ecfeae3c8f22ac73411792e06fb3eb66,Old dogs are great at new tricks: column stores for ir prototyping,"We make the suggestion that instead of implementing custom index structures and query evaluation algorithms, IR researchers should simply store document representations in a column-oriented relational database and implement ranking models using SQL. For rapid prototyping, this is particularly advantageous since researchers can explore new scoring functions and features by simply issuing SQL queries, without needing to write imperative code. We demonstrate the feasibility of this approach by an implementation of conjunctive BM25 using two modern column stores. Experiments on a web collection show that a retrieval engine built in this manner achieves effectiveness and efficiency on par with custom-built retrieval engines, but provides many additional advantages, including cleaner query semantics, a simpler architecture, built-in support for error analysis, and the ability to exploit advances in database technology ""for free"".",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2014.0,18,28,"[{'authorId': '3011964', 'name': 'H. M√ºhleisen'}, {'authorId': '1721815', 'name': 'Thaer Samar'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
215957f111d8c8ae8b80fc589d9fc35e3d2551b1,https://www.semanticscholar.org/paper/215957f111d8c8ae8b80fc589d9fc35e3d2551b1,Exploiting Representations from Statistical Machine Translation for Cross-Language Information Retrieval,"This work explores how internal representations of modern statistical machine translation systems can be exploited for cross-language information retrieval. We tackle two core issues that are central to query translation: how to exploit context to generate more accurate translations and how to preserve ambiguity that may be present in the original query, thereby retaining a diverse set of translation alternatives. These two considerations are often in tension since ambiguity in natural language is typically resolved by exploiting context, but effective retrieval requires striking the right balance. We propose two novel query translation approaches: the grammar-based approach extracts translation probabilities from translation grammars, while the decoder-based approach takes advantage of n-best translation hypotheses. Both are context-sensitive, in contrast to a baseline context-insensitive approach that uses bilingual dictionaries for word-by-word translation. Experimental results show that by ‚Äúopening up‚Äù modern statistical machine translation systems, we can access intermediate representations that yield high retrieval effectiveness. By combining evidence from multiple sources, we demonstrate significant improvements over competitive baselines on standard cross-language information retrieval test collections. In addition to effectiveness, the efficiency of our techniques are explored as well.",TOIS,2014.0,70,12,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
35fe34e8e08f1d301c4a25c83707d784a8292e46,https://www.semanticscholar.org/paper/35fe34e8e08f1d301c4a25c83707d784a8292e46,Learning to efficiently rank on big data,"Ranking in response to user queries is a central problem in information retrieval, data mining, and machine learning. In the era of ""Big data"", traditional effectiveness-centric ranking techniques tend to get more and more costly (requiring additional hardware and energy costs) to sustain reasonable ranking speed on large data. The mentality of combating big data by throwing in more hardware/machines will quickly become highly expensive since data is growing at an extremely fast rate oblivious to any cost concerns from us. ""Learning to efficiently rank"" offers a cost-effective solution to ranking on large data (e.g., billions of documents). That is, it addresses a critically important question -- whether it is possible to improve ranking effectiveness on large data without incurring (too much) additional cost?",The Web Conference,2014.0,8,7,"[{'authorId': '2108915895', 'name': 'Lidan Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680617', 'name': 'Donald Metzler'}, {'authorId': '145325584', 'name': 'Jiawei Han'}]"
36e9e630a8ba725b905806be89570c68f16537ab,https://www.semanticscholar.org/paper/36e9e630a8ba725b905806be89570c68f16537ab,Partitioning strategies for spatio-textual similarity join,"Given a collection of geo-tagged objects with associated textual descriptors, the spatio-textual similarity join (STJoin) problem is to identify all pairs of similar objects that are close in distance. This task, which is useful in localized recommendations and other applications, is challenging since computing the join is super-linear with respect to the size of the collection. In this paper, we explore partitioning strategies for tackling STJoin. One approach is to start with a spatial data structure, traverse regions and apply a previous algorithm for identifying similar pairs of textual documents called All-Pairs. An alternative approach is to construct a global index but partition postings spatially and modify the All-Pairs algorithm to prune candidates based on distance. We evaluate these approaches on two real-world datasets and find that when running in a single thread, both approaches are comparable in terms of performance. However, a multi-threaded implementation of the global index approach is able to achieve far better speedup given its ability to parallelize at a finer granularity to avoid skewed distributions in task sizes. In addition to using All-Pairs as the underlying textual similarity join algorithm, we also explored an alternate algorithm known as PPJ: our findings are consistent, which suggests that load balancing is a fundamental issue affecting parallel implementations of STJoin algorithms.",BigSpatial@SIGSPATIAL,2014.0,35,13,"[{'authorId': '30586030', 'name': 'J. Rao'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1719385', 'name': 'H. Samet'}]"
3885e88155ca6a4816cc37f3e8326dd977766f87,https://www.semanticscholar.org/paper/3885e88155ca6a4816cc37f3e8326dd977766f87,Session details: Session 5b0: auto-completio,,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2014.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3c5154d3aa120eb8d597af7db512bef1068882e6,https://www.semanticscholar.org/paper/3c5154d3aa120eb8d597af7db512bef1068882e6,Using visualizations to monitor changes and harvest insights from a global-scale logging infrastructure at Twitter,"Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter.",IEEE Conference on Visual Analytics Science and Technology,2014.0,45,32,"[{'authorId': '2809559', 'name': 'K. Wongsuphasawat'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
4ec509cfcda5025fa65ed13ee033cfaf374ba8ab,https://www.semanticscholar.org/paper/4ec509cfcda5025fa65ed13ee033cfaf374ba8ab,On run diversity in Evaluation as a Service,"""Evaluation as a service"" (EaaS) is a new methodology that enables community-wide evaluations and the construction of test collections on documents that cannot be distributed. The basic idea is that evaluation organizers provide a service API through which the evaluation task can be completed. However, this concept violates some of the premises of traditional pool-based collection building and thus calls into question the quality of the resulting test collection. In particular, the service API might restrict the diversity of runs that contribute to the pool: this might hamper innovation by researchers and lead to incomplete judgment pools that affect the reusability of the collection. This paper shows that the distinctiveness of the retrieval runs used to construct the first test collection built using EaaS, the TREC 2013 Microblog collection, is not substantially different from that of the TREC-8 ad hoc collection, a high-quality collection built using traditional pooling. Further analysis using the `leave out uniques' test suggests that pools from the Microblog 2013 collection are less complete than those from TREC-8, although both collections benefit from the presence of distinctive and effective manual runs. Although we cannot yet generalize to all EaaS implementations, our analyses reveal no obvious flaws in the test collection built using the methodology in the TREC 2013 Microblog track.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2014.0,11,5,"[{'authorId': '1746656', 'name': 'E. Voorhees'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
52284cb7be5e87f3db39a1aa940c331d5ba4c060,https://www.semanticscholar.org/paper/52284cb7be5e87f3db39a1aa940c331d5ba4c060,Cumulative Citation Recommendation: A Feature-Aware Comparison of Approaches,"In this work, we conduct a feature-aware comparison of approaches to Cumulative Citation Recommendation (CCR), a task that aims to filter and rank a stream of documents according to their relevance to entities in a knowledge base. We conducted experiments starting with a big feature set, identified a powerful subset and applied it to comparing classification and learning-to-rank algorithms. With few set of powerful features, we achieve better performance than the state-of-the-art. Surprisingly, our findings challenge the previously known preference of learning-to-rank over classification: in our study, the CCR performance of the classification approach outperforms that using learning-to-rank. This indicates that comparing two approaches is problematic due to the interplay between the approaches themselves and the feature sets one chooses to use.",2014 25th International Workshop on Database and Expert Systems Applications,2014.0,7,7,"[{'authorId': '1728614', 'name': 'Gebrekirstos G. Gebremeskel'}, {'authorId': '37504156', 'name': 'Jiyin He'}, {'authorId': '144509504', 'name': 'A. D. Vries'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
52742a33da8ba8cdbd68d41183f108affa33661d,https://www.semanticscholar.org/paper/52742a33da8ba8cdbd68d41183f108affa33661d,Do recommendations matter?: news recommendation in real life,"We present a study of how recommendations are received in real life by users across different news domains (traditional online newspapers, hobbyist websites, forums, etc.). Our analysis shows that readers of websites centered around specific topics are generally less likely to interact with recommendations than readers of traditional news websites.",CSCW Companion,2014.0,4,16,"[{'authorId': '40404161', 'name': 'A. Said'}, {'authorId': '1738219', 'name': 'Alejandro Bellog√≠n'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
5c32734fd4a0765db5c11971f8293e4e2089e5ce,https://www.semanticscholar.org/paper/5c32734fd4a0765db5c11971f8293e4e2089e5ce,Overview of the TREC-2014 Microblog Track,"Abstract : This year represents the fourth iteration of the TREC Microblog track, which has been running since 2011. The track continued using the evaluation as a service model [8, 7], in which participants had access to the document collection only through an API. In addition to the temporally-anchored ad hoc retrieval task, which has been running since the inception of the track, we introduced a new task called tweet timeline generation (TTG), where the goal is to produce concise summaries about a particular topic for human consumption. Although this overview covers both tasks, more emphasis is placed on the tweet timeline generation task, which necessitated the development of a new evaluation methodology. We refer the reader to previous track overview papers [8, 12, 9] for details on the setup of the ad hoc task.",Text Retrieval Conference,2014.0,19,100,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '1962617', 'name': 'Miles Efron'}, {'authorId': '17010256', 'name': 'G. Sherman'}]"
6202b7df603137c1a6081d73069c394bf12e6340,https://www.semanticscholar.org/paper/6202b7df603137c1a6081d73069c394bf12e6340,"Supporting ""Distant Reading"" for Web Archives",,Digital Humanities Conference,2014.0,0,5,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144268437', 'name': 'Kari Kraus'}, {'authorId': '50988000', 'name': 'Ricardo L. Punzalan'}]"
7bab27d62e2dd763a419de0a661a68e3cea1ebf0,https://www.semanticscholar.org/paper/7bab27d62e2dd763a419de0a661a68e3cea1ebf0,NScale: Neighborhood-centric Analytics on Large Graphs,"There is an increasing interest in executing rich and complex analysis tasks over large-scale graphs, many of which require processing and reasoning about a large number of multi-hop neighborhoods or subgraphs in the graph. Examples of such tasks include ego network analysis, motif counting in biological networks, finding social circles, personalized recommendations, link prediction, anomaly detection, analyzing influence cascades, and so on. These tasks are not well served by existing vertex-centric graph processing frameworks whose computation and execution models limit the user program to directly access the state of a single vertex, resulting in high communication, scheduling, and memory overheads in executing such tasks. Further, most existing graph processing frameworks also typically ignore the challenges in extracting the relevant portions of the graph that an analysis task is interested in, and loading it onto distributed memory. 
 
In this demonstration proposal, we describe NScale, a novel end-to-end graph processing framework that enables the distributed execution of complex neighborhood-centric analytics over large-scale graphs in the cloud. NScale enables users to write programs at the level of neighborhoods or subgraphs. NScale uses Apache YARN for efficient and fault-tolerant distribution of data and computation; it features GEL, a novel graph extraction and loading phase, that extracts the relevant portions of the graph and loads them into distributed memory using as few machines as possible. NScale utilizes novel techniques for the distributed execution of user computation that minimize memory consumption by exploiting overlap among the neighborhoods of interest. A comprehensive experimental evaluation shows orders-of-magnitude improvements in performance and total cost over vertex-centric approaches.",Proceedings of the VLDB Endowment,2014.0,6,28,"[{'authorId': '1949818', 'name': 'A. Quamar'}, {'authorId': '144520191', 'name': 'A. Deshpande'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7bba909bc4f20a43e021b1f6fb36dfbf03503a8c,https://www.semanticscholar.org/paper/7bba909bc4f20a43e021b1f6fb36dfbf03503a8c,Infrastructure for supporting exploration and discovery in web archives,"Web archiving initiatives around the world capture ephemeral web content to preserve our collective digital memory. However, unlocking the potential of web archives requires tools that support exploration and discovery of captured content. These tools need to be scalable and responsive, and to this end we believe that modern ""big data"" infrastructure can provide a solid foundation. We present Warcbase, an open-source platform for managing web archives built on the distributed datastore HBase. Our system provides a flexible data model for storing and managing raw content as well as metadata and extracted knowledge. Tight integration with Hadoop provides powerful tools for analytics and data processing. Relying on HBase for storage infrastructure simplifies the development of scalable and responsive applications. We describe a service that provides temporal browsing and an interactive visualization based on topic models that allows users to explore archived content.",The Web Conference,2014.0,23,28,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '49872259', 'name': 'Milad Gholami'}, {'authorId': '30586030', 'name': 'J. Rao'}]"
81555e631d369b5b37d6d715c55db9f72c8589a3,https://www.semanticscholar.org/paper/81555e631d369b5b37d6d715c55db9f72c8589a3,Visual analytics of MOOCs at maryland,"We use visual analytics to explore participation in five MOOCs at the University of Maryland. In some of these courses, our analysis reveals interesting clustering patterns of student behavior. For other courses, visualizations provide ""color"" to help us better understand the range of student behavior.",ACM Conference on Learning @ Scale,2014.0,8,13,"[{'authorId': '2149237874', 'name': 'Zhengzheng Xu'}, {'authorId': '2877164', 'name': 'Dan Goldwasser'}, {'authorId': '1799187', 'name': 'B. Bederson'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8cca529e651867e5ac2a30ceca4e661ef0900ef7,https://www.semanticscholar.org/paper/8cca529e651867e5ac2a30ceca4e661ef0900ef7,Real-Time Twitter Recommendation: Online Motif Detection in Large Dynamic Graphs,"We describe a production Twitter system for generating relevant, personalized, and timely recommendations based on observing the temporally-correlated actions of each user's followings. The system currently serves millions of recommendations daily to tens of millions of mobile users. The approach can be viewed as a specific instance of the novel problem of online motif detection in large dynamic graphs. Our current solution partitions the graph across a number of machines, and with the construction of appropriate data structures, motif detection can be translated into the lookup and intersection of adjacency lists in each partition. We conclude by discussing a generalization of the problem that perhaps represents a new class of data management systems.",Proceedings of the VLDB Endowment,2014.0,9,49,"[{'authorId': '46479974', 'name': 'Pankaj Gupta'}, {'authorId': '2417199', 'name': 'Venu Satuluri'}, {'authorId': '2982669', 'name': 'A. Grewal'}, {'authorId': '38051541', 'name': 'S. Gurumurthy'}, {'authorId': '2103461043', 'name': 'Volodymyr Zhabiuk'}, {'authorId': '2108645975', 'name': 'Quannan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8e32045659b6607831433141025e08ec07b2fa45,https://www.semanticscholar.org/paper/8e32045659b6607831433141025e08ec07b2fa45,The Impact of Future Term Statistics in Real-Time Tweet Search,,European Conference on Information Retrieval,2014.0,8,9,"[{'authorId': '2115663562', 'name': 'Yulu Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
90a73e6d4b72d753745020625b9e3fd43118c1fc,https://www.semanticscholar.org/paper/90a73e6d4b72d753745020625b9e3fd43118c1fc,Overview of the TREC-2012 Microblog Track,,Text Retrieval Conference,2014.0,8,136,"[{'authorId': '144526707', 'name': 'I. Soboroff'}, {'authorId': '1698205', 'name': 'I. Ounis'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
91dbe227966e90dce6a5b5f7936cb8037ecf0e92,https://www.semanticscholar.org/paper/91dbe227966e90dce6a5b5f7936cb8037ecf0e92,Identifying Duplicate and Contradictory Information in Wikipedia,"In this paper, we identify sentences in Wikipedia articles that are either identical or highly similar by applying techniques for near-duplicate detection of web pages. This is accomplished with a MapReduce implementation of minhash to identify sentences with high Jaccard similarity, followed by a pass to generate sentence clusters. Based on manual examination, we discovered that these clusters can be categorized into six different types: templates, identical sentences, copyediting, factual drift, references, and other. Two of these categories are particularly interesting: identical sentences quantify the extent to which content in Wikipedia is copied and pasted, and near-duplicate sentences that state contradictory facts point to quality issues in Wikipedia.",ACM/IEEE Joint Conference on Digital Libraries,2014.0,16,13,"[{'authorId': '47093806', 'name': 'Sarah Weissman'}, {'authorId': '1691974', 'name': 'S. Ayhan'}, {'authorId': '2086592914', 'name': 'Joshua Bradley'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
943c7389c81cd44f2222ae8e97e1ecf3742ed331,https://www.semanticscholar.org/paper/943c7389c81cd44f2222ae8e97e1ecf3742ed331,An Exploration of Postings List Contiguity in Main-Memory Incremental Indexing,"For text retrieval systems, the assumption that all data structures reside in main memory is increasingly common. In this context, we present a novel incremental inverted indexing algorithm for web-scale collections that directly constructs compressed postings lists in memory. Designing efficient in-memory algorithms requires understanding modern processor architectures: in this paper, we explore the issue of postings list contiguity. Postings lists that occupy contiguous memory regions are preferred for retrieval, but maintaining contiguity is costly in terms of speed and complexity. On the other hand, allowing discontiguous index segments simplifies index construction but decreases retrieval performance. Understanding this tradeoff is our main contribution: We show that co-locating small groups of inverted list segments yields query evaluation performance that is statistically indistinguishable from fully-contiguous postings lists. In other words, we can achieve ideal performance with a relatively small amount of effort.",,2014.0,26,3,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
97c51aa284a44ddeaef78b50b2bfb90acba12500,https://www.semanticscholar.org/paper/97c51aa284a44ddeaef78b50b2bfb90acba12500,Temporal feedback for tweet search with non-parametric density estimation,"This paper investigates the temporal cluster hypothesis: in search tasks where time plays an important role, do relevant documents tend to cluster together in time? We explore this question in the context of tweet search and temporal feedback: starting with an initial set of results from a baseline retrieval model, we estimate the temporal density of relevant documents, which is then used for result reranking. Our contributions lie in a method to characterize this temporal density function using kernel density estimation, with and without human relevance judgments, and an approach to integrating this information into a standard retrieval model. Experiments on TREC datasets confirm that our temporal feedback formulation improves search effectiveness, thus providing support for our hypothesis. Our approach out-performs both a standard baseline and previous temporal retrieval models. Temporal feedback improves over standard lexical feedback (with and without human judgments), illus- trating that temporal relevance signals exist independently of document content.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2014.0,31,56,"[{'authorId': '1962617', 'name': 'Miles Efron'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '37504156', 'name': 'Jiyin He'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
c09e7bef7f0b0960b507f3b9ab8a4c49ceec9045,https://www.semanticscholar.org/paper/c09e7bef7f0b0960b507f3b9ab8a4c49ceec9045,"2014 IEEE Conference on Visual Analytics Science and Technology, VAST 2014, Paris, France, October 25-31, 2014",,IEEE Conference on Visual Analytics Science and Technology,2014.0,35,0,"[{'authorId': '9106757', 'name': 'D. Keim'}, {'authorId': '2109873790', 'name': 'Cl√°udio T. Silva'}, {'authorId': '3297219', 'name': 'Tarik Crnovrsanin'}, {'authorId': '1726219', 'name': 'C. Muelder'}, {'authorId': '1707383', 'name': 'K. Ma'}, {'authorId': '144075157', 'name': 'M. Behrisch'}, {'authorId': '19331686', 'name': 'Fatih Korkmaz'}, {'authorId': '2067609397', 'name': 'Lin Shao'}, {'authorId': '1706471', 'name': 'Tobias Schreck'}, {'authorId': '21242765', 'name': 'Steven R. Gomez'}, {'authorId': '2110975007', 'name': 'Hua Guo'}, {'authorId': '1751556', 'name': 'Caroline Ziemkiewicz'}, {'authorId': '145514676', 'name': 'D. Laidlaw'}, {'authorId': '3271672', 'name': 'M. D√∂rk'}, {'authorId': '2752430', 'name': 'Reto Wettach'}, {'authorId': '39324835', 'name': 'Sungahn Ko'}, {'authorId': '2194062', 'name': 'S. Afzal'}, {'authorId': '2251520', 'name': 'S. Walton'}, {'authorId': '2152916910', 'name': 'Yang Yang'}, {'authorId': '2678057', 'name': 'Junghoon Chae'}, {'authorId': '2599852', 'name': 'A. Malik'}, {'authorId': '144844038', 'name': 'Yun Jang'}, {'authorId': '2108557241', 'name': 'Min Chen'}, {'authorId': '33449182', 'name': 'D. Ebert'}, {'authorId': '2277743', 'name': 'T. V. Landesberger'}, {'authorId': '1682816', 'name': 'Fei Wang'}, {'authorId': '2157268696', 'name': 'Wei Chen'}, {'authorId': '2110920284', 'name': 'Feiran Wu'}, {'authorId': '2896799', 'name': 'Ye Zhao'}, {'authorId': '2093217886', 'name': 'Han Hong'}, {'authorId': '2367353', 'name': 'Tianyu Gu'}, {'authorId': '2111541890', 'name': 'Long Wang'}, {'authorId': '4487395', 'name': 'Ronghua Liang'}, {'authorId': '1679542', 'name': 'H. Bao'}, {'authorId': '2135597445', 'name': 'Zhicheng Liu'}, {'authorId': '2809559', 'name': 'K. Wongsuphasawat'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '6758101', 'name': 'P. Accorsi'}, {'authorId': '2608819', 'name': 'Micka√´l Fabr√®gue'}, {'authorId': '1761813', 'name': 'A. Sallaberry'}, {'authorId': '2673161', 'name': 'F. Cernesson'}, {'authorId': '46983530', 'name': 'N. Lalande'}, {'authorId': '1912457', 'name': 'Agn√®s Braud'}, {'authorId': '1747425', 'name': 'S. Bringay'}, {'authorId': '1689800', 'name': 'F. Ber'}, {'authorId': '1744598', 'name': 'P. Poncelet'}, {'authorId': '1683304', 'name': 'M. Teisseire'}, {'authorId': '2155868918', 'name': 'Jie Li'}, {'authorId': '2145459570', 'name': 'Kang Zhang'}, {'authorId': '2117771759', 'name': 'Zhaoyue Meng'}, {'authorId': '47203312', 'name': 'Wenchao Wu'}, {'authorId': '47833402', 'name': 'Yixian Zheng'}, {'authorId': '145506027', 'name': 'Huamin Qu'}]"
ce45248fc7861f1ca1683fe287a3c9f560e5fbfd,https://www.semanticscholar.org/paper/ce45248fc7861f1ca1683fe287a3c9f560e5fbfd,Session details: Session 5b1: how to win friends and influence people,,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2014.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d055b02f7511ccf22ce6a00f3569d0a84278f5bd,https://www.semanticscholar.org/paper/d055b02f7511ccf22ce6a00f3569d0a84278f5bd,Information network or social network?: the structure of the twitter follow graph,"In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The ""follow"" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves.",The Web Conference,2014.0,17,331,"[{'authorId': '50362385', 'name': 'Seth A. Myers'}, {'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '46479974', 'name': 'Pankaj Gupta'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d4fe2b0b5b5c10be2bb32e36b3c774885ce36686,https://www.semanticscholar.org/paper/d4fe2b0b5b5c10be2bb32e36b3c774885ce36686,Summingbird: A Framework for Integrating Batch and Online MapReduce Computations,"Summingbird is an open-source domain-specific language implemented in Scala and designed to integrate online and batch MapReduce computations in a single framework. Summingbird programs are written using dataflow abstractions such as sources, sinks, and stores, and can run on different execution platforms: Hadoop for batch processing (via Scalding/Cascading) and Storm for online processing. Different execution modes require different bindings for the dataflow abstractions (e.g., HDFS files or message queues for the source) but do not require any changes to the program logic. Furthermore, Summingbird can operate in a hybrid processing mode that transparently integrates batch and online results to efficiently generate up-to-date aggregations over long time spans. The language was designed to improve developer productivity and address pain points in building analytics solutions at Twitter where often, the same code needs to be written twice (once for batch processing and again for online processing) and indefinitely maintained in parallel. Our key insight is that certain algebraic structures provide the theoretical foundation for integrating batch and online processing in a seamless fashion. This means that Summingbird imposes constraints on the types of aggregations that can be performed, although in practice we have not found these constraints to be overly restrictive for a broad range of analytics tasks at Twitter.",Proceedings of the VLDB Endowment,2014.0,41,115,"[{'authorId': '2285378115', 'name': 'Oscar Boykin'}, {'authorId': '2285377817', 'name': 'Samuel English Ritchie'}, {'authorId': '2085838261', 'name': ""I. O'Connell""}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f9af1d4ba22802a57c0318f7028ed35d779c7b9e,https://www.semanticscholar.org/paper/f9af1d4ba22802a57c0318f7028ed35d779c7b9e,Column Stores as an IR Prototyping Tool,,European Conference on Information Retrieval,2014.0,9,0,"[{'authorId': '3011964', 'name': 'H. M√ºhleisen'}, {'authorId': '1721815', 'name': 'Thaer Samar'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
1a4054cfa2001290b50dfe5e4d6a599fb5b04405,https://www.semanticscholar.org/paper/1a4054cfa2001290b50dfe5e4d6a599fb5b04405,Training Efficient Tree-Based Models for Document Ranking,,European Conference on Information Retrieval,2013.0,28,29,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1dc8e6c4a32040c68887ef49faddc610ee25d641,https://www.semanticscholar.org/paper/1dc8e6c4a32040c68887ef49faddc610ee25d641,Scaling big data mining infrastructure: the twitter experience,"The analytics platform at Twitter has experienced tremendous growth over the past few years in terms of size, complexity, number of users, and variety of use cases. In this paper, we discuss the evolution of our infrastructure and the development of capabilities for data mining on ""big data"". One important lesson is that successful big data mining in practice is about much more than what most academics would consider data mining: life ""in the trenches"" is occupied by much preparatory work that precedes the application of data mining algorithms and followed by substantial effort to turn preliminary models into robust solutions. In this context, we discuss two topics: First, schemas play an important role in helping data scientists understand petabyte-scale data stores, but they're insufficient to provide an overall ""big picture"" of the data available to generate insights. Second, we observe that a major challenge in building data analytics platforms stems from the heterogeneity of the various components that must be integrated together into production workflows---we refer to this as ""plumbing"". This paper has two goals: For practitioners, we hope to share our experiences to flatten bumps in the road for those who come after us. For academic researchers, we hope to provide a broader context for data mining in production environments, pointing out opportunities for future work.",SKDD,2013.0,55,191,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3128794', 'name': 'D. Ryaboy'}]"
20a1afa80ba1ecc069e389b1e36904a7017834a5,https://www.semanticscholar.org/paper/20a1afa80ba1ecc069e389b1e36904a7017834a5,Document vector representations for feature extraction in multi-stage document ranking,,Information retrieval (Boston),2013.0,48,33,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
23b09635ebb00ee8022c89894e9af2abcdbe38f2,https://www.semanticscholar.org/paper/23b09635ebb00ee8022c89894e9af2abcdbe38f2,"Fast, Incremental Inverted Indexing in Main Memory for Web-Scale Collections","For text retrieval systems, the assumption that all data structures reside in main memory is increasingly common. In this context, we present a novel incremental inverted indexing algorithm for web-scale collections that directly constructs compressed postings lists in memory. Designing efficient in-memory algorithms requires understanding modern processor architectures and memory hierarchies: in this paper, we explore the issue of postings lists contiguity. Naturally, postings lists that occupy contiguous memory regions are preferred for retrieval, but maintaining contiguity increases complexity and slows indexing. On the other hand, allowing discontiguous index segments simplifies index construction but decreases retrieval performance. Understanding this tradeoff is our main contribution: We find that co-locating small groups of inverted list segments yields query evaluation performance that is statistically indistinguishable from fully-contiguous postings lists. In other words, it is not necessary to lay out in-memory data structures such that all postings for a term are contiguous; we can achieve ideal performance with a relatively small amount of effort.",arXiv.org,2013.0,43,4,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3182e17b48a7e67fbc5a2035d8e96a054905d749,https://www.semanticscholar.org/paper/3182e17b48a7e67fbc5a2035d8e96a054905d749,Overview of the TREC 2011 Microblog Track | NIST,,,2013.0,0,9,"[{'authorId': '144526707', 'name': 'I. Soboroff'}, {'authorId': '1698205', 'name': 'I. Ounis'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
475b023e9b0914025fdc030ee343e60004a53fea,https://www.semanticscholar.org/paper/475b023e9b0914025fdc030ee343e60004a53fea,Evaluation as a service for information retrieval,"How can we run large-scale, community-wide evaluations of information retrieval systems if we lack the ability to distribute the document collection on which the task is based? This was the challenge we faced in the TREC Microblog tracks over the past few years. In this paper, we present a novel evaluation methodology we dub ""evaluation as a service"", which was implemented at TREC 2013 to address restrictions on data redistribution. The basic idea is that instead of distributing the document collection, we (the track organizers) provided a service API ""in the cloud"" with which participants could accomplish the evaluation task. We outline advantages as well as disadvantages of this evaluation methodology, and discuss how the approach might be extended to other evaluation scenarios.",SIGIR Forum,2013.0,15,21,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
4c93c4130964c55134bcbb4aa91bfa30376e57e3,https://www.semanticscholar.org/paper/4c93c4130964c55134bcbb4aa91bfa30376e57e3,Fast candidate generation for real-time tweet search with bloom filter chains,"The rise of social media and other forms of user-generated content have created the demand for real-time search: against a high-velocity stream of incoming documents, users desire a list of relevant results at the time the query is issued. In the context of real-time search on tweets, this work explores candidate generation in a two-stage retrieval architecture where an initial list of results is processed by a second-stage rescorer to produce the final output. We introduce Bloom filter chains, a novel extension of Bloom filters that can dynamically expand to efficiently represent an arbitrarily long and growing list of monotonically-increasing integers with a constant false positive rate. Using a collection of Bloom filter chains, a novel approximate candidate generation algorithm called BWand is able to perform both conjunctive and disjunctive retrieval. Experiments show that our algorithm is many times faster than competitive baselines and that this increased performance does not require sacrificing end-to-end effectiveness. Our results empirically characterize the trade-off space defined by output quality, query evaluation speed, and memory footprint for this particular search architecture.",TOIS,2013.0,80,34,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
67843e796bf084bf4fc05f5d63e870e33b771e73,https://www.semanticscholar.org/paper/67843e796bf084bf4fc05f5d63e870e33b771e73,Temporal Relevance Profiles for Tweet Search,"When searching tweets, users may know something about the temporal characteristics of the information they‚Äôre after. For example, based on external knowledge, a searcher might prefer more recent results or results within a particular time interval. However, most search applications do not allow the user to explicitly supply this information, and neither do most retrieval models have a mechanism to incorporate this additional evidence. In this paper, we introduce the notion of a temporal relevance profile, which a user explicitly includes alongside a keyword search query. We propose alternative representations of temporal relevance profiles and how existing retrieval models might take advantage of this data. Oracle experiments on microblog track data from TREC 2011 and 2012 empirically demonstrate that this approach has the potential to significantly increase the quality of retrieved results.",,2013.0,13,11,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
6d646cac903bea6295844ac4f1bf61c8cb348cf7,https://www.semanticscholar.org/paper/6d646cac903bea6295844ac4f1bf61c8cb348cf7,Dynamic memory allocation policies for postings in real-time Twitter search,"We explore a real-time Twitter search application where tweets are arriving at a rate of several thousands per second. Real-time search demands that they be indexed and searchable immediately, which leads to a number of implementation challenges. In this paper, we focus on one aspect: dynamic postings allocation policies for index structures that are completely held in main memory. The core issue can be characterized as a ""Goldilocks Problem"". Because memory remains today a scare resource, an allocation policy that is too aggressive leads to inefficient utilization, while a policy that is too conservative is slow and leads to fragmented postings lists. We present a dynamic postings allocation policy that allocates memory in increasingly-larger ""slices"" from a small number of large, fixed pools of memory. With an analytical model and experiments, we explore different settings that balance time (query evaluation speed) and space (memory utilization).",Knowledge Discovery and Data Mining,2013.0,21,14,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2057162538', 'name': 'Michael Busch'}]"
75bdfc998a871fc481ad8e1d127c04d2ba435ba7,https://www.semanticscholar.org/paper/75bdfc998a871fc481ad8e1d127c04d2ba435ba7,"CWI and TU Delft Notebook TREC 2013: Contextual Suggestion, Federated Web Search, KBA, and Web Tracks","This paper provides an overview of the work done at the Centrum Wiskunde & Informatica (CWI) and Delft University of Technology (TU Delft) for different tracks of TREC 2013. We participated in the Contextual Suggestion Track, the Federated Web Search Track, the Knowledge Base Acceleration (KBA) Track, and the Web Ad-hoc Track. In the Contextual Suggestion track, we focused on filtering the entire ClueWeb12 collection to generate recommendations according to the provided user profiles and contexts. For the Federated Web Search track, we exploited both categories from ODP and document relevance to merge result lists. In the KBA track, we focused on the Cumulative Citation Recommendation task where we exploited different features to two classification algorithms. For the Web track, we extended an ad-hoc baseline with a proximity model that promotes documents in which the query terms are positioned closer together.",Text Retrieval Conference,2013.0,37,17,"[{'authorId': '1738219', 'name': 'Alejandro Bellog√≠n'}, {'authorId': '1728614', 'name': 'Gebrekirstos G. Gebremeskel'}, {'authorId': '37504156', 'name': 'Jiyin He'}, {'authorId': '40404161', 'name': 'A. Said'}, {'authorId': '1721815', 'name': 'Thaer Samar'}, {'authorId': '144509504', 'name': 'A. D. Vries'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1685137', 'name': 'Jeroen B. P. Vuurens'}]"
764e859f616401f7a0b2da069d7b4036e31ac33b,https://www.semanticscholar.org/paper/764e859f616401f7a0b2da069d7b4036e31ac33b,"Hone: ""Scaling Down"" Hadoop on Shared-Memory Systems","The underlying assumption behind Hadoop and, more generally, the need for distributed processing is that the data to be analyzed cannot be held in memory on a single machine. Today, this assumption needs to be re-evaluated. Although petabyte-scale data-stores are increasingly common, it is unclear whether ""typical"" analytics tasks require more than a single high-end server. Additionally, we are seeing increased sophistication in analytics, e.g., machine learning, which generally operates over smaller and more refined datasets. To address these trends, we propose ""scaling down"" Hadoop to run on shared-memory machines. This paper presents a prototype runtime called Hone, intended to be both API and binary compatible with standard (distributed) Hadoop. That is, Hone can take an existing Hadoop jar and efficiently execute it, without modification, on a multi-core shared memory machine. This allows us to take existing Hadoop algorithms and find the most suitable run-time environment for execution on datasets of varying sizes. Our experiments show that Hone can be an order of magnitude faster than Hadoop pseudo-distributed mode (PDM); on dataset sizes that fit into memory, Hone can outperform a fully-distributed 15-node Hadoop cluster in some cases as well.",Proceedings of the VLDB Endowment,2013.0,12,18,"[{'authorId': '144080313', 'name': 'K. A. Kumar'}, {'authorId': '1755760', 'name': 'J. Gluck'}, {'authorId': '144520191', 'name': 'A. Deshpande'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7a70aa1b998483cf93ca02d3ada5306f9539e93d,https://www.semanticscholar.org/paper/7a70aa1b998483cf93ca02d3ada5306f9539e93d,Data-Intensive Computing with MapReduce,"The growing demand for large-scale data mining and data analysis applications has led both industry and academia to design new types of highly scalable data-intensive computing platforms. MapReduce and Dryad are two popular platforms in which the dataflow takes the form of a directed acyclic graph of operators. These platforms lack built-in support for iterative programs, which arise naturally in many applications including data mining, web ranking, graph analysis, model fitting, and so on. This paper presents HaLoop, a modified version of the Hadoop MapReduce framework that is designed to serve these applications. HaLoop not only extends MapReduce with programming support for iterative applications, it also dramatically improves their efficiency by making the task scheduler loop-aware and by adding various caching mechanisms. We evaluated HaLoop on real queries and real datasets. Compared with Hadoop, on average, HaLoop reduces query runtimes by 1.85, and shuffles only 4% of the data between mappers and reducers.",,2013.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
921ee4e1c2122ba297baf1ba50e1129d0ccc2a50,https://www.semanticscholar.org/paper/921ee4e1c2122ba297baf1ba50e1129d0ccc2a50,NAACL HLT 2013 Tutorial Abstracts,,North American Chapter of the Association for Computational Linguistics,2013.0,0,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1708114', 'name': 'K. Erk'}]"
9554d7bec4480732d419c67c6d71356a596b7cee,https://www.semanticscholar.org/paper/9554d7bec4480732d419c67c6d71356a596b7cee,Overview of the TREC-2013 Microblog Track,,Text Retrieval Conference,2013.0,2,70,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1962617', 'name': 'Miles Efron'}]"
989d672d38de29c36bb968edfdb593038bba7b85,https://www.semanticscholar.org/paper/989d672d38de29c36bb968edfdb593038bba7b85,WTF: the who to follow service at Twitter,"WTF (""Who to Follow"") is Twitter's user recommendation service, which is responsible for creating millions of connections daily between users based on shared interests, common connections, and other related factors. This paper provides an architectural overview and shares lessons we learned in building and running the service over the past few years. Particularly noteworthy was our design decision to process the entire Twitter graph in memory on a single server, which significantly reduced architectural complexity and allowed us to develop and deploy the service in only a few months. At the core of our architecture is Cassovary, an open-source in-memory graph processing engine we built from scratch for WTF. Besides powering Twitter's user recommendations, Cassovary is also used for search, discovery, promoted products, and other services as well. We describe and evaluate a few graph recommendation algorithms implemented in Cassovary, including a novel approach based on a combination of random walks and SALSA. Looking into the future, we revisit the design of our architecture and comment on its limitations, which are presently being addressed in a second-generation system under development.",The Web Conference,2013.0,34,488,"[{'authorId': '2122332550', 'name': 'Pankaj Gupta'}, {'authorId': '143638107', 'name': 'Ashish Goel'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '2152687987', 'name': 'Dong Wang'}, {'authorId': '5985064', 'name': 'R. Zadeh'}]"
a1e1c97850639f8a328387df806f3654e1815502,https://www.semanticscholar.org/paper/a1e1c97850639f8a328387df806f3654e1815502,A month in the life of a production news recommender system,"During the last decade, recommender systems have become a ubiquitous feature in the online world. Research on systems and algorithms in this area has flourished, leading to novel techniques for personalization and recommendation. The evaluation of recommender systems, however, has not seen similar progress---techniques have changed little since the advent of recommender systems, when evaluation methodologies were ""borrowed"" from related research areas. As an effort to move evaluation methodology forward, this paper describes a production recommender system infrastructure that allows research systems to be evaluated in situ, by real-world metrics such as user clickthrough. We present an analysis of one month of interactions with this infrastructure and share our findings.",LivingLab '13,2013.0,6,27,"[{'authorId': '40404161', 'name': 'A. Said'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1738219', 'name': 'Alejandro Bellog√≠n'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
adea93b44984e95c597e8c6f3284360a5fc5f214,https://www.semanticscholar.org/paper/adea93b44984e95c597e8c6f3284360a5fc5f214,Mr. MIRA: Open-Source Large-Margin Structured Learning on MapReduce,"We present an open-source framework for large-scale online structured learning. Developed with the flexibility to handle cost-augmented inference problems such as statistical machine translation (SMT), our large-margin learner can be used with any decoder. Integration with MapReduce using Hadoop streaming allows efficient scaling with increasing size of training data. Although designed with a focus on SMT, the decoder-agnostic design of our learner allows easy future extension to other structured learning problems such as sequence labeling and parsing.",Annual Meeting of the Association for Computational Linguistics,2013.0,20,6,"[{'authorId': '2332594', 'name': 'Vladimir Eidelman'}, {'authorId': '2112646366', 'name': 'Ke Wu'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '1680292', 'name': 'P. Resnik'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b40bb6c44b48dc1f38d8d993a7134fa22e7fdf91,https://www.semanticscholar.org/paper/b40bb6c44b48dc1f38d8d993a7134fa22e7fdf91,Effectiveness/efficiency tradeoffs for candidate generation in multi-stage retrieval architectures,"This paper examines a multi-stage retrieval architecture consisting of a candidate generation stage, a feature extraction stage, and a reranking stage using machine-learned models. Given a fixed set of features and a learning-to-rank model, we explore effectiveness/efficiency tradeoffs with three candidate generation approaches: postings intersection with SvS, conjunctive query evaluation with WAND, and disjunctive query evaluation with WAND. We find no significant differences in end-to-end effectiveness as measured by NDCG between conjunctive and disjunctive WAND, but conjunctive query evaluation is substantially faster. Postings intersection with SvS, while fast, yields substantially lower end-to-end effectiveness, suggesting that document and term frequencies remain important in the initial ranking stage. These findings show that conjunctive WAND is the best overall candidate generation strategy of those we examined.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2013.0,19,94,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c0ac73f8cb1630cddc9c8f953ed4d30a6cb6a5b4,https://www.semanticscholar.org/paper/c0ac73f8cb1630cddc9c8f953ed4d30a6cb6a5b4,Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,,,2013.0,0,294,"[{'authorId': '2116456836', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144871732', 'name': 'Adam Lopez'}]"
ca4334c89f4223ed7d7699b7eb8b070efb7effd1,https://www.semanticscholar.org/paper/ca4334c89f4223ed7d7699b7eb8b070efb7effd1,Monoidify! Monoids as a Design Principle for Efficient MapReduce Algorithms,"It is well known that since the sort/shuffle stage in MapReduce is costly, local aggregation is one important principle to designing efficient algorithms. This short paper represents an attempt to more clearly articulate this design principle in terms of monoids, which generalizes the use of combiners and the in-mapper combining pattern.",arXiv.org,2013.0,6,5,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
de05c034fcfffbefdab607ab4d5c729e2ffffe16,https://www.semanticscholar.org/paper/de05c034fcfffbefdab607ab4d5c729e2ffffe16,Massively Parallel Suffix Array Queries and On-Demand Phrase Extraction for Statistical Machine Translation Using GPUs,"Translation models in statistical machine translation can be scaled to large corpora and arbitrarily-long phrases by looking up translations of source phrases ‚Äúon the fly‚Äù in an indexed parallel corpus using suffix arrays. However, this can be slow because on-demand extraction of phrase tables is computationally expensive. We address this problem by developing novel algorithms for general purpose graphics processing units (GPUs), which enable suffix array queries for phrase lookup and phrase extraction to be massively parallelized. Compared to a highly-optimized, state-of-the-art serial CPU-based implementation, our techniques achieve at least an order of magnitude improvement in terms of throughput. This work demonstrates the promise of massively parallel architectures and the potential of GPUs for tackling computationallydemanding problems in statistical machine translation and language processing.",North American Chapter of the Association for Computational Linguistics,2013.0,21,6,"[{'authorId': '2111892870', 'name': 'Hua He'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144871732', 'name': 'Adam Lopez'}]"
e2c3bec0644fdf5494d740999883abff96a2c321,https://www.semanticscholar.org/paper/e2c3bec0644fdf5494d740999883abff96a2c321,Flat vs. hierarchical phrase-based translation models for cross-language information retrieval,"Although context-independent word-based approaches remain popular for cross-language information retrieval, many recent studies have shown that integrating insights from modern statistical machine translation systems can lead to substantial improvements in effectiveness. In this paper, we compare flat and hierarchical phrase-based translation models for query translation. Both approaches yield significantly better results than either a token-based or a one-best translation baseline on standard test collections. The choice of model manifests interesting tradeoffs in terms of effectiveness, efficiency, and model compactness.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2013.0,29,7,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e898370545f5b7b5608019cfc692b295630dccb3,https://www.semanticscholar.org/paper/e898370545f5b7b5608019cfc692b295630dccb3,Towards Efficient Large-Scale Feature-Rich Statistical Machine Translation,"We present the system we developed to provide efficient large-scale feature-rich discriminative training for machine translation. We describe how we integrate with MapReduce using Hadoop streaming to allow arbitrarily scaling the tuning set and utilizing a sparse feature set. We report our findings on German-English and RussianEnglish translation, and discuss benefits, as well as obstacles, to tuning on larger development sets drawn from the parallel training data.",WMT@ACL,2013.0,27,4,"[{'authorId': '2332594', 'name': 'Vladimir Eidelman'}, {'authorId': '2112646366', 'name': 'Ke Wu'}, {'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '1680292', 'name': 'P. Resnik'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
1f2902ced604e52d25b8fc16b74750fa042264dc,https://www.semanticscholar.org/paper/1f2902ced604e52d25b8fc16b74750fa042264dc,Runtime Optimizations for Prediction with Tree-Based Models,"Tree-based models have proven to be an effective solution for web ranking as well as other problems in diverse domains. This paper focuses on optimizing the runtime performance of applying such models to make predictions, given an already-trained model. Although exceedingly simple conceptually, most implementations of tree-based models do not efficiently utilize modern superscalar processor architectures. By laying out data structures in memory in a more cache-conscious fashion, removing branches from the execution flow using a technique called predication, and micro-batching predictions using a technique called vectorization, we are able to better exploit modern processor architectures and significantly improve the speed of tree-based models over hard-coded if-else blocks. Our work contributes to the exploration of architecture-conscious runtime implementations of machine learning algorithms.",arXiv.org,2012.0,24,7,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]"
52786c2bdcdf6dc5ad2d8124959a4e8911be8021,https://www.semanticscholar.org/paper/52786c2bdcdf6dc5ad2d8124959a4e8911be8021,On building a reusable Twitter corpus,"The Twitter real-time information network is the subject of research for information retrieval tasks such as real-time search. However, so far, reproducible experimentation on Twitter data has been impeded by restrictions imposed by the Twitter terms of service. In this paper, we detail a new methodology for legally building and distributing Twitter corpora, developed through collaboration between the Text REtrieval Conference (TREC) and Twitter. In particular, we detail how the first publicly available Twitter corpus - referred to as Tweets2011 - was distributed via lists of tweet identifiers and specialist tweet crawling software. Furthermore, we analyse whether this distribution approach remains robust over time, as tweets in the corpus are removed either by users or Twitter itself. Tweets2011 was successfully used by 58 participating groups for the TREC 2011 Microblog track, while our results attest to the robustness of the crawling methodology over time.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2012.0,2,91,"[{'authorId': '1740893', 'name': 'R. McCreadie'}, {'authorId': '144526707', 'name': 'I. Soboroff'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '1698205', 'name': 'I. Ounis'}, {'authorId': '39342345', 'name': 'Dean McCullough'}]"
5b6d17e59fb710c97c066c8197648ede807d7324,https://www.semanticscholar.org/paper/5b6d17e59fb710c97c066c8197648ede807d7324,Combining Statistical Translation Techniques for Cross-Language Information Retrieval,"Cross-language information retrieval today is dominated by techniques that rely principally on context-independent token-to-token mappings despite the fact that state-of-the-art statistical machine translation systems now have far richer translation models available in their internal representations. This paper explores combination-of-evidence techniques using three types of statistical translation models: context-independent token translation, token translation using phrase-dependent contexts, and token translation using sentence-dependent contexts. Context-independent translation is performed using statistically-aligned tokens in parallel text, phrase-dependent translation is performed using aligned statistical phrases, and sentence-dependent translation is performed using those same aligned phrases together with an n-gram language model. Experiments on retrieval of Arabic, Chinese, and French documents using English queries show that no one technique is optimal for all queries, but that statistically significant improvements in mean average precision over strong baselines can be achieved by combining translation evidence from all three techniques. The optimal combination is, however, found to be resource-dependent, indicating a need for future work on robust tuning to the characteristics of individual collections.",International Conference on Computational Linguistics,2012.0,40,30,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1737250', 'name': 'Douglas W. Oard'}]"
5edd152e84f3795e9322316bd017612357da49e3,https://www.semanticscholar.org/paper/5edd152e84f3795e9322316bd017612357da49e3,Fast data in the era of big data: Twitter's real-time related query suggestion architecture,"We present the architecture behind Twitter's real-time related query suggestion and spelling correction service. Although these tasks have received much attention in the web search literature, the Twitter context introduces a real-time ""twist"": after significant breaking news events, we aim to provide relevant results within minutes. This paper provides a case study illustrating the challenges of real-time data processing in the era of ""big data"". We tell the story of how our system was built twice: our first implementation was built on a typical Hadoop-based analytics stack, but was later replaced because it did not meet the latency requirements necessary to generate meaningful real-time results. The second implementation, which is the system deployed in production today, is a custom in-memory processing engine specifically designed for the task. This experience taught us that the current typical usage of Hadoop as a ""big data"" platform, while great for experimentation, is not well suited to low-latency processing, and points the way to future work on data analytics platforms that can handle ""big"" as well as ""fast"" data.",ACM SIGMOD Conference,2012.0,54,108,"[{'authorId': '1693513', 'name': 'G. Mishne'}, {'authorId': '145269114', 'name': 'Jeffrey Dalton'}, {'authorId': '51003520', 'name': 'Zhenghua Li'}, {'authorId': '2109669217', 'name': 'Aneesh Sharma'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
774cac6906db877a3e8a0d37e9f9cab3754a5528,https://www.semanticscholar.org/paper/774cac6906db877a3e8a0d37e9f9cab3754a5528,Why Not Grab a Free Lunch? Mining Large Corpora for Parallel Sentences to Improve Translation Modeling,"It is well known that the output quality of statistical machine translation (SMT) systems increases with more training data. To obtain more parallel text for translation modeling, researchers have turned to the web to mine parallel sentences, but most previous approaches have avoided the difficult problem of pairwise similarity on cross-lingual documents and instead rely on heuristics. In contrast, we confront this challenge head on using the MapReduce framework. On a modest cluster, our scalable end-to-end processing pipeline was able to automatically gather 5.8m parallel sentence pairs from English and German Wikipedia. Augmenting existing bitext with these data yielded significant improvements over a state-of-the-art baseline (2.39 BLEU points in the best case).",North American Chapter of the Association for Computational Linguistics,2012.0,18,20,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9ead7583542e55c84bb9b90260ffde7a70c88e8d,https://www.semanticscholar.org/paper/9ead7583542e55c84bb9b90260ffde7a70c88e8d,Large-scale machine learning at twitter,"The success of data-driven solutions to difficult problems, along with the dropping costs of storing and processing massive amounts of data, has led to growing interest in large-scale machine learning. This paper presents a case study of Twitter's integration of machine learning tools into its existing Hadoop-based, Pig-centric analytics platform. We begin with an overview of this platform, which handles ""traditional"" data warehousing and business intelligence tasks for the organization. The core of this work lies in recent Pig extensions to provide predictive analytics capabilities that incorporate machine learning, focused specifically on supervised classification. In particular, we have identified stochastic gradient descent techniques for online learning and ensemble methods as being highly amenable to scaling out to large amounts of data. In our deployed solution, common machine learning tasks such as data sampling, feature generation, training, and testing can be accomplished directly in Pig, via carefully crafted loaders, storage functions, and user-defined functions. This means that machine learning is just another Pig script, which allows seamless integration with existing infrastructure for data management, scheduling, and monitoring in a production environment, as well as access to rich libraries of user-defined functions and the materialized output of other scripts.",SIGMOD Conference,2012.0,54,205,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2062921', 'name': 'A. Kolcz'}]"
a398c7b65cfee1f58ed9383ff66d87b160140056,https://www.semanticscholar.org/paper/a398c7b65cfee1f58ed9383ff66d87b160140056,A High-Performance Architecture for Training,"A High-Performance Architecture for Training Viola-Jones Object Detectors Charles Lo Master of Applied Science Graduate Department of Electrical and Computer Engineering University of Toronto 2012 The object detection framework developed by Viola and Jones has become very popular due to its high quality and detection speed. However, the complexity of the computation required to train a detector makes it difficult to develop and test potential improvements to this algorithm or train detectors in the field. In this thesis, a configurable, high-performance FPGA architecture is presented to accelerate this training process. The architecture, structured as a systolic array of pipelined compute engines, is constructed to provide high throughput and make efficient use of the available external memory bandwidth. Extensions to the Viola-Jones detection framework are implemented to demonstrate the flexibility of the architecture. The design is implemented on a Xilinx ML605 development platform running at 200 MHz and obtains a 15-fold speed-up over a multi-threaded OpenCV implementation running on a high-end processor.",,2012.0,24,1,"[{'authorId': '2057725627', 'name': 'Eric Lau'}, {'authorId': '2108205884', 'name': 'S. Lee'}, {'authorId': '2118204332', 'name': 'Yuan Li'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2143855885', 'name': 'H. Liu'}, {'authorId': '2065191', 'name': 'Christopher A. Madill'}, {'authorId': '2068524820', 'name': 'Michael Manning'}, {'authorId': '3168771', 'name': 'Vincent Mirian'}, {'authorId': '144126695', 'name': 'A. Patel'}]"
afbc30ec8c690c52f0ada4b64a2eaf88679de233,https://www.semanticscholar.org/paper/afbc30ec8c690c52f0ada4b64a2eaf88679de233,"MapReduce is Good Enough? If All You Have is a Hammer, Throw Away Everything That's Not a Nail!","Hadoop is currently the large-scale data analysis ""hammer"" of choice, but there exist classes of algorithms that aren't ""nails"" in the sense that they are not particularly amenable to the MapReduce programming model. To address this, researchers have proposed MapReduce extensions or alternative programming models in which these algorithms can be elegantly expressed. This article espouses a very different position: that MapReduce is ""good enough,"" and that instead of trying to invent screwdrivers, we should simply get rid of everything that's not a nail. To be more specific, much discussion in the literature surrounds the fact that iterative algorithms are a poor fit for MapReduce. The simple solution is to find alternative, noniterative algorithms that solve the same problem. This article captures my personal experiences as an academic researcher as well as a software engineer in a ""real-world"" production analytics environment. From this combined perspective, I reflect on the current state and future of ""big data"" research.",Big Data,2012.0,62,98,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c1a64dec9d0b8f4e241fcabdfff46f46a7f756f7,https://www.semanticscholar.org/paper/c1a64dec9d0b8f4e241fcabdfff46f46a7f756f7,Looking inside the box: context-sensitive translation for cross-language information retrieval,"Cross-language information retrieval (CLIR) today is dominated by techniques that use token-to-token mappings from bilingual dictionaries. Yet, state-of-the-art statistical translation models (e.g., using Synchronous Context-Free Grammars) are far richer, capturing multi-term phrases, term dependencies, and contextual constraints on translation choice. We present a novel CLIR framework that is able to reach inside the translation ""black box"" and exploit these sources of evidence. Experiments on the TREC-5/6 English-Chinese test collection show this approach to be promising.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2012.0,7,24,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1737250', 'name': 'Douglas W. Oard'}]"
ca26d54c7d8c28d59f27f4860a6ec370984059ba,https://www.semanticscholar.org/paper/ca26d54c7d8c28d59f27f4860a6ec370984059ba,Evaluating Real-Time Search over Tweets | NIST,,,2012.0,0,3,"[{'authorId': '144526707', 'name': 'I. Soboroff'}, {'authorId': '39342345', 'name': 'Dean McCullough'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '1698205', 'name': 'I. Ounis'}, {'authorId': '1740893', 'name': 'R. McCreadie'}]"
ccb224b95bc879b7914d0a2c2915f6694fe6160e,https://www.semanticscholar.org/paper/ccb224b95bc879b7914d0a2c2915f6694fe6160e,Document vector representations for feature extraction in multi-stage document ranking,,Information retrieval (Boston),2012.0,0,1,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
db6eedd560aa2c55f6c2f8ea80d19bd083192190,https://www.semanticscholar.org/paper/db6eedd560aa2c55f6c2f8ea80d19bd083192190,Fast candidate generation for two-phase document ranking: postings list intersection with bloom filters,"Most modern web search engines employ a two-phase ranking strategy: a candidate list of documents is generated using a ""cheap"" but low-quality scoring function, which is then reranked by an ""expensive"" but high-quality method (usually machine-learned). This paper focuses on the problem of candidate generation for conjunctive query processing in this context. We describe and evaluate a fast, approximate postings list intersection algorithms based on Bloom filters. Due to the power of modern learning-to-rank techniques and emphasis on early precision, significant speedups can be achieved without loss of end-to-end retrieval effectiveness. Explorations reveal a rich design space where effectiveness and efficiency can be balanced in response to specific hardware configurations and application scenarios.",International Conference on Information and Knowledge Management,2012.0,20,23,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
dc943ad0942f77e4ba6d9740ed3005e083cc9e8b,https://www.semanticscholar.org/paper/dc943ad0942f77e4ba6d9740ed3005e083cc9e8b,Earlybird: Real-Time Search at Twitter,"The web today is increasingly characterized by social and real-time signals, which we believe represent two frontiers in information retrieval. In this paper, we present Early bird, the core retrieval engine that powers Twitter's real-time search service. Although Early bird builds and maintains inverted indexes like nearly all modern retrieval engines, its index structures differ from those built to support traditional web search. We describe these differences and present the rationale behind our design. A key requirement of real-time search is the ability to ingest content rapidly and make it searchable immediately, while concurrently supporting low-latency, high-throughput query evaluation. These demands are met with a single-writer, multiple-reader concurrency model and the targeted use of memory barriers. Early bird represents a point in the design space of real-time search engines that has worked well for Twitter's needs. By sharing our experiences, we hope to spur additional interest and innovation in this exciting space.",IEEE International Conference on Data Engineering,2012.0,51,171,"[{'authorId': '2057162538', 'name': 'Michael Busch'}, {'authorId': '144315468', 'name': 'Krishna Gade'}, {'authorId': '2054132231', 'name': 'B. Larson'}, {'authorId': '39340163', 'name': 'Patrick Lok'}, {'authorId': '31728061', 'name': 'Samuel B. Luckenbill'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f696586f96d84467eecaa7663bad6cc10756df26,https://www.semanticscholar.org/paper/f696586f96d84467eecaa7663bad6cc10756df26,The Unified Logging Infrastructure for Data Analytics at Twitter,"In recent years, there has been a substantial amount of work on large-scale data analytics using Hadoop-based platforms running on large clusters of commodity machines. A less-explored topic is how those data, dominated by application logs, are collected and structured to begin with. In this paper, we present Twitter's production logging infrastructure and its evolution from application-specific logging to a unified ""client events"" log format, where messages are captured in common, well-formatted, flexible Thrift messages. Since most analytics tasks consider the user session as the basic unit of analysis, we pre-materialize ""session sequences"", which are compact summaries that can answer a large class of common queries quickly. The development of this infrastructure has streamlined log collection and data analysis, thereby improving our ability to rapidly experiment and iterate on various aspects of the service.",Proceedings of the VLDB Endowment,2012.0,30,99,"[{'authorId': '72372464', 'name': 'George Lee'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2116347783', 'name': 'Chuang Liu'}, {'authorId': '39965220', 'name': 'Andrew Lorek'}, {'authorId': '3128794', 'name': 'D. Ryaboy'}]"
1556704649472ef0142fa588994762a958a96af2,https://www.semanticscholar.org/paper/1556704649472ef0142fa588994762a958a96af2,Cross-corpus relevance projection,"Document corpora are key components of information retrieval test collections. However, for certain tasks, such as evaluating the effectiveness of a new retrieval technique or estimating the parameters of a learning to rank model, a corpus alone is not enough. For these tasks, queries and relevance judgments associated with the corpus are also necessary. However, researchers often find themselves in scenarios where they only have access to a corpus, in which case evaluation and learning to rank become challenging. Document corpora are relatively straightforward to gather. On the other hand, obtaining queries and relevance judgments for a given corpus is costly. In production environments, it may be possible to obtain low-cost relevance information using query and click logs. However, in more constrained research environments these options are not available, and relevance judgments are usually provided by humans. To reduce the cost of this potentially expensive process, researchers have developed low-cost evaluation strategies, including minimal test collections [2] and crowdsourcing [1]. Despite the usefulness of these strategies, the resulting relevance judgments cannot easily be ‚Äúported‚Äù to a new or different corpus. To overcome these issues, we propose a new method to reduce manual annotation costs by transferring relevance judgments across corpora. Assuming that a set of queries and relevance judgments have been manually constructed for a source document corpus Ds, our goal is to automatically construct a test collection for a target document corpus Dt by projecting the existing test collection from Ds onto Dt. The goal of projecting test collections is not to produce manual quality test collections. In fact, it is assumed that projected test collections will contain noisy relevance judgments (i.e., ones which humans are unlikely to agree with). The important question, however, is whether these noisy projected judgments are useful for training ranking models in the target corpus.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2011.0,3,0,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '1680617', 'name': 'Donald Metzler'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
35546ad33a3d877063a6a5e938c8d9e8a34badb9,https://www.semanticscholar.org/paper/35546ad33a3d877063a6a5e938c8d9e8a34badb9,Pseudo test collections for learning web search ranking functions,"Test collections are the primary drivers of progress in information retrieval. They provide yardsticks for assessing the effectiveness of ranking functions in an automatic, rapid, and repeatable fashion and serve as training data for learning to rank models. However, manual construction of test collections tends to be slow, labor-intensive, and expensive. This paper examines the feasibility of constructing web search test collections in a completely unsupervised manner given only a large web corpus as input. Within our proposed framework, anchor text extracted from the web graph is treated as a pseudo query log from which pseudo queries are sampled. For each pseudo query, a set of relevant and non-relevant documents are selected using a variety of web-specific features, including spam and aggregated anchor text weights. The automatically mined queries and judgments form a pseudo test collection that can be used for training ranking functions. Experiments carried out on TREC web track data show that learning to rank models trained using pseudo test collections outperform an unsupervised ranking function and are statistically indistinguishable from a model trained using manual judgments, demonstrating the usefulness of our approach in extracting reasonable quality training data ""for free"".",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2011.0,39,41,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '1680617', 'name': 'Donald Metzler'}, {'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3776c4dd5c00a515b4e3229d0e76a3d14d41fd32,https://www.semanticscholar.org/paper/3776c4dd5c00a515b4e3229d0e76a3d14d41fd32,When close enough is good enough: approximate positional indexes for efficient ranked retrieval,"Previous research has shown that features based on term proximity are important for effective retrieval. However, they incur substantial costs in terms of larger inverted indexes and slower query execution times as compared to term-based features. This paper explores whether term proximity features based on approximate term positions are as effective as those based on exact term positions. We introduce the novel notion of approximate positional indexes based on dividing documents into coarse-grained buckets and recording term positions with respect to those buckets. We propose different approaches to defining the buckets and compactly encoding bucket ids. In the context of linear ranking functions, experimental results show that features based on approximate term positions are able to achieve effectiveness comparable to exact term positions, but with smaller indexes and faster query evaluation.",International Conference on Information and Knowledge Management,2011.0,13,13,"[{'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680617', 'name': 'Donald Metzler'}]"
3c8370780e74bcf7b0c671a3a4cf20c6b12d2f55,https://www.semanticscholar.org/paper/3c8370780e74bcf7b0c671a3a4cf20c6b12d2f55,Full-text indexing for optimizing selection operations in large-scale data analytics,"MapReduce, especially the Hadoop open-source implementation, has recently emerged as a popular framework for large-scale data analytics. Given the explosion of unstructured data begotten by social media and other web-based applications, we take the position that any modern analytics platform must support operations on free-text fields as first-class citizens. Toward this end, this paper addresses one inefficient aspect of Hadoop-based processing: the need to perform a full scan of the entire dataset, even in cases where it is clearly not necessary to do so. We show that it is possible to leverage a full-text index to optimize selection operations on text fields within records. The idea is simple and intuitive: the full-text index informs the Hadoop execution engine which compressed data blocks contain query terms of interest, and only those data blocks are decompressed and scanned. Experiments with a proof of concept show moderate improvements in end-to-end query running times and substantial savings in terms of cumulative processing time at the worker nodes. We present an analytical model and discuss a number of interesting challenges: some operational, others research in nature.",MapReduce '11,2011.0,23,50,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3128794', 'name': 'D. Ryaboy'}, {'authorId': '2070163507', 'name': 'Kevin Weil'}]"
5a342a2dd281bbd0c36e3e98758506952dd35aac,https://www.semanticscholar.org/paper/5a342a2dd281bbd0c36e3e98758506952dd35aac,In-depth accounts and passing mentions in the news: connecting readers to the context of a news event,"Software that models how types of news events unfold can extract information about specific events and explain them to a news reader. This support can be useful when the background provided by an article is insufficient, if other news coverage exists from which an event's history can be extracted. For extended sequences of related events, it is reasonable to expect that articles published after the sequence concludes include less background coverage of the sequence. Focusing on two stereotypical types of event sequences --- kidnappings and corporate acquisitions -- we distinguish between articles providing in-depth coverage, those having multiple sentences mentioning the same event sequence, from articles making a passing mention in just one sentence. We find that, after an event sequence concludes, passing mentions become more common and there are significantly fewer mean mentions per article.",iConference,2011.0,5,0,"[{'authorId': '3003604', 'name': 'Earl J. Wagner'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
60603f300453a6c327042f76cbdba6625498946e,https://www.semanticscholar.org/paper/60603f300453a6c327042f76cbdba6625498946e,Smoothing techniques for adaptive online language models: topic tracking in tweet streams,"We are interested in the problem of tracking broad topics such as ""baseball"" and ""fashion"" in continuous streams of short texts, exemplified by tweets from the microblogging service Twitter. The task is conceived as a language modeling problem where per-topic models are trained using hashtags in the tweet stream, which serve as proxies for topic labels. Simple perplexity-based classifiers are then applied to filter the tweet stream for topics of interest. Within this framework, we evaluate, both intrinsically and extrinsically, smoothing techniques for integrating ""foreground"" models (to capture recency) and ""background"" models (to combat sparsity), as well as different techniques for retaining history. Experiments show that unigram language models smoothed using a normalized extension of stupid backoff and a simple queue for history retention performs well on the task.",Knowledge Discovery and Data Mining,2011.0,22,124,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144621026', 'name': 'R. Snow'}, {'authorId': '2059495111', 'name': 'William Morgan'}]"
639c5d11e675b0287342399e2094dbe47f9e4b44,https://www.semanticscholar.org/paper/639c5d11e675b0287342399e2094dbe47f9e4b44,A cascade ranking model for efficient ranked retrieval,"There is a fundamental tradeoff between effectiveness and efficiency when designing retrieval models for large-scale document collections. Effectiveness tends to derive from sophisticated ranking functions, such as those constructed using learning to rank, while efficiency gains tend to arise from improvements in query evaluation and caching strategies. Given their inherently disjoint nature, it is difficult to jointly optimize effectiveness and efficiency in end-to-end systems. To address this problem, we formulate and develop a novel cascade ranking model, which unlike previous approaches, can simultaneously improve both top k ranked effectiveness and retrieval efficiency. The model constructs a cascade of increasingly complex ranking functions that progressively prunes and refines the set of candidate documents to minimize retrieval latency and maximize result set quality. We present a novel boosting algorithm for learning such cascades to directly optimize the tradeoff between effectiveness and efficiency. Experimental results show that our cascades are faster and return higher quality results than comparable ranking models.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2011.0,31,220,"[{'authorId': '2144660311', 'name': 'Lidan Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680617', 'name': 'Donald Metzler'}]"
bc080a666b562e8b7d7059bc0cc8c9b4152f742f,https://www.semanticscholar.org/paper/bc080a666b562e8b7d7059bc0cc8c9b4152f742f,"Automatic management of partitioned, replicated search services","Low-latency, high-throughput web services are typically achieved through partitioning, replication, and caching. Although these strategies and the general design of large-scale distributed search systems are well known, the academic literature provides surprisingly few details on deployment and operational considerations in production environments. In this paper, we address this gap by sharing the distributed search architecture that underlies Twitter user search, a service for discovering relevant accounts on the popular microblogging service. Our design makes use of the principle that eliminates the distinction between failure and other anticipated service disruptions: as a result, most operational scenarios share exactly the same code path. This simplicity leads to greater robustness and fault-tolerance. Another salient feature of our architecture is its exclusive reliance on open-source software components, which makes it easier for the community to learn from our experiences and replicate our findings.",ACM Symposium on Cloud Computing,2011.0,16,14,"[{'authorId': '3239527', 'name': 'Florian Leibert'}, {'authorId': '2712938', 'name': 'J. Mannix'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '133705072', 'name': 'B. Hamadani'}]"
ce8975c7f186223954c6f348181b2904161c68bd,https://www.semanticscholar.org/paper/ce8975c7f186223954c6f348181b2904161c68bd,No Free Lunch: Brute Force vs. Locality-Sensitive Hashing for Cross-lingual Pairwise Similarity,"This work explores the problem of cross-lingual pairwise similarity, where the task is to extract similar pairs of documents across two different languages. Solutions to this problem are of general interest for text mining in the multilingual context and have specific applications in statistical machine translation. Our approach takes advantage of cross-language information retrieval (CLIR) techniques to project feature vectors from one language into another, and then uses locality-sensitive hashing (LSH) to extract similar pairs. We show that effective cross-lingual pairwise similarity requires working with similarity thresholds that are much lower than in typical monolingual applications, making the problem quite challenging. We present a parallel, scalable MapReduce implementation of the sort-based sliding window algorithm, which is compared to a brute-force approach on German and English Wikipedia collections. Our central finding can be summarized as‚Äúno free lunch‚Äù: there is no single optimal solution. Instead, we characterize effectivenessefficiency tradeoffs in the solution space, which can guide the developer to locate a desirable operating point based on applicationand resource-specific constraints.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2011.0,37,48,"[{'authorId': '2851411', 'name': 'Ferhan Ture'}, {'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
f5fbee4c06709d7a192aad33c6d29a882074f73f,https://www.semanticscholar.org/paper/f5fbee4c06709d7a192aad33c6d29a882074f73f,Overview of the TREC 2011 Microblog Track,,Text Retrieval Conference,2011.0,11,244,"[{'authorId': '1698205', 'name': 'I. Ounis'}, {'authorId': '145434248', 'name': 'Craig Macdonald'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144526707', 'name': 'I. Soboroff'}]"
3394edbb49705a1763102bbb45d6d47e2ec78d99,https://www.semanticscholar.org/paper/3394edbb49705a1763102bbb45d6d47e2ec78d99,Putting the User in the Loop: Interactive Maximal Marginal Relevance for Query-Focused Summarization,"This work represents an initial attempt to move beyond ""single-shot"" summarization to interactive summarization. We present an extension to the classic Maximal Marginal Relevance (MMR) algorithm that places a user ""in the loop"" to assist in candidate selection. Experiments in the complex interactive Question Answering (ciQA) task at TREC 2007 show that interactively-constructed responses are significantly higher in quality than automatically-generated ones. This novel algorithm provides a starting point for future work on interactive summarization.",North American Chapter of the Association for Computational Linguistics,2010.0,6,30,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1723404', 'name': 'Nitin Madnani'}, {'authorId': '1752326', 'name': 'B. Dorr'}]"
36570c056c09d4f27b37be180668bf80c5b13505,https://www.semanticscholar.org/paper/36570c056c09d4f27b37be180668bf80c5b13505,Design patterns for efficient graph algorithms in MapReduce,"Graphs are analyzed in many important contexts, including ranking search results based on the hyperlink structure of the world wide web, module detection of proteinprotein interaction networks, and privacy analysis of social networks. Many graphs of interest are difficult to analyze because of their large size, often spanning millions of vertices and billions of edges. As such, researchers have increasingly turned to distributed solutions. In particular, MapReduce has emerged as an enabling technology for large-scale graph processing. However, existing best practices for MapReduce graph algorithms have significant shortcomings that limit performance, especially with respect to partitioning, serializing, and distributing the graph. In this paper, we present three design patterns that address these issues and can be used to accelerate a large class of graph algorithms based on message passing, exemplified by PageRank. Experiments show that the application of our design patterns reduces the running time of PageRank on a web graph with 1.4 billion edges by 69%.",Mining and Learning with Graphs,2010.0,22,190,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2205516', 'name': 'M. Schatz'}]"
508732db9cbe6cbf6dc1a5451090a0cec950a7f4,https://www.semanticscholar.org/paper/508732db9cbe6cbf6dc1a5451090a0cec950a7f4,Book Reviews: Data-Intensive Text Processing with MapReduce by Jimmy Lin and Chris Dyer,"This half-day tutorial introduces participants to data-intensive text processing with the MapReduce programming model [1], using the open-source Hadoop implementation. The focus will be on scalability and the tradeoffs associated with distributed processing of large datasets. Content will include general discussions about algorithm design, presentation of illustrative algorithms, case studies in HLT applications, as well as practical advice in writing Hadoop programs and running Hadoop clusters.",International Conference on Computational Logic,2010.0,169,327,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1745899', 'name': 'Chris Dyer'}]"
780606b8e4ef77856d3544bc5c259259a5968732,https://www.semanticscholar.org/paper/780606b8e4ef77856d3544bc5c259259a5968732,Scaling Populations of a Genetic Algorithm for Job Shop Scheduling Problems Using MapReduce,"Inspired by Darwinian evolution, a genetic algorithm (GA) approach is one popular heuristic method for solving hard problems such as the Job Shop Scheduling Problem (JSSP), which is one of the hardest problems lacking efficient exact solutions today. It is intuitive that the population size of a GA may greatly affect the quality of the solution, but it is unclear what are the effects of having population sizes that are significantly greater than typical experiments. The emergence of MapReduce, a framework running on a cluster of computers that aims to provide large-scale data processing, offers great opportunities to investigate this issue. In this paper, a GA is implemented to scale the population using MapReduce. Experiments are conducted on a large cluster, and population sizes up to 10^7 are inspected. It is shown that larger population sizes not only tend to yield better solutions, but also require fewer generations. Therefore, it is clear that when dealing with a hard problem such as JSSP, an existing GA can be improved by massively scaling up populations with MapReduce, so that the solution can be parallelized and completed in reasonable time.",2010 IEEE Second International Conference on Cloud Computing Technology and Science,2010.0,26,50,"[{'authorId': '2741672', 'name': 'Di-Wei Huang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
8b9fd410631800579e1e697d71fe56fbc8f4e51f,https://www.semanticscholar.org/paper/8b9fd410631800579e1e697d71fe56fbc8f4e51f,"Brute-Force Approaches to Batch Retrieval : Scalable Indexing with MapReduce , or Why Bother ?","Modern information retrieval research has evolved a standard workflow that involves first indexing a document collection and then running ad hoc queries sequentially to evaluate retrieval effectiveness using standard test collections. This paper explores how aspects of this workflow might change in a MapReduce cluster-based environment. First, we present and evaluate two algorithms for inverted indexing that take advantage of the programming model‚Äôs sorting mechanism to different extents. The running times of both algorithms scale linearly in terms of collection size up to 102 million web pages. Second, we show that it is possible to efficiently perform batch query evaluation with MapReduce by scanning all postings lists in parallel, as opposed to sequentially accessing each postings list. Third, we explore an approach that forgoes inverted indexing altogether and simply computes all query‚Äìdocument scores from document vectors themselves. Experimental results challenge us to think differently about previous assumptions in information retrieval, and show that brute force approaches are surprisingly compelling under certain circumstances: parallel scan of postings can effectively take advantage of large clusters and parallel scan of documents fits naturally with ranking functions that use document-level features.",,2010.0,37,8,"[{'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '52416773', 'name': 'Ferhan Ture'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b7f7f93993d5eae0f1842aa239ea460047bfc58a,https://www.semanticscholar.org/paper/b7f7f93993d5eae0f1842aa239ea460047bfc58a,Web-scale computer vision using MapReduce for multimedia data mining,"This work explores computer vision applications of the MapReduce framework that are relevant to the data mining community. An overview of MapReduce and common design patterns are provided for those with limited MapReduce background. We discuss both the high level theory and the low level implementation for several computer vision algorithms: classifier training, sliding windows, clustering, bag-of-features, background subtraction, and image registration. Experimental results for the k-means clustering and single Gaussian background subtraction algorithms are performed on a 410 node Hadoop cluster.",MDMKDD '10,2010.0,26,93,"[{'authorId': '37929982', 'name': 'B. White'}, {'authorId': '2059814276', 'name': 'Tom Yeh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1693428', 'name': 'L. Davis'}]"
d679c127eea865d99f593b315c4c9927636d2a10,https://www.semanticscholar.org/paper/d679c127eea865d99f593b315c4c9927636d2a10,Ranking under temporal constraints,"This paper introduces the notion of temporally constrained ranked retrieval, which, given a query and a time constraint, produces the best possible ranked list within the specified time limit. Naturally, more time should translate into better results, but the ranking algorithm should always produce some results. This property is desirable from a number of perspectives: to cope with diverse users and information needs, as well as to better manage system load and variance in query execution times. We propose two temporally constrained ranking algorithms based on a class of probabilistic prediction models that can naturally incorporate efficiency constraints: one that makes independent feature selection decisions, and the other that makes joint feature selection decisions. Experiments on three different test collections show that both ranking algorithms are able to satisfy imposed time constraints, although the joint model outperforms the independent model in being able to deliver more effective results, especially under tight time constraints, due to its ability to capture feature dependencies.",International Conference on Information and Knowledge Management,2010.0,27,39,"[{'authorId': '2144660311', 'name': 'Lidan Wang'}, {'authorId': '1680617', 'name': 'Donald Metzler'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e24f6d293cd423a88249ea1ec0e0e2c56a55b3bb,https://www.semanticscholar.org/paper/e24f6d293cd423a88249ea1ec0e0e2c56a55b3bb,UMD and USC/ISI: TREC 2010 Web Track Experiments with Ivory,"Ivory is a web-scale retrieval engine we have been developing for the past two years, built around a cluster-based environment running Hadoop, the open-source implementation of the MapReduce programming model. Building on successes last year at TREC, we explored two major directions this year: more sophisticated retrieval models and large-scale graph analysis for spam detection. We describe results of ad hoc retrieval experiments with latent concept expansion and a greedily-learned linear ranking model. Although neither model is novel, our experiments provide some insight on the behavior of these two approaches at scale, on collections larger than those previously studied. We also discuss our link-based spam filtering algorithm that operated on the entire web graph of ClueWeb09. Unfortunately, results in the spam track were worse than the baseline provided by the track organizers.",Text Retrieval Conference,2010.0,28,8,"[{'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '2144660311', 'name': 'Lidan Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680617', 'name': 'Donald Metzler'}]"
0a9f61a9ff4d99b30e76193496951867a4894b66,https://www.semanticscholar.org/paper/0a9f61a9ff4d99b30e76193496951867a4894b66,Of Ivory and Smurfs: Loxodontan MapReduce Experiments for Web Search,"This paper describes Ivory, an attempt to build a distributed retrieval system around the open-source Hadoop implementation of MapReduce. We focus on three noteworthy aspects of our work: a retrieval architecture built directly on the Hadoop Distributed File System (HDFS), a scalable MapReduce algorithm for inverted indexing, and webpage classification to enhance retrieval effectiveness.",Text Retrieval Conference,2009.0,19,51,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '2144660311', 'name': 'Lidan Wang'}, {'authorId': '1680617', 'name': 'Donald Metzler'}]"
164dab5afb4688a664be6d2dd3f43bee8983ae8a,https://www.semanticscholar.org/paper/164dab5afb4688a664be6d2dd3f43bee8983ae8a,Elements of a computational model for multi-party discourse: The turn-taking behavior of Supreme Court justices,"This paper explores computational models of multi-party discourse, using transcripts from U.S. Supreme Court oral arguments. The turn-taking behavior of participants is treated as a supervised sequence labeling problem and modeled using firstand secondorder Conditional Random Fields. We specifically explore the hypothesis that discourse markers and personal references provide important features in such models. Results from a sequence prediction experiment demonstrate that incorporating these two types of features yields significant improvements in performance. This work is couched in the broader context of developing tools to support legal scholarship, although we see other NLP applications as well. Publication Date: January 14, 2008",J. Assoc. Inf. Sci. Technol.,2009.0,25,23,"[{'authorId': '34615980', 'name': 'T. Hawes'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680292', 'name': 'P. Resnik'}]"
213b352b58e060d18ee3ca25779543e3659628f2,https://www.semanticscholar.org/paper/213b352b58e060d18ee3ca25779543e3659628f2,Service Bus,,Encyclopedia of Database Systems,2009.0,0,8,"[{'authorId': '1695840', 'name': 'R. Topor'}, {'authorId': '145527641', 'name': 'K. Salem'}, {'authorId': '1722619', 'name': 'Amarnath Gupta'}, {'authorId': '1806014', 'name': 'K. Goda'}, {'authorId': '120962807', 'name': 'J. Gehrke'}, {'authorId': '1739132', 'name': 'N. Palmer'}, {'authorId': '1473458210', 'name': 'Mohamed Sharaf'}, {'authorId': '1716685', 'name': 'Alexandros Labrinidis'}, {'authorId': '1707518', 'name': 'J. Roddick'}, {'authorId': '2326719', 'name': 'Ariel Fuxman'}, {'authorId': '2116284480', 'name': 'Ren√©e J. Miller'}, {'authorId': '2131764025', 'name': 'Wang-Chiew Tan'}, {'authorId': '1687892', 'name': 'Anastasios Kementsietsidis'}, {'authorId': '1736800318', 'name': 'Philippe Bonnet'}, {'authorId': '1695878', 'name': 'D. Shasha'}, {'authorId': '2044073', 'name': 'R. Peikert'}, {'authorId': '1716911', 'name': 'Bertram Lud√§scher'}, {'authorId': '1900211', 'name': 'S. Bowers'}, {'authorId': '2737817', 'name': 'T. McPhillips'}, {'authorId': '144441900', 'name': 'Harald Naumann'}, {'authorId': '1780707', 'name': 'K. Voruganti'}, {'authorId': '1393591007', 'name': 'J. Domingo-Ferrer'}, {'authorId': '1750995', 'name': 'Ben Carterette'}, {'authorId': '1392254815', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '144658846', 'name': 'M. Arenas'}, {'authorId': '1796253', 'name': 'Y. Manolopoulos'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '1761528', 'name': 'V. Tsotras'}, {'authorId': '1678413', 'name': 'B. Carminati'}, {'authorId': '9461483', 'name': 'Jan Jurjens'}, {'authorId': '2111793021', 'name': 'E. Fern√°ndez'}, {'authorId': '1741044', 'name': 'Murat Kantarcioglu'}, {'authorId': '145033630', 'name': 'Jaideep Vaidya'}, {'authorId': '144039860', 'name': 'I. Ray'}, {'authorId': '1741423', 'name': 'A. Vakali'}, {'authorId': '1896793', 'name': 'Cristina Sirangelo'}, {'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '145873061', 'name': 'H. Gupta'}, {'authorId': '145647476', 'name': 'S. Chaudhuri'}, {'authorId': '1751591', 'name': 'G. Weikum'}, {'authorId': '1693022', 'name': 'U. Leser'}, {'authorId': '1694279', 'name': 'D. Embley'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}, {'authorId': '2418440', 'name': 'P. Shvaiko'}, {'authorId': '2228676', 'name': 'Mikalai Yatskevich'}, {'authorId': '2064990932', 'name': 'Edward Y. Chang'}, {'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1697955', 'name': 'E. Zim√°nyi'}, {'authorId': '2754289', 'name': 'G. Anadiotis'}, {'authorId': '1680354', 'name': 'S. Kotoulas'}, {'authorId': '1784751', 'name': 'R. Siebes'}, {'authorId': '1746617', 'name': 'G. Antoniou'}, {'authorId': '1705358', 'name': 'D. Plexousakis'}, {'authorId': '145148572', 'name': 'J. Bailey'}, {'authorId': '1767012', 'name': 'Fran√ßois Bry'}, {'authorId': '2874808', 'name': 'Tim Furche'}, {'authorId': '1777556', 'name': 'Sebastian Schaffert'}, {'authorId': '152122277', 'name': 'David Martin'}, {'authorId': '1768196', 'name': 'Gregory D. Speegle'}, {'authorId': '1704729', 'name': 'K. Ramamritham'}, {'authorId': '1728643', 'name': 'Panos K. Chrysanthis'}, {'authorId': '1716839', 'name': 'K. Sattler'}, {'authorId': '1735321', 'name': 'S. Bressan'}, {'authorId': '69026873', 'name': 'S. Abiteboul'}, {'authorId': '144823759', 'name': 'Dan Suciu'}, {'authorId': '152945656', 'name': 'G. Dobbie'}, {'authorId': '1798818', 'name': 'T. Ling'}, {'authorId': '40632403', 'name': 'Sugato Basu'}, {'authorId': '1747970', 'name': 'R. Govindan'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '144572233', 'name': 'C. Jensen'}, {'authorId': '2109084789', 'name': 'Jianyong Wang'}, {'authorId': '2295920', 'name': 'K. Vidyasankar'}, {'authorId': '145017583', 'name': 'A. Chan'}, {'authorId': '52411592', 'name': 'Serge Mankovski'}, {'authorId': '1767761', 'name': 'S. Elnikety'}, {'authorId': '144255847', 'name': 'P. Valduriez'}, {'authorId': '2163752', 'name': 'Yannis Velegrakis'}, {'authorId': '144977963', 'name': 'M. Nascimento'}, {'authorId': '143956131', 'name': 'Michael Huggett'}, {'authorId': '1803067', 'name': 'A. Frank'}, {'authorId': '49889222', 'name': 'Yanchun Zhang'}, {'authorId': '2149131224', 'name': 'Guandong Xu'}, {'authorId': '1739732', 'name': 'R. Snodgrass'}, {'authorId': '144406831', 'name': 'A. Fekete'}, {'authorId': '153481005', 'name': 'M. Herzog'}, {'authorId': '2363116', 'name': 'Konstantinos Morfonios'}, {'authorId': '1684197', 'name': 'Y. Ioannidis'}, {'authorId': '1789749', 'name': 'E. Wohlstadter'}, {'authorId': '145228093', 'name': 'M. Matera'}, {'authorId': '2668326', 'name': 'F. Schwagereit'}, {'authorId': '1752093', 'name': 'Steffen Staab'}, {'authorId': '37026706', 'name': 'K. Fraser'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '1756679', 'name': 'M. Mokbel'}, {'authorId': '1709661', 'name': 'W. Aref'}, {'authorId': '144531003', 'name': 'M. Moro'}, {'authorId': '144995341', 'name': 'Markus Schneider'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '3277872', 'name': 'G. Ghinita'}, {'authorId': '2191738', 'name': 'M. Goodchild'}, {'authorId': '2113354821', 'name': 'Shashi Shekhar'}, {'authorId': '35102788', 'name': 'James M. Kang'}, {'authorId': '2047487638', 'name': 'Vijay Gandhi'}, {'authorId': '1718168', 'name': 'N. Mamoulis'}, {'authorId': '66668960', 'name': 'Betsy George'}, {'authorId': '144911319', 'name': 'M. Scholl'}, {'authorId': '1739159', 'name': 'A. Voisard'}, {'authorId': '3068011', 'name': 'R. H. G√ºting'}, {'authorId': '144779196', 'name': 'Yufei Tao'}, {'authorId': '1746338', 'name': 'Dimitris Papadias'}, {'authorId': '1805545', 'name': 'P. Revesz'}, {'authorId': '1715771', 'name': 'G. Kollios'}, {'authorId': '2823398', 'name': 'E. Frentzos'}, {'authorId': '1394219663', 'name': 'Apostolos N. Papadopoulos'}, {'authorId': '1734945', 'name': 'B. Thalheim'}, {'authorId': '3324944', 'name': 'J. Pehcevski'}, {'authorId': '2065256246', 'name': 'Benjamin Piwowarski'}, {'authorId': '9261284', 'name': 'S. Theodoridis'}, {'authorId': '1758377', 'name': 'K. Koutroumbas'}, {'authorId': '1702232', 'name': 'George Karabatis'}, {'authorId': '5525539', 'name': 'D. Chamberlin'}, {'authorId': '1737944', 'name': 'P. Bernstein'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '1719053', 'name': 'J. Gamper'}, {'authorId': '14274793', 'name': 'Ping Li'}, {'authorId': '1755147', 'name': 'K. Subieta'}, {'authorId': '2367532', 'name': 'S. Harizopoulos'}, {'authorId': '3270238', 'name': 'Ethan Zhang'}, {'authorId': '144884116', 'name': 'Yi Zhang'}, {'authorId': '145633895', 'name': 'T. Johnson'}, {'authorId': '145641161', 'name': 'H. Jacobsen'}, {'authorId': '1684961', 'name': 'S. Fienberg'}, {'authorId': '2115757855', 'name': 'Jiashun Jin'}, {'authorId': '1764620', 'name': 'R. Sion'}, {'authorId': '3259579', 'name': 'C. Paice'}, {'authorId': '103694459', 'name': 'Nikos Hardavellas'}, {'authorId': '2754078', 'name': 'Ippokratis Pandis'}, {'authorId': '34066017', 'name': 'E. Rasmussen'}, {'authorId': '2107332919', 'name': 'H. Yoshida'}, {'authorId': '1799376', 'name': 'G. Graefe'}, {'authorId': '2246578', 'name': 'B. Reiner'}, {'authorId': '145105823', 'name': 'K. Hahn'}, {'authorId': '1783767', 'name': 'K. Wada'}, {'authorId': '48250034', 'name': 'T. Risch'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1688834', 'name': 'Lukasz Golab'}, {'authorId': '145345023', 'name': 'M. Stonebraker'}, {'authorId': '2095429', 'name': 'Bibudh Lahiri'}, {'authorId': '1679836', 'name': 'Srikanta Tirthapura'}, {'authorId': '1791896', 'name': 'Erik Vee'}, {'authorId': '1841612', 'name': 'Yanif Ahmad'}, {'authorId': '2109957', 'name': 'U. √áetintemel'}, {'authorId': '31987589', 'name': 'Mitch Cherniack'}, {'authorId': '2031287', 'name': 'S. Zdonik'}, {'authorId': '1735847', 'name': 'M. Consens'}, {'authorId': '1684032', 'name': 'M. Lalmas'}, {'authorId': '1389957009', 'name': 'R. Baeza-Yates'}, {'authorId': '1691929', 'name': 'D. Hiemstra'}, {'authorId': '1394219580', 'name': 'Peer Kr√∂gerand'}, {'authorId': '3310376', 'name': 'Arthur Zimek'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '1726081', 'name': 'C. Leung'}, {'authorId': '144017417', 'name': 'M. Crochemore'}, {'authorId': '1712103', 'name': 'T. Lecroq'}, {'authorId': '1747737', 'name': 'A. Shoshani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '71397603', 'name': 'Hw Yu'}, {'authorId': '1785673', 'name': 'D. Lomet'}, {'authorId': '1864967', 'name': 'H. Hinterberger'}, {'authorId': '12671514', 'name': 'Ninghui Li'}, {'authorId': '1394219579', 'name': 'Phillip B. Gibbons'}, {'authorId': '1910151', 'name': 'Mouna Kacimi'}, {'authorId': '2053024606', 'name': 'Thomas Neumann'}]"
275ef33ad3f36956a65a72c464e79ff53c20ce59,https://www.semanticscholar.org/paper/275ef33ad3f36956a65a72c464e79ff53c20ce59,Proceedings of the 18th ACM conference on Information and knowledge management,"On behalf of the organizing committee, we wholeheartedly welcome you to the ACM Eighteenth International Conference on Information and Knowledge Management (CIKM 2009). We hope this conference proves to be interesting and beneficial. 
 
CIKM 2009 was originally planned to be held in Beijing, China. However, due to unforeseen reasons, CIKM 2009 had to be moved to Hong Kong in early December 2009, and the organizing committee was re-invited. This late re-organization of the conference caused many troubles and much burden in terms of preparation and financial costs. Despite the shortened time period and financial problems, David Cheung, the newly invited General co-Chair, and his local team worked very diligently to carefully prepare an outstanding program for everyone. 
 
Since its inception, the CIKM conference has provided a unique international forum for the presentation, discussion, and dissemination of research findings in data management, information retrieval, and knowledge management. The conference has been a leading forum in which experts from academia, industry, and the government gather to exchange ideas, research achievements, and technical developments in multidisciplinary research areas. 
 
CIKM has rapidly grown to become one of the world's most recognized conferences in the field. CIKM 2009 has received a record high number of submissions in the history of CIKM, as can be seen from the following statistics: - 1153 abstracts submitted - 847 full papers submitted - 123 papers accepted for presentation as full papers (14.5% acceptance rate) and an additional 171 were accepted for poster presentation. 
 
In addition to regular research tracks, CIKM 2009 features 3 keynote speakers, 4 pre-conference tutorials, 11 workshops, 18 industrial papers, 24 demo papers, and 1 panel. We are proud of our program and acknowledge the tireless efforts of people who materialized this program. 
 
First of all, we are honored to have 3 distinguished keynote speakers: Kyu-Young Whang, Edward Chang, and Clement Yu. We deeply appreciate their time and commitment to attend our conference and share their cutting-edge research experiences and insightful comments in their research topics.",International Conference on Information and Knowledge Management,2009.0,0,13,"[{'authorId': '1723793', 'name': 'D. Cheung'}, {'authorId': '144436171', 'name': 'I. Song'}, {'authorId': '1724907', 'name': 'W. Chu'}, {'authorId': '145161991', 'name': 'Xiaohua Hu'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
295bdd383af9e8efb3fcc81267834fdac5f762f0,https://www.semanticscholar.org/paper/295bdd383af9e8efb3fcc81267834fdac5f762f0,Users' adjustments to unsuccessful queries in biomedical search,"Biomedical researchers depend on on-line databases and digital libraries for up to date information. We introduce a pilot project aimed at characterizing adjustments made to biomedical queries that improve search results. Specifically we focus on queries submitted to PubMed¬Æ, a large sophisticated search engine that facilitates Web access to abstracts of articles in over 5,200 biomedical journals. On average 2 million users search PubMed each day. During their search, nearly 20% will experience a result page from one of their queries that has zero results. In some cases there really is no document or abstract that will satisfy a particular query. However, in analyzing one month of queries submitted to PubMed, we find that more often than not, queries that retrieved no results are queries that would retrieve something relevant if they were constructed differently. This paper describes a new effort to identify some of the characteristics of a query that produces zero results, and the changes that users most often apply in constructing new, ""corrected"" queries. Zero-result queries afford us an opportunity to examine changes made to queries that we know did not return relevant data, because they did not return any data. An investigation of the changes users make under these circumstances can yield insight into users' search processes.",ACM/IEEE Joint Conference on Digital Libraries,2009.0,0,2,"[{'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1695611', 'name': 'W. Wilbur'}, {'authorId': '144202084', 'name': 'Zhiyong Lu'}]"
2fcc6783f79adb5ae7c0eb8c1604c2089a0e881f,https://www.semanticscholar.org/paper/2fcc6783f79adb5ae7c0eb8c1604c2089a0e881f,Statistical Disclosure Control (SDC),,Encyclopedia of Database Systems,2009.0,0,0,"[{'authorId': '1695840', 'name': 'R. Topor'}, {'authorId': '145527641', 'name': 'K. Salem'}, {'authorId': '1722619', 'name': 'Amarnath Gupta'}, {'authorId': '1806014', 'name': 'K. Goda'}, {'authorId': '143614516', 'name': 'J. Gehrke'}, {'authorId': '1739132', 'name': 'N. Palmer'}, {'authorId': '1473458210', 'name': 'Mohamed Sharaf'}, {'authorId': '1716685', 'name': 'Alexandros Labrinidis'}, {'authorId': '1707518', 'name': 'J. Roddick'}, {'authorId': '2326719', 'name': 'Ariel Fuxman'}, {'authorId': '2116284480', 'name': 'Ren√©e J. Miller'}, {'authorId': '2131764025', 'name': 'Wang-Chiew Tan'}, {'authorId': '1687892', 'name': 'Anastasios Kementsietsidis'}, {'authorId': '1736800318', 'name': 'Philippe Bonnet'}, {'authorId': '1695878', 'name': 'D. Shasha'}, {'authorId': '2044073', 'name': 'R. Peikert'}, {'authorId': '1716911', 'name': 'Bertram Lud√§scher'}, {'authorId': '1900211', 'name': 'S. Bowers'}, {'authorId': '2737817', 'name': 'T. McPhillips'}, {'authorId': '144441900', 'name': 'Harald Naumann'}, {'authorId': '1780707', 'name': 'K. Voruganti'}, {'authorId': '1393591007', 'name': 'J. Domingo-Ferrer'}, {'authorId': '1750995', 'name': 'Ben Carterette'}, {'authorId': '1392254815', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '144658846', 'name': 'M. Arenas'}, {'authorId': '1796253', 'name': 'Y. Manolopoulos'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '1761528', 'name': 'V. Tsotras'}, {'authorId': '1678413', 'name': 'B. Carminati'}, {'authorId': '9461483', 'name': 'Jan Jurjens'}, {'authorId': '2111793021', 'name': 'E. Fern√°ndez'}, {'authorId': '1741044', 'name': 'Murat Kantarcioglu'}, {'authorId': '145033630', 'name': 'Jaideep Vaidya'}, {'authorId': '144039860', 'name': 'I. Ray'}, {'authorId': '1741423', 'name': 'A. Vakali'}, {'authorId': '1896793', 'name': 'Cristina Sirangelo'}, {'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '145873061', 'name': 'H. Gupta'}, {'authorId': '145647476', 'name': 'S. Chaudhuri'}, {'authorId': '1751591', 'name': 'G. Weikum'}, {'authorId': '1693022', 'name': 'U. Leser'}, {'authorId': '1694279', 'name': 'D. Embley'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}, {'authorId': '2418440', 'name': 'P. Shvaiko'}, {'authorId': '2228676', 'name': 'Mikalai Yatskevich'}, {'authorId': '33794424', 'name': 'E. Chang'}, {'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1697955', 'name': 'E. Zim√°nyi'}, {'authorId': '2754289', 'name': 'G. Anadiotis'}, {'authorId': '1680354', 'name': 'S. Kotoulas'}, {'authorId': '1784751', 'name': 'R. Siebes'}, {'authorId': '1746617', 'name': 'G. Antoniou'}, {'authorId': '1705358', 'name': 'D. Plexousakis'}, {'authorId': '145148572', 'name': 'J. Bailey'}, {'authorId': '1767012', 'name': 'Fran√ßois Bry'}, {'authorId': '2874808', 'name': 'Tim Furche'}, {'authorId': '1777556', 'name': 'Sebastian Schaffert'}, {'authorId': '152122277', 'name': 'David Martin'}, {'authorId': '1768196', 'name': 'Gregory D. Speegle'}, {'authorId': '1704729', 'name': 'K. Ramamritham'}, {'authorId': '1728643', 'name': 'Panos K. Chrysanthis'}, {'authorId': '1716839', 'name': 'K. Sattler'}, {'authorId': '1735321', 'name': 'S. Bressan'}, {'authorId': '69026873', 'name': 'S. Abiteboul'}, {'authorId': '144823759', 'name': 'Dan Suciu'}, {'authorId': '152945656', 'name': 'G. Dobbie'}, {'authorId': '1798818', 'name': 'T. Ling'}, {'authorId': '40632403', 'name': 'Sugato Basu'}, {'authorId': '1747970', 'name': 'R. Govindan'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '144572233', 'name': 'C. Jensen'}, {'authorId': '2109084789', 'name': 'Jianyong Wang'}, {'authorId': '2295920', 'name': 'K. Vidyasankar'}, {'authorId': '145017583', 'name': 'A. Chan'}, {'authorId': '52411592', 'name': 'Serge Mankovski'}, {'authorId': '1767761', 'name': 'S. Elnikety'}, {'authorId': '144255847', 'name': 'P. Valduriez'}, {'authorId': '2163752', 'name': 'Yannis Velegrakis'}, {'authorId': '144977963', 'name': 'M. Nascimento'}, {'authorId': '143956131', 'name': 'Michael Huggett'}, {'authorId': '1803067', 'name': 'A. Frank'}, {'authorId': '49889222', 'name': 'Yanchun Zhang'}, {'authorId': '2149131224', 'name': 'Guandong Xu'}, {'authorId': '1739732', 'name': 'R. Snodgrass'}, {'authorId': '144406831', 'name': 'A. Fekete'}, {'authorId': '153481005', 'name': 'M. Herzog'}, {'authorId': '2363116', 'name': 'Konstantinos Morfonios'}, {'authorId': '1684197', 'name': 'Y. Ioannidis'}, {'authorId': '1789749', 'name': 'E. Wohlstadter'}, {'authorId': '145228093', 'name': 'M. Matera'}, {'authorId': '2668326', 'name': 'F. Schwagereit'}, {'authorId': '1752093', 'name': 'Steffen Staab'}, {'authorId': '37026706', 'name': 'K. Fraser'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '1756679', 'name': 'M. Mokbel'}, {'authorId': '1709661', 'name': 'W. Aref'}, {'authorId': '144531003', 'name': 'M. Moro'}, {'authorId': '144995341', 'name': 'Markus Schneider'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '3277872', 'name': 'G. Ghinita'}, {'authorId': '2191738', 'name': 'M. Goodchild'}, {'authorId': '2057331062', 'name': 'Shashi Shekhar'}, {'authorId': '35102788', 'name': 'James M. Kang'}, {'authorId': '2047487638', 'name': 'Vijay Gandhi'}, {'authorId': '1718168', 'name': 'N. Mamoulis'}, {'authorId': '66668960', 'name': 'Betsy George'}, {'authorId': '144911319', 'name': 'M. Scholl'}, {'authorId': '1739159', 'name': 'A. Voisard'}, {'authorId': '3068011', 'name': 'R. H. G√ºting'}, {'authorId': '144779196', 'name': 'Yufei Tao'}, {'authorId': '1746338', 'name': 'Dimitris Papadias'}, {'authorId': '1805545', 'name': 'P. Revesz'}, {'authorId': '1715771', 'name': 'G. Kollios'}, {'authorId': '2823398', 'name': 'E. Frentzos'}, {'authorId': '1394219663', 'name': 'Apostolos N. Papadopoulos'}, {'authorId': '1734945', 'name': 'B. Thalheim'}, {'authorId': '3324944', 'name': 'J. Pehcevski'}, {'authorId': '2065256246', 'name': 'Benjamin Piwowarski'}, {'authorId': '9261284', 'name': 'S. Theodoridis'}, {'authorId': '1758377', 'name': 'K. Koutroumbas'}, {'authorId': '1702232', 'name': 'George Karabatis'}, {'authorId': '5525539', 'name': 'D. Chamberlin'}, {'authorId': '1737944', 'name': 'P. Bernstein'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '1719053', 'name': 'J. Gamper'}, {'authorId': '14274793', 'name': 'Ping Li'}, {'authorId': '1755147', 'name': 'K. Subieta'}, {'authorId': '2367532', 'name': 'S. Harizopoulos'}, {'authorId': '3270238', 'name': 'Ethan Zhang'}, {'authorId': '144884116', 'name': 'Yi Zhang'}, {'authorId': '145633895', 'name': 'T. Johnson'}, {'authorId': '145641161', 'name': 'H. Jacobsen'}, {'authorId': '1684961', 'name': 'S. Fienberg'}, {'authorId': '2115757855', 'name': 'Jiashun Jin'}, {'authorId': '1764620', 'name': 'R. Sion'}, {'authorId': '3259579', 'name': 'C. Paice'}, {'authorId': '103694459', 'name': 'Nikos Hardavellas'}, {'authorId': '2754078', 'name': 'Ippokratis Pandis'}, {'authorId': '34066017', 'name': 'E. Rasmussen'}, {'authorId': '2107332919', 'name': 'H. Yoshida'}, {'authorId': '1799376', 'name': 'G. Graefe'}, {'authorId': '2246578', 'name': 'B. Reiner'}, {'authorId': '145105823', 'name': 'K. Hahn'}, {'authorId': '1783767', 'name': 'K. Wada'}, {'authorId': '48250034', 'name': 'T. Risch'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1688834', 'name': 'Lukasz Golab'}, {'authorId': '145345023', 'name': 'M. Stonebraker'}, {'authorId': '2095429', 'name': 'Bibudh Lahiri'}, {'authorId': '1679836', 'name': 'Srikanta Tirthapura'}, {'authorId': '1791896', 'name': 'Erik Vee'}, {'authorId': '1841612', 'name': 'Yanif Ahmad'}, {'authorId': '2109957', 'name': 'U. √áetintemel'}, {'authorId': '31987589', 'name': 'Mitch Cherniack'}, {'authorId': '2031287', 'name': 'S. Zdonik'}, {'authorId': '1735847', 'name': 'M. Consens'}, {'authorId': '1684032', 'name': 'M. Lalmas'}, {'authorId': '1389957009', 'name': 'R. Baeza-Yates'}, {'authorId': '1691929', 'name': 'D. Hiemstra'}, {'authorId': '1394219580', 'name': 'Peer Kr√∂gerand'}, {'authorId': '3310376', 'name': 'Arthur Zimek'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '1726081', 'name': 'C. Leung'}, {'authorId': '144017417', 'name': 'M. Crochemore'}, {'authorId': '1712103', 'name': 'T. Lecroq'}, {'authorId': '1747737', 'name': 'A. Shoshani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '71397603', 'name': 'Hw Yu'}, {'authorId': '1785673', 'name': 'D. Lomet'}, {'authorId': '1864967', 'name': 'H. Hinterberger'}, {'authorId': '12671514', 'name': 'Ninghui Li'}, {'authorId': '1394219579', 'name': 'Phillip B. Gibbons'}, {'authorId': '1910151', 'name': 'Mouna Kacimi'}, {'authorId': '2053024606', 'name': 'Thomas Neumann'}]"
51ca11cddeec18dc5044dfbb7951110c73a0a397,https://www.semanticscholar.org/paper/51ca11cddeec18dc5044dfbb7951110c73a0a397,Is searching full text more effective than searching abstracts?,,BMC Bioinformatics,2009.0,52,88,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
7ec456521ec3edd05ff47095ac8e8f3e6cf0e269,https://www.semanticscholar.org/paper/7ec456521ec3edd05ff47095ac8e8f3e6cf0e269,Modeling actions of PubMed users with n-gram language models,,Information retrieval (Boston),2009.0,43,28,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2229419193', 'name': 'Ae W John Wilbur'}]"
7eee362f5b46725d0a481749eb4ce10ce36b08f1,https://www.semanticscholar.org/paper/7eee362f5b46725d0a481749eb4ce10ce36b08f1,Secret-Key Encryption,,Encyclopedia of Database Systems,2009.0,0,1,"[{'authorId': '1695840', 'name': 'R. Topor'}, {'authorId': '145527641', 'name': 'K. Salem'}, {'authorId': '1722619', 'name': 'Amarnath Gupta'}, {'authorId': '1806014', 'name': 'K. Goda'}, {'authorId': '143614516', 'name': 'J. Gehrke'}, {'authorId': '1739132', 'name': 'N. Palmer'}, {'authorId': '1473458210', 'name': 'Mohamed Sharaf'}, {'authorId': '1716685', 'name': 'Alexandros Labrinidis'}, {'authorId': '1707518', 'name': 'J. Roddick'}, {'authorId': '2326719', 'name': 'Ariel Fuxman'}, {'authorId': '2116284480', 'name': 'Ren√©e J. Miller'}, {'authorId': '2131764025', 'name': 'Wang-Chiew Tan'}, {'authorId': '1687892', 'name': 'Anastasios Kementsietsidis'}, {'authorId': '1736800318', 'name': 'Philippe Bonnet'}, {'authorId': '1695878', 'name': 'D. Shasha'}, {'authorId': '2044073', 'name': 'R. Peikert'}, {'authorId': '1716911', 'name': 'Bertram Lud√§scher'}, {'authorId': '1900211', 'name': 'S. Bowers'}, {'authorId': '2737817', 'name': 'T. McPhillips'}, {'authorId': '144441900', 'name': 'Harald Naumann'}, {'authorId': '1780707', 'name': 'K. Voruganti'}, {'authorId': '1393591007', 'name': 'J. Domingo-Ferrer'}, {'authorId': '1750995', 'name': 'Ben Carterette'}, {'authorId': '1392254815', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '144658846', 'name': 'M. Arenas'}, {'authorId': '1796253', 'name': 'Y. Manolopoulos'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '1761528', 'name': 'V. Tsotras'}, {'authorId': '1678413', 'name': 'B. Carminati'}, {'authorId': '9461483', 'name': 'Jan Jurjens'}, {'authorId': '1745901', 'name': 'E. Fern√°ndez'}, {'authorId': '1741044', 'name': 'Murat Kantarcioglu'}, {'authorId': '145033630', 'name': 'Jaideep Vaidya'}, {'authorId': '144039860', 'name': 'I. Ray'}, {'authorId': '1741423', 'name': 'A. Vakali'}, {'authorId': '1896793', 'name': 'Cristina Sirangelo'}, {'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '145873061', 'name': 'H. Gupta'}, {'authorId': '145647476', 'name': 'S. Chaudhuri'}, {'authorId': '1751591', 'name': 'G. Weikum'}, {'authorId': '1693022', 'name': 'U. Leser'}, {'authorId': '1694279', 'name': 'D. Embley'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}, {'authorId': '2418440', 'name': 'P. Shvaiko'}, {'authorId': '2228676', 'name': 'Mikalai Yatskevich'}, {'authorId': '143809206', 'name': 'E. Chang'}, {'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1697955', 'name': 'E. Zim√°nyi'}, {'authorId': '2754289', 'name': 'G. Anadiotis'}, {'authorId': '1680354', 'name': 'S. Kotoulas'}, {'authorId': '1784751', 'name': 'R. Siebes'}, {'authorId': '1746617', 'name': 'G. Antoniou'}, {'authorId': '1705358', 'name': 'D. Plexousakis'}, {'authorId': '145148572', 'name': 'J. Bailey'}, {'authorId': '1767012', 'name': 'Fran√ßois Bry'}, {'authorId': '2874808', 'name': 'Tim Furche'}, {'authorId': '1777556', 'name': 'Sebastian Schaffert'}, {'authorId': '152122277', 'name': 'David Martin'}, {'authorId': '1768196', 'name': 'Gregory D. Speegle'}, {'authorId': '1704729', 'name': 'K. Ramamritham'}, {'authorId': '1728643', 'name': 'Panos K. Chrysanthis'}, {'authorId': '1716839', 'name': 'K. Sattler'}, {'authorId': '1735321', 'name': 'S. Bressan'}, {'authorId': '69026873', 'name': 'S. Abiteboul'}, {'authorId': '144823759', 'name': 'Dan Suciu'}, {'authorId': '152945656', 'name': 'G. Dobbie'}, {'authorId': '1798818', 'name': 'T. Ling'}, {'authorId': '40632403', 'name': 'Sugato Basu'}, {'authorId': '1747970', 'name': 'R. Govindan'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '144572233', 'name': 'C. Jensen'}, {'authorId': '2109084789', 'name': 'Jianyong Wang'}, {'authorId': '2295920', 'name': 'K. Vidyasankar'}, {'authorId': '145017583', 'name': 'A. Chan'}, {'authorId': '52411592', 'name': 'Serge Mankovski'}, {'authorId': '1767761', 'name': 'S. Elnikety'}, {'authorId': '144255847', 'name': 'P. Valduriez'}, {'authorId': '2163752', 'name': 'Yannis Velegrakis'}, {'authorId': '144977963', 'name': 'M. Nascimento'}, {'authorId': '143956131', 'name': 'Michael Huggett'}, {'authorId': '1803067', 'name': 'A. Frank'}, {'authorId': '49889222', 'name': 'Yanchun Zhang'}, {'authorId': '2149131224', 'name': 'Guandong Xu'}, {'authorId': '1739732', 'name': 'R. Snodgrass'}, {'authorId': '144406831', 'name': 'A. Fekete'}, {'authorId': '153481005', 'name': 'M. Herzog'}, {'authorId': '2363116', 'name': 'Konstantinos Morfonios'}, {'authorId': '1684197', 'name': 'Y. Ioannidis'}, {'authorId': '1789749', 'name': 'E. Wohlstadter'}, {'authorId': '145228093', 'name': 'M. Matera'}, {'authorId': '2668326', 'name': 'F. Schwagereit'}, {'authorId': '1752093', 'name': 'Steffen Staab'}, {'authorId': '37026706', 'name': 'K. Fraser'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '1756679', 'name': 'M. Mokbel'}, {'authorId': '1709661', 'name': 'W. Aref'}, {'authorId': '144531003', 'name': 'M. Moro'}, {'authorId': '144995341', 'name': 'Markus Schneider'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '3277872', 'name': 'G. Ghinita'}, {'authorId': '2191738', 'name': 'M. Goodchild'}, {'authorId': '145072875', 'name': 'S. Shekhar'}, {'authorId': '35102788', 'name': 'James M. Kang'}, {'authorId': '2047487638', 'name': 'Vijay Gandhi'}, {'authorId': '1718168', 'name': 'N. Mamoulis'}, {'authorId': '66668960', 'name': 'Betsy George'}, {'authorId': '144911319', 'name': 'M. Scholl'}, {'authorId': '1739159', 'name': 'A. Voisard'}, {'authorId': '3068011', 'name': 'R. H. G√ºting'}, {'authorId': '144779196', 'name': 'Yufei Tao'}, {'authorId': '1746338', 'name': 'Dimitris Papadias'}, {'authorId': '1805545', 'name': 'P. Revesz'}, {'authorId': '1715771', 'name': 'G. Kollios'}, {'authorId': '2823398', 'name': 'E. Frentzos'}, {'authorId': '1394219663', 'name': 'Apostolos N. Papadopoulos'}, {'authorId': '1734945', 'name': 'B. Thalheim'}, {'authorId': '3324944', 'name': 'J. Pehcevski'}, {'authorId': '2065256246', 'name': 'Benjamin Piwowarski'}, {'authorId': '9261284', 'name': 'S. Theodoridis'}, {'authorId': '1758377', 'name': 'K. Koutroumbas'}, {'authorId': '1702232', 'name': 'George Karabatis'}, {'authorId': '5525539', 'name': 'D. Chamberlin'}, {'authorId': '1737944', 'name': 'P. Bernstein'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '1719053', 'name': 'J. Gamper'}, {'authorId': '14274793', 'name': 'Ping Li'}, {'authorId': '1755147', 'name': 'K. Subieta'}, {'authorId': '2367532', 'name': 'S. Harizopoulos'}, {'authorId': '3270238', 'name': 'Ethan Zhang'}, {'authorId': '144884116', 'name': 'Yi Zhang'}, {'authorId': '145633895', 'name': 'T. Johnson'}, {'authorId': '145641161', 'name': 'H. Jacobsen'}, {'authorId': '1684961', 'name': 'S. Fienberg'}, {'authorId': '2115757855', 'name': 'Jiashun Jin'}, {'authorId': '1764620', 'name': 'R. Sion'}, {'authorId': '3259579', 'name': 'C. Paice'}, {'authorId': '103694459', 'name': 'Nikos Hardavellas'}, {'authorId': '2754078', 'name': 'Ippokratis Pandis'}, {'authorId': '34066017', 'name': 'E. Rasmussen'}, {'authorId': '2107332919', 'name': 'H. Yoshida'}, {'authorId': '1799376', 'name': 'G. Graefe'}, {'authorId': '2246578', 'name': 'B. Reiner'}, {'authorId': '145105823', 'name': 'K. Hahn'}, {'authorId': '1783767', 'name': 'K. Wada'}, {'authorId': '48250034', 'name': 'T. Risch'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1688834', 'name': 'Lukasz Golab'}, {'authorId': '145345023', 'name': 'M. Stonebraker'}, {'authorId': '2095429', 'name': 'Bibudh Lahiri'}, {'authorId': '1679836', 'name': 'Srikanta Tirthapura'}, {'authorId': '1791896', 'name': 'Erik Vee'}, {'authorId': '1841612', 'name': 'Yanif Ahmad'}, {'authorId': '2109957', 'name': 'U. √áetintemel'}, {'authorId': '31987589', 'name': 'Mitch Cherniack'}, {'authorId': '2031287', 'name': 'S. Zdonik'}, {'authorId': '1735847', 'name': 'M. Consens'}, {'authorId': '1684032', 'name': 'M. Lalmas'}, {'authorId': '1389957009', 'name': 'R. Baeza-Yates'}, {'authorId': '1691929', 'name': 'D. Hiemstra'}, {'authorId': '1394219580', 'name': 'Peer Kr√∂gerand'}, {'authorId': '3310376', 'name': 'Arthur Zimek'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '1726081', 'name': 'C. Leung'}, {'authorId': '144017417', 'name': 'M. Crochemore'}, {'authorId': '1712103', 'name': 'T. Lecroq'}, {'authorId': '1747737', 'name': 'A. Shoshani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1723357', 'name': 'Hwanjo Yu'}, {'authorId': '1785673', 'name': 'D. Lomet'}, {'authorId': '1864967', 'name': 'H. Hinterberger'}, {'authorId': '12671514', 'name': 'Ninghui Li'}, {'authorId': '1394219579', 'name': 'Phillip B. Gibbons'}, {'authorId': '1910151', 'name': 'Mouna Kacimi'}, {'authorId': '2053024606', 'name': 'Thomas Neumann'}]"
ab3be09100f98f14f48c79af8dc3d6030a530d9a,https://www.semanticscholar.org/paper/ab3be09100f98f14f48c79af8dc3d6030a530d9a,Service Choreography,,Encyclopedia of Database Systems,2009.0,23,0,"[{'authorId': '1695840', 'name': 'R. Topor'}, {'authorId': '145527641', 'name': 'K. Salem'}, {'authorId': '1722619', 'name': 'Amarnath Gupta'}, {'authorId': '1806014', 'name': 'K. Goda'}, {'authorId': '143614516', 'name': 'J. Gehrke'}, {'authorId': '1739132', 'name': 'N. Palmer'}, {'authorId': '1473458210', 'name': 'Mohamed Sharaf'}, {'authorId': '1716685', 'name': 'Alexandros Labrinidis'}, {'authorId': '1707518', 'name': 'J. Roddick'}, {'authorId': '2326719', 'name': 'Ariel Fuxman'}, {'authorId': '2116284480', 'name': 'Ren√©e J. Miller'}, {'authorId': '34582619', 'name': 'W. Tan'}, {'authorId': '1687892', 'name': 'Anastasios Kementsietsidis'}, {'authorId': '1736800318', 'name': 'Philippe Bonnet'}, {'authorId': '1695878', 'name': 'D. Shasha'}, {'authorId': '2044073', 'name': 'R. Peikert'}, {'authorId': '1716911', 'name': 'Bertram Lud√§scher'}, {'authorId': '1900211', 'name': 'S. Bowers'}, {'authorId': '2737817', 'name': 'T. McPhillips'}, {'authorId': '144441900', 'name': 'Harald Naumann'}, {'authorId': '1780707', 'name': 'K. Voruganti'}, {'authorId': '1393591007', 'name': 'J. Domingo-Ferrer'}, {'authorId': '1750995', 'name': 'Ben Carterette'}, {'authorId': '1392254815', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '144658846', 'name': 'M. Arenas'}, {'authorId': '1796253', 'name': 'Y. Manolopoulos'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '1761528', 'name': 'V. Tsotras'}, {'authorId': '1678413', 'name': 'B. Carminati'}, {'authorId': '9461483', 'name': 'Jan Jurjens'}, {'authorId': '2111793480', 'name': 'Eduardo B. Fernandez'}, {'authorId': '1741044', 'name': 'Murat Kantarcioglu'}, {'authorId': '145033630', 'name': 'Jaideep Vaidya'}, {'authorId': '144039860', 'name': 'I. Ray'}, {'authorId': '1741423', 'name': 'A. Vakali'}, {'authorId': '1896793', 'name': 'Cristina Sirangelo'}, {'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '145873061', 'name': 'H. Gupta'}, {'authorId': '145647476', 'name': 'S. Chaudhuri'}, {'authorId': '1751591', 'name': 'G. Weikum'}, {'authorId': '1693022', 'name': 'U. Leser'}, {'authorId': '1694279', 'name': 'D. Embley'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}, {'authorId': '2418440', 'name': 'P. Shvaiko'}, {'authorId': '2228676', 'name': 'Mikalai Yatskevich'}, {'authorId': '2064990932', 'name': 'Edward Y. Chang'}, {'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1697955', 'name': 'E. Zim√°nyi'}, {'authorId': '2754289', 'name': 'G. Anadiotis'}, {'authorId': '1680354', 'name': 'S. Kotoulas'}, {'authorId': '1784751', 'name': 'R. Siebes'}, {'authorId': '1746617', 'name': 'G. Antoniou'}, {'authorId': '1705358', 'name': 'D. Plexousakis'}, {'authorId': '145148572', 'name': 'J. Bailey'}, {'authorId': '1767012', 'name': 'Fran√ßois Bry'}, {'authorId': '2874808', 'name': 'Tim Furche'}, {'authorId': '1777556', 'name': 'Sebastian Schaffert'}, {'authorId': '152122277', 'name': 'David Martin'}, {'authorId': '1768196', 'name': 'Gregory D. Speegle'}, {'authorId': '1704729', 'name': 'K. Ramamritham'}, {'authorId': '1728643', 'name': 'Panos K. Chrysanthis'}, {'authorId': '1716839', 'name': 'K. Sattler'}, {'authorId': '1735321', 'name': 'S. Bressan'}, {'authorId': '69026873', 'name': 'S. Abiteboul'}, {'authorId': '144823759', 'name': 'Dan Suciu'}, {'authorId': '152945656', 'name': 'G. Dobbie'}, {'authorId': '1798818', 'name': 'T. Ling'}, {'authorId': '40632403', 'name': 'Sugato Basu'}, {'authorId': '1747970', 'name': 'R. Govindan'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '144572233', 'name': 'C. Jensen'}, {'authorId': '2109084789', 'name': 'Jianyong Wang'}, {'authorId': '2295920', 'name': 'K. Vidyasankar'}, {'authorId': '145017583', 'name': 'A. Chan'}, {'authorId': '52411592', 'name': 'Serge Mankovski'}, {'authorId': '1767761', 'name': 'S. Elnikety'}, {'authorId': '144255847', 'name': 'P. Valduriez'}, {'authorId': '2163752', 'name': 'Yannis Velegrakis'}, {'authorId': '144977963', 'name': 'M. Nascimento'}, {'authorId': '143956131', 'name': 'Michael Huggett'}, {'authorId': '1803067', 'name': 'A. Frank'}, {'authorId': '49889222', 'name': 'Yanchun Zhang'}, {'authorId': '2149131224', 'name': 'Guandong Xu'}, {'authorId': '1739732', 'name': 'R. Snodgrass'}, {'authorId': '144406831', 'name': 'A. Fekete'}, {'authorId': '153481005', 'name': 'M. Herzog'}, {'authorId': '2363116', 'name': 'Konstantinos Morfonios'}, {'authorId': '1684197', 'name': 'Y. Ioannidis'}, {'authorId': '1789749', 'name': 'E. Wohlstadter'}, {'authorId': '145228093', 'name': 'M. Matera'}, {'authorId': '2668326', 'name': 'F. Schwagereit'}, {'authorId': '1752093', 'name': 'Steffen Staab'}, {'authorId': '37026706', 'name': 'K. Fraser'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '1756679', 'name': 'M. Mokbel'}, {'authorId': '1709661', 'name': 'W. Aref'}, {'authorId': '144531003', 'name': 'M. Moro'}, {'authorId': '144995341', 'name': 'Markus Schneider'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '3277872', 'name': 'G. Ghinita'}, {'authorId': '2191738', 'name': 'M. Goodchild'}, {'authorId': '145072875', 'name': 'S. Shekhar'}, {'authorId': '35102788', 'name': 'James M. Kang'}, {'authorId': '2047487638', 'name': 'Vijay Gandhi'}, {'authorId': '1718168', 'name': 'N. Mamoulis'}, {'authorId': '66668960', 'name': 'Betsy George'}, {'authorId': '144911319', 'name': 'M. Scholl'}, {'authorId': '1739159', 'name': 'A. Voisard'}, {'authorId': '3068011', 'name': 'R. H. G√ºting'}, {'authorId': '144779196', 'name': 'Yufei Tao'}, {'authorId': '1746338', 'name': 'Dimitris Papadias'}, {'authorId': '1805545', 'name': 'P. Revesz'}, {'authorId': '1715771', 'name': 'G. Kollios'}, {'authorId': '2823398', 'name': 'E. Frentzos'}, {'authorId': '1394219663', 'name': 'Apostolos N. Papadopoulos'}, {'authorId': '1734945', 'name': 'B. Thalheim'}, {'authorId': '3324944', 'name': 'J. Pehcevski'}, {'authorId': '2065256246', 'name': 'Benjamin Piwowarski'}, {'authorId': '9261284', 'name': 'S. Theodoridis'}, {'authorId': '1758377', 'name': 'K. Koutroumbas'}, {'authorId': '1702232', 'name': 'George Karabatis'}, {'authorId': '5525539', 'name': 'D. Chamberlin'}, {'authorId': '1737944', 'name': 'P. Bernstein'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '1719053', 'name': 'J. Gamper'}, {'authorId': '14274793', 'name': 'Ping Li'}, {'authorId': '1755147', 'name': 'K. Subieta'}, {'authorId': '2367532', 'name': 'S. Harizopoulos'}, {'authorId': '3270238', 'name': 'Ethan Zhang'}, {'authorId': '144884116', 'name': 'Yi Zhang'}, {'authorId': '145633895', 'name': 'T. Johnson'}, {'authorId': '145641161', 'name': 'H. Jacobsen'}, {'authorId': '1684961', 'name': 'S. Fienberg'}, {'authorId': '37718006', 'name': 'Jiashun Jin'}, {'authorId': '1764620', 'name': 'R. Sion'}, {'authorId': '3259579', 'name': 'C. Paice'}, {'authorId': '103694459', 'name': 'Nikos Hardavellas'}, {'authorId': '2754078', 'name': 'Ippokratis Pandis'}, {'authorId': '34066017', 'name': 'E. Rasmussen'}, {'authorId': '2107332919', 'name': 'H. Yoshida'}, {'authorId': '1799376', 'name': 'G. Graefe'}, {'authorId': '2246578', 'name': 'B. Reiner'}, {'authorId': '145105823', 'name': 'K. Hahn'}, {'authorId': '1783767', 'name': 'K. Wada'}, {'authorId': '48250034', 'name': 'T. Risch'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1688834', 'name': 'Lukasz Golab'}, {'authorId': '145345023', 'name': 'M. Stonebraker'}, {'authorId': '2095429', 'name': 'Bibudh Lahiri'}, {'authorId': '1679836', 'name': 'Srikanta Tirthapura'}, {'authorId': '1791896', 'name': 'Erik Vee'}, {'authorId': '1841612', 'name': 'Yanif Ahmad'}, {'authorId': '2109957', 'name': 'U. √áetintemel'}, {'authorId': '31987589', 'name': 'Mitch Cherniack'}, {'authorId': '2031287', 'name': 'S. Zdonik'}, {'authorId': '1735847', 'name': 'M. Consens'}, {'authorId': '1684032', 'name': 'M. Lalmas'}, {'authorId': '1389957009', 'name': 'R. Baeza-Yates'}, {'authorId': '1691929', 'name': 'D. Hiemstra'}, {'authorId': '1394219580', 'name': 'Peer Kr√∂gerand'}, {'authorId': '3310376', 'name': 'Arthur Zimek'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '1726081', 'name': 'C. Leung'}, {'authorId': '144017417', 'name': 'M. Crochemore'}, {'authorId': '1712103', 'name': 'T. Lecroq'}, {'authorId': '1747737', 'name': 'A. Shoshani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '71397603', 'name': 'Hw Yu'}, {'authorId': '1785673', 'name': 'D. Lomet'}, {'authorId': '1864967', 'name': 'H. Hinterberger'}, {'authorId': '1740882', 'name': 'Ninghui Li'}, {'authorId': '1394219579', 'name': 'Phillip B. Gibbons'}, {'authorId': '1910151', 'name': 'Mouna Kacimi'}, {'authorId': '49704872', 'name': 'Thomas Neumann'}]"
d513eb0bf204210b13587b64bafd87b85bfca8fe,https://www.semanticscholar.org/paper/d513eb0bf204210b13587b64bafd87b85bfca8fe,Mining texts for image terms: the CLiMB project,"T CLiMB (Computational Linguistics for Metadata Building) project addresses the existing gap in subject metadata for images, particularly for the domains of art history, architecture, and landscape architecture. Within each of these domains, image collections are increasingly available online yet subject access points for these images remain minimal. In an observational study with six image catalogers, we found that typically 1 ‚Äì 8 subject terms are assigned, and that many legacy records lack subject entries altogether. Studies on end users‚Äô image searching indicate that this level of subject description is often insufficient. In a study of the imagesearching behaviors of faculty and graduate students in American history, Choi and Rasmussen 2003 found that 92% of the 38 participants in their study considered the textual information associated with the images in the Library of Congress‚Äô American Memory Collection to be inadequate. The number of subject descriptors assigned to an image in this collection is comparable to what we found in the exploratory CLiMB studies. Furthermore, these searchers submitted more subject-oriented queries than known-artist and title queries. Similar results demonstrating the importance of subject retrieval have been reported in other studies, including Keister, Collins, and Chen 1994. Under the hypothesis that searchers do not find images they seek partly due to inadequate subject description in metadata fields, the CLiMB project was initiated to address this subject metadata gap by applying automatic and semi-automatic techniques to the identification, extraction, and thesaural linking of subject terms. The CLiMB Toolkit processes text associated with an image through natural language processing (NLP), categorization using machine learning (ML), and disambiguation techniques to identify, filter, and normalize high-quality subject descriptors. Like Pastra et al. 2003 we use NLP techniques and domain-specific ontologies, although our focus is on associated texts such as art historical surveys or curatorial essays rather than captions; unlike generic image search, such as in Google, we analyze beyond keywords and we use text which is specifically and clearly related to an image. For this project, we use the standard Cataloging Cultural Objects (CCO) definition of subject metadata1 as including terms which provide ‚Äúan identification, description, or interpretation of what is depicted in and by a work or image.‚Äù",,2009.0,8,3,"[{'authorId': '1761739', 'name': 'Judith L. Klavans'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1703046', 'name': 'R. Passonneau'}, {'authorId': '1695420', 'name': 'D. Soergel'}]"
d55ea57bc762f4da3b81ddbd779703844c344ccc,https://www.semanticscholar.org/paper/d55ea57bc762f4da3b81ddbd779703844c344ccc,Storage Array,,Encyclopedia of Database Systems,2009.0,0,0,"[{'authorId': '1695840', 'name': 'R. Topor'}, {'authorId': '145527641', 'name': 'K. Salem'}, {'authorId': '1722619', 'name': 'Amarnath Gupta'}, {'authorId': '1806014', 'name': 'K. Goda'}, {'authorId': '143614516', 'name': 'J. Gehrke'}, {'authorId': '1739132', 'name': 'N. Palmer'}, {'authorId': '1473458210', 'name': 'Mohamed Sharaf'}, {'authorId': '1716685', 'name': 'Alexandros Labrinidis'}, {'authorId': '1707518', 'name': 'J. Roddick'}, {'authorId': '2326719', 'name': 'Ariel Fuxman'}, {'authorId': '2116284480', 'name': 'Ren√©e J. Miller'}, {'authorId': '2131764025', 'name': 'Wang-Chiew Tan'}, {'authorId': '1687892', 'name': 'Anastasios Kementsietsidis'}, {'authorId': '1736800318', 'name': 'Philippe Bonnet'}, {'authorId': '1695878', 'name': 'D. Shasha'}, {'authorId': '2044073', 'name': 'R. Peikert'}, {'authorId': '1716911', 'name': 'Bertram Lud√§scher'}, {'authorId': '1900211', 'name': 'S. Bowers'}, {'authorId': '2737817', 'name': 'T. McPhillips'}, {'authorId': '144441900', 'name': 'Harald Naumann'}, {'authorId': '1780707', 'name': 'K. Voruganti'}, {'authorId': '1393591007', 'name': 'J. Domingo-Ferrer'}, {'authorId': '1750995', 'name': 'Ben Carterette'}, {'authorId': '1392254815', 'name': 'Panagiotis G. Ipeirotis'}, {'authorId': '144658846', 'name': 'M. Arenas'}, {'authorId': '1796253', 'name': 'Y. Manolopoulos'}, {'authorId': '1714996', 'name': 'Y. Theodoridis'}, {'authorId': '1761528', 'name': 'V. Tsotras'}, {'authorId': '1678413', 'name': 'B. Carminati'}, {'authorId': '9461483', 'name': 'Jan Jurjens'}, {'authorId': '2111793021', 'name': 'E. Fern√°ndez'}, {'authorId': '1741044', 'name': 'Murat Kantarcioglu'}, {'authorId': '145033630', 'name': 'Jaideep Vaidya'}, {'authorId': '144039860', 'name': 'I. Ray'}, {'authorId': '1741423', 'name': 'A. Vakali'}, {'authorId': '1896793', 'name': 'Cristina Sirangelo'}, {'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '145873061', 'name': 'H. Gupta'}, {'authorId': '145647476', 'name': 'S. Chaudhuri'}, {'authorId': '1751591', 'name': 'G. Weikum'}, {'authorId': '1693022', 'name': 'U. Leser'}, {'authorId': '1694279', 'name': 'D. Embley'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}, {'authorId': '2418440', 'name': 'P. Shvaiko'}, {'authorId': '2228676', 'name': 'Mikalai Yatskevich'}, {'authorId': '33794424', 'name': 'E. Chang'}, {'authorId': '49272925', 'name': 'C. Parent'}, {'authorId': '2346809', 'name': 'S. Spaccapietra'}, {'authorId': '1697955', 'name': 'E. Zim√°nyi'}, {'authorId': '2754289', 'name': 'G. Anadiotis'}, {'authorId': '1680354', 'name': 'S. Kotoulas'}, {'authorId': '1784751', 'name': 'R. Siebes'}, {'authorId': '1746617', 'name': 'G. Antoniou'}, {'authorId': '1705358', 'name': 'D. Plexousakis'}, {'authorId': '145148572', 'name': 'J. Bailey'}, {'authorId': '1767012', 'name': 'Fran√ßois Bry'}, {'authorId': '2874808', 'name': 'Tim Furche'}, {'authorId': '1777556', 'name': 'Sebastian Schaffert'}, {'authorId': '152122277', 'name': 'David Martin'}, {'authorId': '1768196', 'name': 'Gregory D. Speegle'}, {'authorId': '1704729', 'name': 'K. Ramamritham'}, {'authorId': '1728643', 'name': 'Panos K. Chrysanthis'}, {'authorId': '1716839', 'name': 'K. Sattler'}, {'authorId': '1735321', 'name': 'S. Bressan'}, {'authorId': '69026873', 'name': 'S. Abiteboul'}, {'authorId': '144823759', 'name': 'Dan Suciu'}, {'authorId': '152945656', 'name': 'G. Dobbie'}, {'authorId': '1798818', 'name': 'T. Ling'}, {'authorId': '40632403', 'name': 'Sugato Basu'}, {'authorId': '1747970', 'name': 'R. Govindan'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '144572233', 'name': 'C. Jensen'}, {'authorId': '2109084789', 'name': 'Jianyong Wang'}, {'authorId': '2295920', 'name': 'K. Vidyasankar'}, {'authorId': '145017583', 'name': 'A. Chan'}, {'authorId': '52411592', 'name': 'Serge Mankovski'}, {'authorId': '1767761', 'name': 'S. Elnikety'}, {'authorId': '144255847', 'name': 'P. Valduriez'}, {'authorId': '2163752', 'name': 'Yannis Velegrakis'}, {'authorId': '144977963', 'name': 'M. Nascimento'}, {'authorId': '143956131', 'name': 'Michael Huggett'}, {'authorId': '1803067', 'name': 'A. Frank'}, {'authorId': '49889222', 'name': 'Yanchun Zhang'}, {'authorId': '2149131224', 'name': 'Guandong Xu'}, {'authorId': '1739732', 'name': 'R. Snodgrass'}, {'authorId': '144406831', 'name': 'A. Fekete'}, {'authorId': '153481005', 'name': 'M. Herzog'}, {'authorId': '2363116', 'name': 'Konstantinos Morfonios'}, {'authorId': '1684197', 'name': 'Y. Ioannidis'}, {'authorId': '1789749', 'name': 'E. Wohlstadter'}, {'authorId': '145228093', 'name': 'M. Matera'}, {'authorId': '2668326', 'name': 'F. Schwagereit'}, {'authorId': '1752093', 'name': 'Steffen Staab'}, {'authorId': '37026706', 'name': 'K. Fraser'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '1756679', 'name': 'M. Mokbel'}, {'authorId': '1709661', 'name': 'W. Aref'}, {'authorId': '144531003', 'name': 'M. Moro'}, {'authorId': '144995341', 'name': 'Markus Schneider'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '3277872', 'name': 'G. Ghinita'}, {'authorId': '2191738', 'name': 'M. Goodchild'}, {'authorId': '145072875', 'name': 'S. Shekhar'}, {'authorId': '35102788', 'name': 'James M. Kang'}, {'authorId': '2047487638', 'name': 'Vijay Gandhi'}, {'authorId': '1718168', 'name': 'N. Mamoulis'}, {'authorId': '66668960', 'name': 'Betsy George'}, {'authorId': '144911319', 'name': 'M. Scholl'}, {'authorId': '1739159', 'name': 'A. Voisard'}, {'authorId': '3068011', 'name': 'R. H. G√ºting'}, {'authorId': '144779196', 'name': 'Yufei Tao'}, {'authorId': '1746338', 'name': 'Dimitris Papadias'}, {'authorId': '1805545', 'name': 'P. Revesz'}, {'authorId': '1715771', 'name': 'G. Kollios'}, {'authorId': '2823398', 'name': 'E. Frentzos'}, {'authorId': '1394219663', 'name': 'Apostolos N. Papadopoulos'}, {'authorId': '1734945', 'name': 'B. Thalheim'}, {'authorId': '3324944', 'name': 'J. Pehcevski'}, {'authorId': '2065256246', 'name': 'Benjamin Piwowarski'}, {'authorId': '9261284', 'name': 'S. Theodoridis'}, {'authorId': '1758377', 'name': 'K. Koutroumbas'}, {'authorId': '1702232', 'name': 'George Karabatis'}, {'authorId': '5525539', 'name': 'D. Chamberlin'}, {'authorId': '1737944', 'name': 'P. Bernstein'}, {'authorId': '145903871', 'name': 'Michael H. B√∂hlen'}, {'authorId': '1719053', 'name': 'J. Gamper'}, {'authorId': '14274793', 'name': 'Ping Li'}, {'authorId': '1755147', 'name': 'K. Subieta'}, {'authorId': '2367532', 'name': 'S. Harizopoulos'}, {'authorId': '3270238', 'name': 'Ethan Zhang'}, {'authorId': '144884116', 'name': 'Yi Zhang'}, {'authorId': '145633895', 'name': 'T. Johnson'}, {'authorId': '145641161', 'name': 'H. Jacobsen'}, {'authorId': '1684961', 'name': 'S. Fienberg'}, {'authorId': '2115757855', 'name': 'Jiashun Jin'}, {'authorId': '1764620', 'name': 'R. Sion'}, {'authorId': '3259579', 'name': 'C. Paice'}, {'authorId': '103694459', 'name': 'Nikos Hardavellas'}, {'authorId': '2754078', 'name': 'Ippokratis Pandis'}, {'authorId': '34066017', 'name': 'E. Rasmussen'}, {'authorId': '2107332919', 'name': 'H. Yoshida'}, {'authorId': '1799376', 'name': 'G. Graefe'}, {'authorId': '2246578', 'name': 'B. Reiner'}, {'authorId': '145105823', 'name': 'K. Hahn'}, {'authorId': '1783767', 'name': 'K. Wada'}, {'authorId': '48250034', 'name': 'T. Risch'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1688834', 'name': 'Lukasz Golab'}, {'authorId': '145345023', 'name': 'M. Stonebraker'}, {'authorId': '2095429', 'name': 'Bibudh Lahiri'}, {'authorId': '1679836', 'name': 'Srikanta Tirthapura'}, {'authorId': '1791896', 'name': 'Erik Vee'}, {'authorId': '1841612', 'name': 'Yanif Ahmad'}, {'authorId': '2109957', 'name': 'U. √áetintemel'}, {'authorId': '31987589', 'name': 'Mitch Cherniack'}, {'authorId': '2031287', 'name': 'S. Zdonik'}, {'authorId': '1735847', 'name': 'M. Consens'}, {'authorId': '1684032', 'name': 'M. Lalmas'}, {'authorId': '1389957009', 'name': 'R. Baeza-Yates'}, {'authorId': '1691929', 'name': 'D. Hiemstra'}, {'authorId': '1394219580', 'name': 'Peer Kr√∂gerand'}, {'authorId': '3310376', 'name': 'Arthur Zimek'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '1726081', 'name': 'C. Leung'}, {'authorId': '144017417', 'name': 'M. Crochemore'}, {'authorId': '1712103', 'name': 'T. Lecroq'}, {'authorId': '1747737', 'name': 'A. Shoshani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1723357', 'name': 'Hwanjo Yu'}, {'authorId': '1785673', 'name': 'D. Lomet'}, {'authorId': '1864967', 'name': 'H. Hinterberger'}, {'authorId': '12671514', 'name': 'Ninghui Li'}, {'authorId': '1394219579', 'name': 'Phillip B. Gibbons'}, {'authorId': '1910151', 'name': 'Mouna Kacimi'}, {'authorId': '2053024606', 'name': 'Thomas Neumann'}]"
d7af18953e25626b6cbbc8eaf83af1c45f62240e,https://www.semanticscholar.org/paper/d7af18953e25626b6cbbc8eaf83af1c45f62240e,Brute force and indexed approaches to pairwise document similarity comparisons with MapReduce,"This paper explores the problem of computing pairwise similarity on document collections, focusing on the application of ""more like this"" queries in the life sciences domain. Three MapReduce algorithms are introduced: one based on brute force, a second where the problem is treated as large-scale ad hoc retrieval, and a third based on the Cartesian product of postings lists. Each algorithm supports one or more approximations that trade effectiveness for efficiency, the characteristics of which are studied experimentally. Results show that the brute force algorithm is the most efficient of the three when exact similarity is desired. However, the other two algorithms support approximations that yield large efficiency gains without significant loss of effectiveness.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2009.0,16,112,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e108ac671e6c9252907eeb84c41bc35668e0b940,https://www.semanticscholar.org/paper/e108ac671e6c9252907eeb84c41bc35668e0b940,You Are Where You Edit: Locating Wikipedia Contributors through Edit Histories,"
 
 Whether knowingly or otherwise, Wikipedia contributors reveal their interests and expertise through their contribution patterns. An analysis of Wikipedia edit histories shows that it is often possible to associate contributors with relatively small geographic regions, usually corresponding to where they were born or where they presently live. For many contributors, the geographic coordinates of pages they have edited are tightly clustered. Results suggest that a wealth of information about contributors can be gleaned from edit histories. This illustrates the efÔ¨Åcacy of data mining on large, publicly-available datasets and raises potential privacy concerns.
 
",International Conference on Web and Social Media,2009.0,27,57,"[{'authorId': '13883062', 'name': 'Michael D. Lieberman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
e5430d8e3b302f5d55ae8766e5bd316b02539fe0,https://www.semanticscholar.org/paper/e5430d8e3b302f5d55ae8766e5bd316b02539fe0,"Computational linguistics for metadata building (CLiMB): using text mining for the automatic identification, categorization, and disambiguation of subject terms for image metadata",,Multimedia tools and applications,2009.0,41,17,"[{'authorId': '1761739', 'name': 'Judith L. Klavans'}, {'authorId': '145295358', 'name': 'Carolyn Sheffield'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1703046', 'name': 'R. Passonneau'}, {'authorId': '2060625143', 'name': 'Tandeep Sidhu'}, {'authorId': '1695420', 'name': 'D. Soergel'}]"
ea77068c3edc0e0a9e4a5b205105f72845440c21,https://www.semanticscholar.org/paper/ea77068c3edc0e0a9e4a5b205105f72845440c21,The Curse of Zipf and Limits to Parallelization: An Look at the Stragglers Problem in MapReduce,"This paper explores the problem of \stragglers"" in MapReduce: a common phenomenon where a small number of mappers or reducers takes signicantly longer than the others to complete. The eects of these stragglers include unnecessarily long wall-clock running times and sub-optimal cluster utilization. In many cases, this problem cannot simply be attributed to hardware idiosyncrasies, but is rather caused by the Zipan distribution of input or intermediate data. I present a simple theoretical model that shows how such distributions impose a fundamental limit on the amount of parallelism that can be extracted from a large class of algorithms where all occurrences of the same element must be processed together. A case study in parallel ad hoc query evaluation highlights the severity of the stragglers problem. Fortunately, a simple modication of the input data cuts end-to-end running time in half. This example illustrates some of the issues associated with designing ecient MapReduce algorithms for real-world datasets.",LSDS-IR@SIGIR,2009.0,9,99,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
eb142151c77e9fc91933b223d43bb1d3f772310c,https://www.semanticscholar.org/paper/eb142151c77e9fc91933b223d43bb1d3f772310c,"Low-Latency, High-Throughput Access to Static Global Resources within the Hadoop Framework","Hadoop is an open source implementation of Google‚Äôs MapReduce programming model that has recently gained popularity as a practical approach to distributed information processing. This work explores the use of memcached, an open-source distributed in-memory object caching system, to provide low-latency, high-throughput access to static global resources in Hadoop. Such a capability is essential to a large class of MapReduce algorithms that require, for example, querying language model probabilities, accessing model parameters in iterative algorithms, or performing joins across relational datasets. Experimental results on a simple demonstration application illustrate that memcached provides a feasible general-purpose solution for rapidly accessing global key-value pairs from within Hadoop programs. Our proposed architecture exhibits the desirable scaling characteristic of linear increase in throughput with respect to cluster size. To our knowledge, this application of memcached in Hadoop is novel. Although considerable opportunities for increased performance remain, this work enables implementation of algorithms that do not have satisfactory solutions at scale today.",,2009.0,30,24,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2273567067', 'name': 'Anand Bahety'}, {'authorId': '72608280', 'name': 'S. Konda'}, {'authorId': '3056625', 'name': 'Samantha Mahindrakar'}]"
f42e03c4300036fde350277dffceb6f823a08a78,https://www.semanticscholar.org/paper/f42e03c4300036fde350277dffceb6f823a08a78,A cost-effective lexical acquisition process for large-scale thesaurus translation,,Language Resources and Evaluation,2009.0,21,3,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '144002335', 'name': 'Jan Hajic'}, {'authorId': '1758528', 'name': 'Pavel Pecina'}]"
08fd33cb1c8837d374bc4c863a09cc792f6c52f2,https://www.semanticscholar.org/paper/08fd33cb1c8837d374bc4c863a09cc792f6c52f2,Pairwise Document Similarity in Large Collections with MapReduce,"This paper presents a MapReduce algorithm for computing pairwise document similarity in large document collections. MapReduce is an attractive framework because it allows us to decompose the inner products involved in computing document similarity into separate multiplication and summation stages in a way that is well matched to efficient disk access patterns across several machines. On a collection consisting of approximately 900,000 newswire articles, our algorithm exhibits linear growth in running time and space in terms of the number of documents.",Annual Meeting of the Association for Computational Linguistics,2008.0,6,238,"[{'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1737250', 'name': 'Douglas W. Oard'}]"
118df6d656ec6d193fe09ceafb650ae1d35f6ec7,https://www.semanticscholar.org/paper/118df6d656ec6d193fe09ceafb650ae1d35f6ec7,Single-document and multi-document summarization techniques for email threads using sentence compression,,Information Processing & Management,2008.0,28,99,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
46165b257f3c99da4aa57a7bda6d50d3c4b6c7d9,https://www.semanticscholar.org/paper/46165b257f3c99da4aa57a7bda6d50d3c4b6c7d9,Exploring Large-Data Issues in the Curriculum: A Case Study with MapReduce,"This paper describes the design of a pilot research and educational effort at the University of Maryland centered around technologies for tackling Web-scale problems. In the context of a ""cloud computing"" initiative lead by Google and IBM, students and researchers are provided access to a computer cluster running Hadoop, an open-source Java implementation of Google's MapReduce framework. This technology provides an opportunity for students to explore large-data issues in the context of a course organized around teams of graduate and undergraduate students, in which they tackle open research problems in the human language technologies. This design represents one attempt to bridge traditional instruction with real-world, large-data research challenges.",,2008.0,9,19,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
5602a2426fef55c0ad527d3e2dc722fa56ecc5fb,https://www.semanticscholar.org/paper/5602a2426fef55c0ad527d3e2dc722fa56ecc5fb,"Fast, Easy, and Cheap: Construction of Statistical Machine Translation Models with MapReduce","In recent years, the quantity of parallel training data available for statistical machine translation has increased far more rapidly than the performance of individual computers, resulting in a potentially serious impediment to progress. Parallelization of the model-building algorithms that process this data on computer clusters is fraught with challenges such as synchronization, data exchange, and fault tolerance. However, the MapReduce programming paradigm has recently emerged as one solution to these issues: a powerful functional abstraction hides system-level details from the researcher, allowing programs to be transparently distributed across potentially very large clusters of commodity hardware. We describe MapReduce implementations of two algorithms used to estimate the parameters for two word alignment models and one phrase-based translation model, all of which rely on maximum likelihood probability estimates. On a 20-machine cluster, experimental results show that our solutions exhibit good scaling characteristics compared to a hypothetical, optimally-parallelized version of current state-of-the-art single-core tools.",WMT@ACL,2008.0,23,70,"[{'authorId': '1745899', 'name': 'Chris Dyer'}, {'authorId': '50295423', 'name': 'A. Cordova'}, {'authorId': '41175571', 'name': 'A. Mont'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
622502ea30cf6f3995de6c9405f437d51cf2ae05,https://www.semanticscholar.org/paper/622502ea30cf6f3995de6c9405f437d51cf2ae05,Computational linguistics for metadata building: Aggregating text processing technologies for enhanced image access,"We present a system which applies text mining using computational linguistic techniques to automatically extract, categorize, disambiguate and filter metadata for image access. Candidate subject terms are identified through standard approaches; novel semantic categorization using machine learning and disambiguation using both WordNet and a domain specific thesaurus are applied. The resulting metadata can be manually edited by image catalogers or filtered by semi-automatic rules. We describe the implementation of this workbench created for, and evaluated by, image catalogers. We discuss the system's current functionality, developed under the Computational Linguistics for Metadata Building (CLiMB) research project. The CLiMB Toolkit has been tested with several collections, including: Art Images for College Teaching (AICT), ARTStor, the National Gallery of Art (NGA), the Senate Museum, and from collaborative projects such as the Landscape Architecture Image Resource (LAIR) and the field guides of the Vernacular Architecture Group (VAG).",,2008.0,21,3,"[{'authorId': '1761739', 'name': 'Judith L. Klavans'}, {'authorId': '145295358', 'name': 'Carolyn Sheffield'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '40139883', 'name': 'Joan E. Beaudoin'}, {'authorId': '66935157', 'name': 'Laura Jenemann'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2327884', 'name': 'Thomas Lippincott'}, {'authorId': '1703046', 'name': 'R. Passonneau'}, {'authorId': '2060625143', 'name': 'Tandeep Sidhu'}, {'authorId': '1695420', 'name': 'D. Soergel'}, {'authorId': '40599545', 'name': 'T. Yano'}]"
747014d3853f8982fd1ab1d38a78a67e1119202b,https://www.semanticscholar.org/paper/747014d3853f8982fd1ab1d38a78a67e1119202b,Toward automatic facet analysis and need negotiation: Lessons from mediated search,"This work explores the hypothesis that interactions between a trained human search intermediary and an information seeker can inform the design of interactive IR systems. We discuss results from a controlled Wizard-of-Oz case study, set in the context of the TREC 2005 HARD track evaluation, in which a trained intermediary executed an integrated search and interaction strategy based on conceptual facet analysis and informed by need negotiation techniques common in reference interviews. Having a human ‚Äúin the loop‚Äù yielded large improvements over fully automated systems as measured by standard ranked-retrieval metrics, demonstrating the value of mediated search. We present a detailed analysis of the intermediary's actions to gain a deeper understanding of what worked and why. One contribution is a taxonomy of clarification types informed both by empirical results and existing theories in library and information science. We discuss how these findings can guide the development of future systems. Overall, this work illustrates how studying human information-seeking processes can lead to better information retrieval applications.",TOIS,2008.0,98,7,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2143819726', 'name': 'Philip Wu'}, {'authorId': '145055395', 'name': 'E. Abels'}]"
a401ed8bff736645de14d3bdc6ffbf257121da27,https://www.semanticscholar.org/paper/a401ed8bff736645de14d3bdc6ffbf257121da27,Multiple Alternative Sentence Compressions and Word-Pair Antonymy for Automatic Text Summarization and Recognizing Textual Entailment,"Abstract The University of Maryland participatedin three tasks organized by the Text Anal-ysis Conference 2008 (TAC 2008): (1) theupdate task of text summarization; (2) theopinion task of text summarization; and(3) recognizing textual entailment (RTE).At the heart of our summarization sys-tem is Trimmer, which generates multi-ple alternative compressed versions of thesource sentences that act as candidate sen-tences for inclusion in the summary. Forthe Ô¨Årst time, we investigated the use ofautomatically generated antonym pairs forboth text summarization and recognizingtextual entailment. The UMD summariesfor the opinion task were especially effec-tive in providing non-redundant informa-tion (rank 3 out of a total 19 submissions).More coherent summaries resulted whenusing the antonymy feature as comparedto when not using it. On the RTE task,even when using only automatically gen-erated antonyms the system performed aswell as when using a manually compiledlist of antonyms. 1 Introduction",Text Analysis Conference,2008.0,24,4,"[{'authorId': '143880621', 'name': 'Saif M. Mohammad'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '144243233', 'name': 'Melissa Egan'}, {'authorId': '1723404', 'name': 'Nitin Madnani'}, {'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b35ad2823c2a727a9dcef0845f8dec694fe3790d,https://www.semanticscholar.org/paper/b35ad2823c2a727a9dcef0845f8dec694fe3790d,PageRank without Hyperlinks: Reranking with Related Document Networks,"Graph analysis algorithms such as PageRank and HITS have been successful in Web environments because they are able to extract important inter-document relationships from manually-created hyperlinks. We consider the application of these algorithms to related document networks comprised of automatically-generated content-similarity links. Specifically, this work tackles the problem of document retrieval in the biomedical domain, in the context of the PubMed search engine. A series of reranking experiments demonstrate that incorporating evidence extracted from link structure yields significant improvements in terms of standard ranked retrieval metrics. These results extend the applicability of link analysis algorithms to dierent environments.",,2008.0,24,4,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b8738417c367b230afa8dfe6803caf7b6d527e8a,https://www.semanticscholar.org/paper/b8738417c367b230afa8dfe6803caf7b6d527e8a,Navigating information spaces: A case study of related article search in PubMed,,Information Processing & Management,2008.0,34,23,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2041192', 'name': 'Michael DiCuccio'}, {'authorId': '145358444', 'name': 'Vahan Grigoryan'}, {'authorId': '2249345526', 'name': 'W. J. Wilbur'}, {'authorId': '2249345526', 'name': 'W. J. Wilbur'}]"
ce71924b69342ea7bc49143d1cda122d23bb694a,https://www.semanticscholar.org/paper/ce71924b69342ea7bc49143d1cda122d23bb694a,Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Demo Session,"Welcome to the proceedings of the demo session. We received 21 submissions, 9 of which were selected for inclusion in the program after review by at least two members of the program committee.",Annual Meeting of the Association for Computational Linguistics,2008.0,0,2,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d99919e402387b7a9d6a35c370fe0e8f213e318e,https://www.semanticscholar.org/paper/d99919e402387b7a9d6a35c370fe0e8f213e318e,How do users find things with PubMed?: towards automatic utility evaluation with user simulations,"In the context of document retrieval in the biomedical domain, this paper explores the complex relationship between the quality of initial query results and the overall utility of an interactive retrieval system. We demonstrate that a content-similarity browsing tool can compensate for poor retrieval results, and that the relationship between retrieval performance and overall utility is non-linear. Arguments are advanced with user simulations, which characterize the relevance of documents that a user might encounter with different browsing strategies. With broader implications to IR, this work provides a case study of how user simulations can be exploited as a formative tool for automatic utility evaluation. Simulation-based studies provide researchers with an additional evaluation tool to complement interactive and Cranfield-style experiments.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2008.0,30,40,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1689089', 'name': 'Mark D. Smucker'}]"
eec9a50881bbefc3b72064e9e6852558f000cf04,https://www.semanticscholar.org/paper/eec9a50881bbefc3b72064e9e6852558f000cf04,Scalable Language Processing Algorithms for the Masses: A Case Study in Computing Word Co-occurrence Matrices with MapReduce,"This paper explores the challenge of scaling up language processing algorithms to increasingly large datasets. While cluster computing has been available in commercial environments for several years, academic researchers have fallen behind in their ability to work on large datasets. I discuss two barriers contributing to this problem: lack of a suitable programming model for managing concurrency and difficulty in obtaining access to hardware. Hadoop, an open-source implementation of Google's MapReduce framework, provides a compelling solution to both issues. Its simple programming model hides system-level details from the developer, and its ability to run on commodity hardware puts cluster computing within the reach of many academic research groups. This paper illustrates these points with a case study in building word cooccurrence matrices from large corpora. I conclude with an analysis of an alternative computing model based on renting instead of buying computer clusters.",Conference on Empirical Methods in Natural Language Processing,2008.0,19,42,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
06827350da406d8519cd6e5037902687eb7650dc,https://www.semanticscholar.org/paper/06827350da406d8519cd6e5037902687eb7650dc,Overview of the TREC 2006 ciQA task,"Growing interest in interactive systems for answering complex questions lead to the development of the complex, interactive QA (ciQA) task, introduced for the first time at TREC 2006. This paper describes the rationale and design of the ciQA task and the evaluation results. Thirty complex relationship questions based on five question templates were investigated using the AQUAINT collection of newswire text. Interaction forms were the primary vehicle for defining and capturing user-system interactions. In total, six groups participated in the ciQA task and contributed ten different sets of interaction forms. There were two main findings: baseline IR techniques are competitive for complex QA and interaction, at least as defined and implemented in this evaluation, did not appear to improve performance by much.",SIGF,2007.0,11,46,"[{'authorId': '144859929', 'name': 'D. Kelly'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
113ab714f29a4787a8f5e9c18a240b0dc5dbfce5,https://www.semanticscholar.org/paper/113ab714f29a4787a8f5e9c18a240b0dc5dbfce5,An exploration of the principles underlying redundancy-based factoid question answering,"The so-called ‚Äúredundancy-based‚Äù approach to question answering represents a successful strategy for mining answers to factoid questions such as ‚ÄúWho shot Abraham Lincoln?‚Äù from the World Wide Web. Through contrastive and ablation experiments with Aranea, a system that has performed well in several TREC QA evaluations, this work examines the underlying assumptions and principles behind redundancy-based techniques. Specifically, we develop two theses: that stable characteristics of data redundancy allow factoid systems to rely on external ‚Äúblack box‚Äù components, and that despite embodying a data-driven approach, redundancy-based methods encode a substantial amount of knowledge in the form of heuristics. Overall, this work attempts to address the broader question of ‚Äúwhat really matters‚Äù and to provide guidance for future researchers.",TOIS,2007.0,68,90,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
17e6e5fa698cedb5b67ea23568ccd7a8402c1b21,https://www.semanticscholar.org/paper/17e6e5fa698cedb5b67ea23568ccd7a8402c1b21,Presentation schemes for component analysis in IR experiments,"Information retrieval research, at least as conceived by the SIGIR community, is fundamentally experimental in nature. As such, the presentation of results from controlled, reproducible experiments lies at the core of our work. Many reports follow the same general format: authors propose a new retrieval method, whose performance on some well-defined task is compared against a baseline. Authors also report results from alternative configurations, e.g., variations in parameters, turning off (ablation) of different components, etc. The presentation of experimental results forms an integral part of the conferences and journals that comprise the medium in which knowledge is disseminated.",SIGF,2007.0,4,0,"[{'authorId': '1705425', 'name': 'P. Kantor'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
32247f527b8a1003a271650fea3a39c1a42fc4a5,https://www.semanticscholar.org/paper/32247f527b8a1003a271650fea3a39c1a42fc4a5,Recounting the Courts? Applying Automated Content Analysis to Enhance Empirical Legal Research: Automated Content Analysis to Enhance Empirical Legal Research,,,2007.0,27,36,"[{'authorId': '49271726', 'name': 'Michael N. Evans'}, {'authorId': '49885138', 'name': 'Wayne V. McIntosh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1815431', 'name': 'Cynthia L. Cates'}]"
46036e273b212d97289ea0787bf439423bea57c8,https://www.semanticscholar.org/paper/46036e273b212d97289ea0787bf439423bea57c8,Multiple Alternative Sentence Compressions for Automatic Text Summarization,"We perform multi-document summarization by generating compressed versions of source sentences as summary candidates and using weighted features of these candidates to construct summaries. We combine a parse-and-trim approach with a novel technique for producing multiple alternative compressions for source sentences. In addition, we use a novel method for tuning the feature weights that maximizes the change in the ROUGE-2 score ( ROUGE) between the already existing summary state and the new state that results from the addition of the candidate under consideration. We also describe experiments using a new paraphrase-based feature for redundancy checking. Finally, we present the results of our DUC2007 submissions and some ideas for future work.",,2007.0,22,41,"[{'authorId': '1723404', 'name': 'Nitin Madnani'}, {'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '1769060', 'name': 'N. F. Ayan'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
490036a767a347f91ee979f21989d40475a70ab4,https://www.semanticscholar.org/paper/490036a767a347f91ee979f21989d40475a70ab4,Interfaces to Support the Scholarly Exploration of Text Collections,"The analysis of text collections forms the basis of scholarship in many disciplines in the humanities and social sciences. Despite the growing availability of electronic texts, automated techniques have not been effectively exploited to support the activities of scholars in these fields. We present a prototype search interface for exploring text collections that places equal emphasis on content, what the document is about, and metadata, the context that situates a piece of text. As a start, we focus on a selection of briefs and opinions from the U.S. Supreme Court to support legal scholars.",,2007.0,15,1,"[{'authorId': '144324673', 'name': 'G. Apitz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
56c51fdb49a79c2d6d470dc53f9595ec3382e906,https://www.semanticscholar.org/paper/56c51fdb49a79c2d6d470dc53f9595ec3382e906,Exploring the effectiveness of related article search in PubMed,"We describe two complementary studies that explore the effectiveness of related article search in PubMed. The first attempts to characterize the topological properties of document networks that are implicitly defined by this capability. The second focuses on analysis of PubMed query logs to gain an understanding of real user behavior. Combined evidence suggests that related article search is both a useful and often exploited feature in PubMed. Publication Date: July 13, 2007",,2007.0,14,10,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2041192', 'name': 'Michael DiCuccio'}, {'authorId': '145358444', 'name': 'Vahan Grigoryan'}, {'authorId': '1695611', 'name': 'W. Wilbur'}]"
5e7eb9f216b275508533b5a41e42ba818663ef51,https://www.semanticscholar.org/paper/5e7eb9f216b275508533b5a41e42ba818663ef51,Large-Scale Network Analysis to Improve Retrieval in the Biomedical Domain,"1. Problem MEDLINE is the authoritative repository of abstracts from the primary literature in the biomedical domain, maintained by the National Library of Medicine. It currently contains over 17 million records. PubMed [1] is a publicly accessible Web gateway to the system. It is considered one of the most important resources available to researchers in biology, medicine, biochemistry, etc. Currently, PubMed implements a Boolean search algorithm that sorts results in reverse chronological order.",,2007.0,1,0,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
65360c1f3b72c668d5cb576ba4dbc2c679662254,https://www.semanticscholar.org/paper/65360c1f3b72c668d5cb576ba4dbc2c679662254,"Different Structures for Evaluating Answers to Complex Questions: Pyramids Won‚Äôt Topple, and Neither Will Human Assessors","The idea of ‚Äúnugget pyramids‚Äù has recently been introduced as a refinement to the nugget-based methodology used to evaluate answers to complex questions in the TREC QA tracks. This paper examines data from the 2006 evaluation, the first large-scale deployment of the nugget pyramids scheme. We show that this method of combining judgments of nugget importance from multiple assessors increases the stability and discriminative power of the evaluation while introducing only a small additional burden in terms of manual assessment. We also consider an alternative method for combining assessor opinions, which yields a distinction similar to micro- and macro-averaging in the context of classification tasks. While the two approaches differ in terms of underlying assumptions, their results are nevertheless highly correlated.",Annual Meeting of the Association for Computational Linguistics,2007.0,11,24,"[{'authorId': '2122755', 'name': 'H. Dang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6539a745318a5edbdaf821dce5e555bfe7dc8a0d,https://www.semanticscholar.org/paper/6539a745318a5edbdaf821dce5e555bfe7dc8a0d,Is Question Answering Better than Information Retrieval? Towards a Task-Based Evaluation Framework for Question Series,"This paper introduces a novel evaluation framework for question series and employs it to explore the effectiveness of QA and IR systems at addressing users‚Äô information needs. The framework is based on the notion of recall curves, which characterize the amount of relevant information contained within a fixed-length text segment. Although it is widely assumed that QA technology provides more efficient access to information than IR systems, our experiments show that a simple IR baseline is quite competitive. These results help us better understand the role of NLP technology in QA systems and suggest directions for future research.",North American Chapter of the Association for Computational Linguistics,2007.0,17,30,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
6d74077f5a76db02afec352b0532ac5a1284e259,https://www.semanticscholar.org/paper/6d74077f5a76db02afec352b0532ac5a1284e259,Identification of user sessions with hierarchical agglomerative clustering,We introduce a novel approach to identifying Web search user sessions based on the burstiness of users‚Äô activity. Our method is user-centered rather than population-centered or system-centered and can be deployed in situations in which users choose to withhold personal content information. We adopt a hierarchical agglomerative clustering approach with a stopping criterion that is statistically motivated by users‚Äô activities. An evaluation based on extracts from AOL Search‚Ñ¢ logs reveals that our algorithm achieves 98% accuracy in identifying session boundaries compared to human judgments.,ASIS&T Annual Meeting,2007.0,9,44,"[{'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144087841', 'name': 'Abdur Chowdhury'}]"
79ee7e2dd665dee9b36c54303eeccd1d62ea5ef1,https://www.semanticscholar.org/paper/79ee7e2dd665dee9b36c54303eeccd1d62ea5ef1,Syntactic sentence compression in the biomedical domain: facilitating access to related articles,,Information retrieval (Boston),2007.0,50,13,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2229419193', 'name': 'Ae W John Wilbur'}]"
9084e229cdd6b653cb839bcacd75169e4a74328c,https://www.semanticscholar.org/paper/9084e229cdd6b653cb839bcacd75169e4a74328c,Semantic Clustering of Answers to Clinical Questions,"Access to clinical evidence is a critical component of the practice of evidence-based medicine. Advanced retrieval systems can supplement precompiled secondary sources to assist physicians in making sound clinical decisions. This study explores one particular issue related to the design of such retrieval systems: the effective organization of search results to facilitate rapid understanding and synthesis of potentially relevant information. We hypothesize that grouping retrieved MEDLINE citations into semantically-coherent clusters, based on automatically-extracted interventions from the abstract text, represents an effective strategy for presenting results, compared to a traditional ranked list. Experiments with our implemented system appear to support this claim.",American Medical Informatics Association Annual Symposium,2007.0,16,26,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
97a8c36a025af2364a0e3968d2c3c4b44e4ba80c,https://www.semanticscholar.org/paper/97a8c36a025af2364a0e3968d2c3c4b44e4ba80c,"Different Structures for Evaluating Answers to Complex Questions: Pyramids Are Stable, and So Are Human Assessors",,Annual Meeting of the Association for Computational Linguistics,2007.0,0,1,"[{'authorId': '2122755', 'name': 'H. Dang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,https://www.semanticscholar.org/paper/9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0,Answering Clinical Questions with Knowledge-Based and Statistical Techniques,"The combination of recent developments in question-answering research and the availability of unparalleled resources developed specifically for automatic semantic processing of text in the medical domain provides a unique opportunity to explore complex question answering in the domain of clinical medicine. This article presents a system designed to satisfy the information needs of physicians practicing evidence-based medicine. We have developed a series of knowledge extractors, which employ a combination of knowledge-based and statistical techniques, for automatically identifying clinically relevant aspects of MEDLINE abstracts. These extracted elements serve as the input to an algorithm that scores the relevance of citations with respect to structured representations of information needs, in accordance with the principles of evidence-based medicine. Starting with an initial list of citations retrieved by PubMed, our system can bring relevant abstracts into higher ranking positions, and from these abstracts generate responses that directly answer physicians' questions. We describe three separate evaluations: one focused on the accuracy of the knowledge extractors, one conceptualized as a document reranking task, and finally, an evaluation of answers by two physicians. Experiments on a collection of real-world clinical questions show that our approach significantly outperforms the already competitive PubMed baseline.",International Conference on Computational Logic,2007.0,66,290,"[{'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
ac6744082c1b16d80b4e07ac36e35b681b05204d,https://www.semanticscholar.org/paper/ac6744082c1b16d80b4e07ac36e35b681b05204d,User simulations for evaluating answers to question series,,Information Processing & Management,2007.0,22,7,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
b26d6ea5ee7d127a9dfa61e18f8361b83acce1ef,https://www.semanticscholar.org/paper/b26d6ea5ee7d127a9dfa61e18f8361b83acce1ef,TREC 2007 ciQA Task: University of Maryland,"Information needs are complex, evolving, and dicult to express or capture (Taylor, 1962), a fact thatis often overlooked by modern information retrieval systems. TREC, through the HARD track, hasbeen attempting to introduce elements of interaction into large-scale evaluations in order to achievehigh accuracy document retrieval (Allan, 2005). Previous research has shown that well-constructedclari cation questions can yield a better understanding of users‚Äô information needs and thereby improveretrieval performance (Lin et al., 2006).Interactive question answering has recently become a focus of research in the context of complex QA.The topics in the ciQA task are substantially di erent from factoid questions in that the informationneeds are complex, multi-faceted, and often not well de ned or expressed. To investigate the roleof interaction in complex QA, we experimented with two approaches. The rst approach relied onMaximum Marginal Relevance (MMR) and is described in Section 2. The second approach employedthe Multiple Alternative Sentence Compressions (MASC) framework (Zajic, 2007; Madnani et al.,2007), described in Section 3. Section 4 presents ocial results.",Text Retrieval Conference,2007.0,8,2,"[{'authorId': '1723404', 'name': 'Nitin Madnani'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1752326', 'name': 'B. Dorr'}]"
bab524d885d4771f7347820c7c5b5191ba81e5b6,https://www.semanticscholar.org/paper/bab524d885d4771f7347820c7c5b5191ba81e5b6,Deconstructing nuggets: the stability and reliability of complex question answering evaluation,"A methodology based on ""information nuggets"" has recently emerged as the de facto standard by which answers to complex questions are evaluated. After several implementations in the TREC question answering tracks, the community has gained a better understanding of its many characteristics. This paper focuses on one particular aspect of the evaluation: the human assignment of nuggets to answer strings, which serves as the basis of the F-score computation. As a byproduct of the TREC 2006 ciQA task, identical answer strings were independently evaluated twice, which allowed us to assess the consistency of human judgments. Based on these results, we explored simulations of assessor behavior that provide a method to quantify scoring variations. Understanding these variations in turn lets researchers be more confident in their comparisons of systems.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2007.0,17,15,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1492161567', 'name': 'Pengyi Zhang'}]"
c2c3a4542713f9f514cf9c560341cf375ea159d1,https://www.semanticscholar.org/paper/c2c3a4542713f9f514cf9c560341cf375ea159d1,Concept Disambiguation for Improved Subject Access Using Multiple Knowledge Sources,"We address the problem of mining text for relevant image metadata. Our work is situated in the art and architecture domain, where highly specialized technical vocabulary presents challenges for NLP techniques. To extract high quality metadata, the problem of word sense disambiguation must be addressed in order to avoid leading the searcher to the wrong image as a result of ambiguous ‚Äî and thus faulty ‚Äî metadata. In this paper, we present a disambiguation algorithm that attempts to select the correct sense of nouns in textual descriptions of art objects, with respect to a rich domain-specific thesaurus, the Art and Architecture Thesaurus (AAT). We performed a series of intrinsic evaluations using a data set of 600 subject terms extracted from an online National Gallery of Art (NGA) collection of images and text. Our results showed that the use of external knowledge sources shows an improvement over a baseline.",LaTeCH@ACL 2007,2007.0,17,5,"[{'authorId': '2060625143', 'name': 'Tandeep Sidhu'}, {'authorId': '1761739', 'name': 'Judith L. Klavans'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
c9dad53179ead48e5db8f707640970d09b479c4e,https://www.semanticscholar.org/paper/c9dad53179ead48e5db8f707640970d09b479c4e,Multiple alternative sentence compressions as a tool for automatic summarization tasks,"Automatic summarization is the distillation of important information from a source into an abridged form for a particular user or task. Many current systems summarize texts by selecting sentences with important content. The limitation of extraction at the sentence level is that highly relevant sentences may also contain non-relevant and redundant content. 
This thesis presents a novel framework for text summarization that addresses the limitations of sentence-level extraction. Under this framework text summarization is performed by generating Multiple Alternative Sentence Compressions (MASC) as candidate summary components and using weighted features of the candidates to construct summaries from them. Sentence compression is the rewriting of a sentence in a shorter form. This framework provides an environment in which hypotheses about summarization techniques can be tested. 
Three approaches to sentence compression were developed under this framework. The first approach, HMM Hedge, uses the Noisy Channel Model to calculate the most likely compressions of a sentence. The second approach, Trimmer, uses syntactic trimming rules that are linguistically motivated by Headlinese, a form of compressed English associated with newspaper headlines. The third approach, Topiary, is a combination of fluent text with topic terms. 
The MASC framework for automatic text summarization has been applied to the tasks of headline generation and multi-document summarization, and has been used for initial work in summarization of novel genres and applications, including broadcast news, email threads, cross-language, and structured queries. The framework supports combinations of component techniques, fostering collaboration between development teams. 
Three results will be demonstrated under the MASC framework. The first is that an extractive summarization system can produce better summaries by automatically selecting from a pool of compressed sentence candidates than by automatically selecting from unaltered source sentences. The second result is that sentence selectors can construct better summaries from pools of compressed candidates when they make use of larger candidate feature sets. The third result is that for the task of Headline Generation, a combination of topic terms and compressed sentences performs better then either approach alone. Experimental evidence supports all three results.",,2007.0,88,13,"[{'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '3192273', 'name': 'David M. Zajic'}]"
cc7a4028a405ac4a310e872240b07113ffdd4197,https://www.semanticscholar.org/paper/cc7a4028a405ac4a310e872240b07113ffdd4197,PubMed related articles: a probabilistic topic-based model for content similarity,,BMC Bioinformatics,2007.0,28,250,"[{'authorId': '2079910739', 'name': 'Bmc Bioinformatics'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2292377206', 'name': 'John Wilbur'}, {'authorId': '2292357370', 'name': 'Email'}]"
f9ad221c2627e2b0d16edfa05e65656447e00b77,https://www.semanticscholar.org/paper/f9ad221c2627e2b0d16edfa05e65656447e00b77,Multi-candidate reduction: Sentence compression as a tool for document summarization tasks,,Information Processing & Management,2007.0,53,155,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '35442155', 'name': 'R. Schwartz'}]"
041295972bcdf97821ae48bc37070164b790325b,https://www.semanticscholar.org/paper/041295972bcdf97821ae48bc37070164b790325b,Complex question answering based on a semantic domain model of clinical medicine,"Much research in recent years has focused on question answering. Due to significant advances in answering simple fact-seeking questions, research is moving towards resolving complex questions. An approach adopted by many researchers is to decompose a complex question into a series of fact-seeking questions and reuse techniques developed for answering simple questions. This thesis presents an alternative novel approach to domain-specific complex question answering based on consistently applying a semantic domain model to question and document understanding as well as to answer extraction and generation. 
This study uses a semantic domain model of clinical medicine to encode (a)¬†a clinician's information need expressed as a question on the one hand and (b)¬†the meaning of scientific publications on the other to yield a common representation. It is hypothesized that this approach will work well for (1)¬†finding documents that contain answers to clinical questions and (2)¬†extracting these answers from the documents. 
The domain of clinical question answering was selected primarily because of its unparalleled resources that permit providing a proof by construction for this hypothesis. In addition, a working prototype of a clinical question answering system will support research in informed clinical decision making. The proposed methodology is based on the semantic domain model developed within the paradigm of Evidence Based Medicine. Three basic components of this model---the clinical task, a framework for capturing a synopsis of a clinical scenario that generated the question, and strength of evidence presented in an answer---are identified and discussed in detail. 
Algorithms and methods were developed that combine knowledge-based and statistical techniques to extract the basic components of the domain model from abstracts of biomedical articles. These algorithms serve as a foundation for the prototype end-to-end clinical question answering system that was built and evaluated to test the hypotheses. 
Evaluation of the system on test collections developed in the course of this work and based on real life clinical questions demonstrates feasibility of complex question answering and high accuracy information retrieval using a semantic domain model.",,2006.0,159,16,"[{'authorId': '1737250', 'name': 'Douglas W. Oard'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
1e7b4b0770567913f7c6c048af876a6589334108,https://www.semanticscholar.org/paper/1e7b4b0770567913f7c6c048af876a6589334108,Evaluation of PICO as a Knowledge Representation for Clinical Questions,"The paradigm of evidence-based medicine (EBM) recommends that physicians formulate clinical questions in terms of the problem/population, intervention, comparison, and outcome. Together, these elements comprise a PICO frame. Although this framework was developed to facilitate the formulation of clinical queries, the ability of PICO structures to represent physicians' information needs has not been empirically investigated. This paper evaluates the adequacy and suitability of PICO frames as a knowledge representation by analyzing 59 real-world primary-care clinical questions. We discovered that only two questions in our corpus contain all four PICO elements, and that 37% of questions contain both intervention and outcome. Our study reveals prevalent structural patterns for the four types of clinical questions: therapy, diagnosis, prognosis, and etiology. We found that the PICO framework is primarily centered on therapy questions, and is less suitable for representing other types of clinical information needs. Challenges in mapping natural language questions into PICO structures are also discussed. Although we point out limitations of the PICO framework, our work as a whole reaffirms its value as a tool to assist physicians practicing EBM.",American Medical Informatics Association Annual Symposium,2006.0,18,715,"[{'authorId': '49444819', 'name': 'Xiaoli Huang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
216f2cbdcc4c06943f38f8d1bde99a5746171b62,https://www.semanticscholar.org/paper/216f2cbdcc4c06943f38f8d1bde99a5746171b62,"Answer Extraction, Semantic Clustering, and Extractive Summarization for Clinical Question Answering","This paper presents a hybrid approach to question answering in the clinical domain that combines techniques from summarization and information retrieval. We tackle a frequently-occurring class of questions that takes the form ""What is the best drug treatment for X?"" Starting from an initial set of MEDLINE citations, our system first identifies the drugs under study. Abstracts are then clustered using semantic classes from the UMLS ontology. Finally, a short extractive summary is generated for each abstract to populate the clusters. Two evaluations---a manual one focused on short answers and an automatic one focused on the supporting abstract---demonstrate that our system compares favorably to PubMed, the search system most widely used by physicians today.",Annual Meeting of the Association for Computational Linguistics,2006.0,24,108,"[{'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2d21ac595e9615d9dc01420e0357be0f31c653a5,https://www.semanticscholar.org/paper/2d21ac595e9615d9dc01420e0357be0f31c653a5,"The digital sublime: Myth, power, and cyberspace",,J. Assoc. Inf. Sci. Technol.,2006.0,16,240,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '6104312', 'name': 'Boris Katz'}]"
33f33197434dbcb6dbe5b2f5e27d646262fcd19d,https://www.semanticscholar.org/paper/33f33197434dbcb6dbe5b2f5e27d646262fcd19d,Generative Content Models for Structural Analysis of Medical Abstracts,"The ability to accurately model the content structure of text is important for many natural language processing applications. This paper describes experiments with generative models for analyzing the discourse structure of medical abstracts, which generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"". We demonstrate that Hidden Markov Models are capable of accurately capturing the structure of such texts, and can achieve classification accuracy comparable to that of discriminative techniques. In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions. Our work makes two contributions: at the application level, we report good performance on an interesting task in an important domain; more generally, our results contribute to an ongoing discussion regarding the tradeoffs between generative and discriminative techniques.",BioNLP@NAACL-HLT,2006.0,30,88,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2841922', 'name': 'Damianos G. Karakos'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '2803071', 'name': 'S. Khudanpur'}]"
345a098321cff1a90befe47717e033f010de2096,https://www.semanticscholar.org/paper/345a098321cff1a90befe47717e033f010de2096,Building a reusable test collection for question answering,"In contrast to traditional information retrieval systems, which return ranked lists of documents that users must manually browse through, a question answering system attempts to directly answer nat...",J. Assoc. Inf. Sci. Technol.,2006.0,46,48,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '6104312', 'name': 'Boris Katz'}]"
37e555bdd8c0dd94bf79c7977ec82b8e22cd257f,https://www.semanticscholar.org/paper/37e555bdd8c0dd94bf79c7977ec82b8e22cd257f,Extracting Answers from the Web Using Data Annotation and Knowledge Mining Techniques,"Abstract : Aranea is a question answering system that extracts answers from the World Wide Web using knowledge annotation and knowledge mining techniques. Knowledge annotation, which utilizes semistructured database techniques, is effective for answering large classes of commonly occurring questions. Knowledge mining, which utilizes statistical techniques, can leverage the massive amounts of data available on the Web to overcome many natural language processing challenges. Aranea integrates these two different paradigms of question answering into a single framework. For the TREC evaluation, we also explored the problem of answer projection, or finding supporting documents for our Web-derived answers from the AQUAINT corpus.",Text Retrieval Conference,2006.0,18,28,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}, {'authorId': '2913681', 'name': 'Stefanie Tellex'}]"
3bbace0cf844abc6cdc5f4fd3ec53dcd54a83eb7,https://www.semanticscholar.org/paper/3bbace0cf844abc6cdc5f4fd3ec53dcd54a83eb7,Leveraging Recurrent Phrase Structure in Large-scale Ontology Translation,"This paper presents a process for leveraging structural relationships and reusable phrases when translating large-scale ontologies. Digital libraries are becoming more and more prevalent. An important step in providing universal access to such material is to provide multi-lingual access to the underlying principles of organization via ontologies, thesauri, and controlled vocabularies. Machine translation of these resources requires high accuracy and a deep vocabulary. Human input is often required, but full manual translation can be slow and expensive. We report on a cost-effective approach to ontology translation. We describe our technique of prioritization, our process of collecting aligned translations and generating a new lexicon, and the resulting improvement to translation system output. Our preliminary evaluation indicates that this technique provides significant cost savings for human-assisted translation. The process we developed can be applied to ontologies in other domains and is easily incorporated into other translation systems.",European Association for Machine Translation Conferences/Workshops,2006.0,25,4,"[{'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144002335', 'name': 'Jan Hajic'}, {'authorId': '1758528', 'name': 'Pavel Pecina'}]"
3e91aa3b57c81b3c64e103c913daaab5fb98f389,https://www.semanticscholar.org/paper/3e91aa3b57c81b3c64e103c913daaab5fb98f389,Action modeling: language models that predict query behavior,"We present a novel language modeling approach to capturing the query reformulation behavior of Web search users. Based on a framework that categorizes eight different types of ""user moves"" (adding/removing query terms, etc.), we treat search sessions as sequence data and build n-gram language models to capture user behavior. We evaluated our models in a prediction task. The results suggest that useful patterns of activity can be extracted from user histories. Furthermore, by examining prediction performance under different order n-gram models, we gained insight into the amount of history/context that is associated with different types of user actions. Our work serves as the basis for more refined user models.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2006.0,4,1,"[{'authorId': '2288402737', 'name': 'G. Craig Murray'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144087841', 'name': 'Abdur Chowdhury'}]"
739e94bae04cdd483684ec5b93cc20f393599baf,https://www.semanticscholar.org/paper/739e94bae04cdd483684ec5b93cc20f393599baf,Will Pyramids Built of Nuggets Topple Over?,"The present methodology for evaluating complex questions at TREC analyzes answers in terms of facts called ""nuggets"". The official F-score metric represents the harmonic mean between recall and precision at the nugget level. There is an implicit assumption that some facts are more important than others, which is implemented in a binary split between ""vital"" and ""okay"" nuggets. This distinction holds important implications for the TREC scoring model---essentially, systems only receive credit for retrieving vital nuggets---and is a source of evaluation instability. The upshot is that for many questions in the TREC testsets, the median score across all submitted runs is zero. In this work, we introduce a scoring model based on judgments from multiple assessors that captures a more refined notion of nugget importance. We demonstrate on TREC 2003, 2004, and 2005 data that our ""nugget pyramids"" address many shortcomings of the present methodology, while introducing only minimal additional overhead on the evaluation flow.",North American Chapter of the Association for Computational Linguistics,2006.0,12,78,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
800d5005e834aadf5477b5e7866a2a35f0795fbb,https://www.semanticscholar.org/paper/800d5005e834aadf5477b5e7866a2a35f0795fbb,Leveraging Reusability: Cost-Effective Lexical Acquisition for Large-Scale Ontology Translation,"Thesauri and ontologies provide important value in facilitating access to digital archives by representing underlying principles of organization. Translation of such resources into multiple languages is an important component for providing multilingual access. However, the specificity of vocabulary terms in most ontologies precludes fully-automated machine translation using general-domain lexical resources. In this paper, we present an efficient process for leveraging human translations when constructing domain-specific lexical resources. We evaluate the effectiveness of this process by producing a probabilistic phrase dictionary and translating a thesaurus of 56,000 concepts used to catalogue a large archive of oral histories. Our experiments demonstrate a cost-effective technique for accurate machine translation of large ontologies.",Annual Meeting of the Association for Computational Linguistics,2006.0,16,9,"[{'authorId': '144705242', 'name': 'G. C. Murray'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144002335', 'name': 'Jan Hajic'}, {'authorId': '1758528', 'name': 'Pavel Pecina'}]"
818c43db550de599e166ad17c300d35621343f40,https://www.semanticscholar.org/paper/818c43db550de599e166ad17c300d35621343f40,Situated Question Answering in the Clinical Domain: Selecting the Best Drug Treatment for Diseases,The combination of a shanked tool and a holder therefor the holder being formed with a socket for receiving the tool shank and with a resilient latch biased in a direction transverse to the operating direction for engaging in a recess in the side of the tool shank.,Proceedings of the Workshop on Task-Focused Summarization and Question Answering - SumQA '06,2006.0,20,9,"[{'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
835b7d6cc54fcd8393a266b0ed64f65a1f4d5414,https://www.semanticscholar.org/paper/835b7d6cc54fcd8393a266b0ed64f65a1f4d5414,Methods for automatically evaluating answers to complex questions,,Information retrieval (Boston),2006.0,25,43,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
901e31635918310569ec0bddf23755154a6df829,https://www.semanticscholar.org/paper/901e31635918310569ec0bddf23755154a6df829,Overview of the TREC 2006 Question Answering Track 99,"The TREC 2006 question answering (QA) track contained two tasks: the main task and the complex, interactive question answering (ciQA) task. As in 2005, the main task consisted of series of factoid, list, and ‚ÄúOther‚Äù questions organized around a set of targets; in contrast to previous years, the evaluation of factoid and list responses distinguished between answers that were globally correct (with respect to the document collection), and those that were only locally correct (with respect to the supporting document). The ciQA task provided a framework for participants to investigate interaction in the context of complex information needs, and was a blend of the TREC 2005 QA relationship task and the TREC 2005 HARD track. Multiple assessors were used to judge the importance of information nuggets used to evaluate the responses to ciQA and ‚ÄúOther‚Äù questions, resulting in an evaluation that is more stable and discriminative than one that uses only a single assessor to judge nugget importance.",Text Retrieval Conference,2006.0,13,115,"[{'authorId': '2122755', 'name': 'H. Dang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144859929', 'name': 'D. Kelly'}]"
9ecee99849a6b925f1a1dac454e87e600821565e,https://www.semanticscholar.org/paper/9ecee99849a6b925f1a1dac454e87e600821565e,The Role of Information Retrieval in Answering Complex Questions,"This paper explores the role of information retrieval in answering ""relationship"" questions, a new class complex information needs formally introduced in TREC 2005. Since information retrieval is often an integral component of many question answering strategies, it is important to understand the impact of different term-based techniques. Within a framework of sentence retrieval, we examine three factors that contribute to question answering performance: the use of different retrieval engines, relevance (both at the document and sentence level), and redundancy. Results point out the limitations of purely term-based methods to this challenging task. Nevertheless, IR-based techniques provide a strong baseline on top of which more sophisticated language processing techniques can be deployed.",Annual Meeting of the Association for Computational Linguistics,2006.0,24,13,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a4e0babd310f0256db006a9d012c93b44af310e5,https://www.semanticscholar.org/paper/a4e0babd310f0256db006a9d012c93b44af310e5,Sentence Compression as a Component of a Multi-Document Summarization System,"We applied a single-document sentencetrimming approach (Trimmer) to the problem of multi-document summarization. Trimmer was designed with the intention of compressing a lead sentence into a space consisting of tens of characters. In our Multi-Document Trimmer (MDT), we use Trimmer to generate multiple trimmed candidates for each sentence. Sentence selection is used to determine which trimmed candidates provide the best combination of topic coverage and brevity. We demonstrate that we were able to port Trimmer easily to this new problem. We also show that MDT generally ranked higher for recall than for precision, suggesting that MDT is currently more successful at finding relevant content than it is at weeding out irrelevant content. Finally, we present an error analysis that shows that, while sentence compressions is making space for additional sentences, more work is needed in the area of generating and selecting the right candidates.",,2006.0,12,34,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '152901373', 'name': 'R. Schwartz'}]"
a6aaec3c36297ac054a3e14f1fac1cae9766c10e,https://www.semanticscholar.org/paper/a6aaec3c36297ac054a3e14f1fac1cae9766c10e,Exploring the limits of single-iteration clarification dialogs,"Single-iteration clarification dialogs, as implemented in the TREC HARD track, represent an attempt to introduce interaction into ad hoc retrieval, while preserving the many benefits of large-scale evaluations. Although previous experiments have not conclusively demonstrated performance gains resulting from such interactions, it is unclear whether these findings speak to the nature of clarification dialogs, or simply the limitations of current systems. To probe the limits of such interactions, we employed a human intermediary to formulate clarification questions and exploit user responses. In addition to establishing a plausible upper bound on performance, we were also able to induce an ""ontology of clarifications"" to characterize human behavior. This ontology, in turn, serves as the input to a regression model that attempts to determine which types of clarification questions are most helpful. Our work can serve to inform the design of interactive systems that initiate user dialogs.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2006.0,29,6,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2143819726', 'name': 'Philip Wu'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '145055395', 'name': 'E. Abels'}]"
a97f3440ec7b6ab5d8faad61c339f21b404e3e24,https://www.semanticscholar.org/paper/a97f3440ec7b6ab5d8faad61c339f21b404e3e24,The role of knowledge in conceptual retrieval: a study in the domain of clinical medicine,"Despite its intuitive appeal, the hypothesis that retrieval at the level of ""concepts"" should outperform purely term-based approaches remains unverified empirically. In addition, the use of ""knowledge"" has not consistently resulted in performance gains. After identifying possible reasons for previous negative results, we present a novel framework for ""conceptual retrieval"" that articulates the types of knowledge that are important for information seeking. We instantiate this general framework in the domain of clinical medicine based on the principles of evidence-based medicine (EBM). Experiments show that an EBM-based scoring algorithm dramatically outperforms a state-of-the-art baseline that employs only term statistics. Ablation studies further yield a better understanding of the performance contributions of different components. Finally, we discuss how other domains can benefit from knowledge-based approaches.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2006.0,41,71,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
b4f92471f946e043edd0d5a416122fe447dcc632,https://www.semanticscholar.org/paper/b4f92471f946e043edd0d5a416122fe447dcc632,"TREC 2006 at Maryland: Blog, Enterprise, Legal and QA Tracks","Abstract : In TREC 2006, teams from the University of Maryland participated in the Blog track, the Expert Search task of the Enterprise track, the Complex Interactive Question Answering task of the Question Answering track, and the Legal track. This paper reports our results.",Text Retrieval Conference,2006.0,25,27,"[{'authorId': '1737250', 'name': 'Douglas W. Oard'}, {'authorId': '143928505', 'name': 'T. Elsayed'}, {'authorId': '2110215030', 'name': 'Jianqiang Wang'}, {'authorId': '2136373', 'name': 'Yejun Wu'}, {'authorId': '1492161567', 'name': 'Pengyi Zhang'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1695420', 'name': 'D. Soergel'}]"
cbb1972c210a88bff6a655ea74370588be86fbfd,https://www.semanticscholar.org/paper/cbb1972c210a88bff6a655ea74370588be86fbfd,Sentence Trimming and Selection: Mixing and Matching,"We describe how components from two distinct multi-document summarization systems were combined. Twenty four possible combinations of components were considered. We observed some contrasts between conservative and aggressive sentence compression (i.e., trimming) in the context of multidocument summarization.",,2006.0,9,4,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '11579914', 'name': 'John M. Conroy'}, {'authorId': '117489779', 'name': 'D. O‚ÄôLeary'}, {'authorId': '2468970', 'name': 'J. Schlesinger'}]"
cc1245197663aa94556f7ebd2c12eeea99d20495,https://www.semanticscholar.org/paper/cc1245197663aa94556f7ebd2c12eeea99d20495,Recounting the Courts? Applying Automated Content Analysis to Enhance Empirical Legal Research,"Political scientists in general and public law specialists in particular have only recently begun to exploit text classification using machine learning techniques to enable the reliable and detailed content analysis of political/legal documents on a large scale. This paper provides an overview and assessment of this methodology. We describe the basics of text classification, suggest applications of this technique to enhance empirical legal research (and political science more broadly), and report results of experiments designed to test the strengths and weaknesses of alternative text classification models for classifying the positions and interpreting the content of briefs submitted to the U.S. Supreme Court. We find that the Wordscores method (introduced by Laver, Benoit, et. al. 2003), and various models using a Naive Bayes classifier, perform well at accurately classifying the ideological direction of amicus curiae briefs submitted in the Bakke (1978) and Bollinger (2003) affirmative action cases. We also find that automated feature selection techniques can enable the detection of disparate issue conceptualizations by opposing sides in a single case, and facilitate analysis of relative linguistic ""reliance"" and ""dominance"" over time. We conclude by discussing the implications of our results and pointing to areas where technical and infrastructural improvement are most needed.",,2006.0,43,74,"[{'authorId': '2116438020', 'name': 'Michael C. Evans'}, {'authorId': '49885138', 'name': 'Wayne V. McIntosh'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1815431', 'name': 'Cynthia L. Cates'}]"
12937ad4a222a9e48099f405f60487e0003e8411,https://www.semanticscholar.org/paper/12937ad4a222a9e48099f405f60487e0003e8411,Assessing the term independence assumption in blind relevance feedback,"When applying blind relevance feedback for ad hoc document retrieval, is it possible to identify, a priori, the set of query terms that will most improve retrieval performance? Can this complex problem be reduced into the simpler one of making independent decisions about the performance effects of each query term? Our experiments suggest that, for the selection of terms for blind relevance feedback, the term independence assumption may be empirically justified.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2005.0,4,11,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2288402737', 'name': 'G. Craig Murray'}]"
2af0473e63ef0a9a77795c449620b90bb21730e2,https://www.semanticscholar.org/paper/2af0473e63ef0a9a77795c449620b90bb21730e2,Evaluating Summaries and Answers: Two Sides of the Same Coin?,"This paper discusses the convergence between question answering and multidocument summarization, pointing out implications and opportunities for knowledge transfer in both directions. As a case study in one direction, we discuss the recent development of an automatic method for evaluating definition questions based on n-gram overlap, a commonlyused technique in summarization evaluation. In the other direction, the move towards topic-oriented summaries requires an understanding of relevance and topicality, issues which have received attention in the question answering literature. It is our opinion that question answering and multi-document summarization represent two complementary approaches to the same problem of satisfying complex user information needs. Although this points to many exciting opportunities for systembuilding, here we primarily focus on implications for system evaluation.",IEEvaluation@ACL,2005.0,29,14,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
53da1cf13a867d7dcc57e680afc6e0262a5a33e7,https://www.semanticscholar.org/paper/53da1cf13a867d7dcc57e680afc6e0262a5a33e7,Are Degree Achievements Really Achievements ?,"This paper, which builds of the work of Hay, Kennedy, and Levin (1999), examines the puzzling aspectual behavior of so-called degree achievements. Drawing evidence from Mandarin Chinese, I argue that degree achievements without difference values denote punctual events, i.e., they are true achievements. I present an analysis that is consistent with facts from both English and Mandarin; to explain the complex aspectual behavior of degree achievements, my account appeals to coercion operators that are licensed to resolve type clashes. It differs from previous theories in that complex aspectual behavior arises from interactions between predicates and other sentential elements, and not from properties inherent to the predicates themselves. Cross-linguistic differences can be attributed to the availability of these operators, which is a parameter of Universal Grammar.",,2005.0,16,4,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
570bfcb94270e1d565450fb6029a9f6e7c8749a2,https://www.semanticscholar.org/paper/570bfcb94270e1d565450fb6029a9f6e7c8749a2,Automatically Evaluating Answers to Definition Questions,"Following recent developments in the automatic evaluation of machine translation and document summarization, we present a similar approach, implemented in a measure called Pourpre, for automatically evaluating answers to definition questions. Until now, the only way to assess the correctness of answers to such questions involves manual determination of whether an information nugget appears in a system's response. The lack of automatic methods for scoring system output is an impediment to progress in the field, which we address with this work. Experiments with the TREC 2003 and TREC 2004 QA tracks indicate that rankings produced by our metric correlate highly with official rankings, and that Pourpre outperforms direct application of existing metrics.",Human Language Technology - The Baltic Perspectiv,2005.0,14,70,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
58e3df962aeea5ece0857ab6e37870857a54ee07,https://www.semanticscholar.org/paper/58e3df962aeea5ece0857ab6e37870857a54ee07,Knowledge Extraction for Clinical Question Answering: Preliminary Results,"The combination of recent developments in question answering research and the unparalleled resources developed speciÔ¨Åcally for automatic semantic processing of text in the medical domain provides a unique opportunity to explore complex question answering in the clinical domain. In this paper, we attempt to operationalize major aspects of evidence-based medicine in the form of knowledge extractors that serve as the fundamental building blocks of a clinical question answering sys-tem. Our evaluations demonstrate that domain-speciÔ¨Åc knowledge can be effectively leveraged to extract PICO frame elements from MEDLINE abstracts. Clinical information systems in support of physicians‚Äô decision-making process have the potential to improve the quality of patient care in real-world settings.",,2005.0,35,54,"[{'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
726645f2e712ead485b2d37cc1010e40aef1ad25,https://www.semanticscholar.org/paper/726645f2e712ead485b2d37cc1010e40aef1ad25,Fusion of Knowledge-Intensive and Statistical Approaches for Retrieving and Annotating Textual Genomics Documents,"This paper represents a continuation of research into the retrieval and annotation of textual genomics documents (both MEDLINE ¬Æ citations and full text articles) for the purpose of satisfying biologists‚Äô real information needs. The overall approach taken here for both the ad hoc retrieval and categorization tasks within the TREC genomics track in 2005 was one combining the results of several NLP, statistical and ML methods, using a fusion method for ad hoc retrieval and ensemble methods for categorization. The results show that fusion approaches can improve the final outcome for the ad hoc and the categorization tasks, but that care must be taken in order to take advantage of the strengths of the constituent methods.",Text Retrieval Conference,2005.0,28,45,"[{'authorId': '1703414', 'name': 'A. Aronson'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '2682561', 'name': 'Susanne M. Humphrey'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724346', 'name': 'Patrick Ruch'}, {'authorId': '144881417', 'name': 'M. Ruiz'}, {'authorId': '2892414', 'name': 'Lawrence H. Smith'}, {'authorId': '39723089', 'name': 'L. Tanabe'}, {'authorId': '1695611', 'name': 'W. Wilbur'}, {'authorId': '50793079', 'name': 'Hongfang Liu'}]"
8da025c8b95936ca882ad154daa6c00f379a9d84,https://www.semanticscholar.org/paper/8da025c8b95936ca882ad154daa6c00f379a9d84,Recounting the Courts? Toward A Text-Centered Computational Approach to Understanding the Dynamics of the Judicial System,"This paper explores the potential uses of computational linguistics techniques for analyzing Supreme Court briefs and opinions. To do so, we focused on advocacy documents associated with the two recent University of Michigan affirmative action cases (Gratz v. Bollinger and Grutter v. Bollinger). The cases attracted more than one hundred amicus briefs, which provide a rich textual database for such an exploratory study. The goal of our preliminary work is to model the linguistic contents of the arguments presented by the petitioners and respondents, as captured in the original litigants‚Äô briefs and the amici briefs submitted in these two cases. In particular, we are interested in the types of words and phrases used by both sides in order to forward their arguments. These linguistic cues may provide us with insight into the policy and ideological inclinations of the parties involved. We utilize and compare two analytical methods, an adaptation of the Wordscoring technique first developed by Laver, Benoit, and Garry (2003) and a Naive Bayes‚Äô classifier to identify commonalities in documents and group them accordingly. We find the methods to be quite competent at detecting amici brief positions, clustering petitioner and respondent briefs into well-spaced separate normal distributions. Additionally, we find it quite useful as an aid to qualitative content analysis. We identify distinctive rhetorical styles utilized by the respondents and petitioners and suggest how this type of analysis can improve our understanding of how and why different groups, ideologies, actors, interests, and the like, conceptualize issues.",,2005.0,94,5,"[{'authorId': '49271726', 'name': 'Michael N. Evans'}, {'authorId': '49885138', 'name': 'Wayne V. McIntosh'}, {'authorId': '1815431', 'name': 'Cynthia L. Cates'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9851ad4065413ef541adc913c52d7023bec5bf7c,https://www.semanticscholar.org/paper/9851ad4065413ef541adc913c52d7023bec5bf7c,Evaluation of resources for question answering evaluation,"Controlled and reproducible laboratory experiments, enabled by reusable test collections, represent a well-established methodology in modern information retrieval research. In order to confidently draw conclusions about the performance of different retrieval methods using test collections, their reliability and trustworthiness must first be established. Although such studies have been performed for ad hoc test collections, currently available resources for evaluating question answering systems have not been similarly analyzed. This study evaluates the quality of answer patterns and lists of relevant documents currently employed in automatic question answering evaluation, and concludes that they are not suitable for post-hoc experimentation. These resources, created from runs submitted by TREC QA track participants, do not produce fair and reliable assessments of systems that did not participate in the original evaluations. Potential solutions for addressing this evaluation gap and their shortcomings are discussed.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2005.0,20,32,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
a5c4afe44521893b5454aaee235be4363813acfd,https://www.semanticscholar.org/paper/a5c4afe44521893b5454aaee235be4363813acfd,A Paraphrase-Based Approach to Machine Translation Evaluation,"We propose a novel approach to automatic machine translation evaluation based on paraphrase identification. The quality of machine-generated output can be viewed as the extent to which the conveyed meaning matches the semantics of reference translations, independent of lexical and syntactic divergences. This idea is implemented in linear regression models that attempt to capture human judgments of adequacy and fluency, based on features that have previously been shown to be effective for paraphrase identification. We evaluated our model using the output of three different MT systems from the 2004 NIST Arabic-to-English MT evaluation. Results show that models employing paraphrase-based features correlate better with human judgments than models based purely on existing automatic MT metrics.",,2005.0,17,49,"[{'authorId': '1409051954', 'name': 'Grazia Russo-Lassner'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1680292', 'name': 'P. Resnik'}]"
c995ebe1ea5f7035bf6303c36f67d4c21ebb85bf,https://www.semanticscholar.org/paper/c995ebe1ea5f7035bf6303c36f67d4c21ebb85bf,A Sentence-Trimming Approach to Multi-Document Summarization,"We implemented an initial application of a sentence-trimming approach (Trimmer) to the problem of multi-document summarization in the MSE2005 and DUC2005 tasks. Sentence trimming was incorporated into a feature-based summarization system, called MultiDocument Trimmer (MDT), by using sentence trimming as both a preprocessing stage and a feature for sentence ranking. We demonstrate that we were able to port Trimmer easily to this new problem. Although the direct impact of sentence trimming was minimal compared to other features used in the system, the interaction of the other features resulted in trimmed sentences accounting for nearly half of the selected summary sentences.",,2005.0,13,22,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1696402', 'name': 'Christof Monz'}, {'authorId': '35442155', 'name': 'R. Schwartz'}]"
eeb6793493f4ee2676b15f1cbb4133797443603f,https://www.semanticscholar.org/paper/eeb6793493f4ee2676b15f1cbb4133797443603f,"""Bag of Words"" is not enough for Strength of Evidence Classification","Incorporation of evidence from clinical research requires critical appraisal of its quality. Information retrieval systems can facilitate clinicians' judgments by automatically labeling retrieved citations with their strength of evidence categories. Preliminary results of such a text classification experiment involving MEDLINE citations show that a ""bag of words"" approach is insufficient for accurate classification.",American Medical Informatics Association Annual Symposium,2005.0,8,7,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
ef1f496106b598b1484039f6b61f37fac1961949,https://www.semanticscholar.org/paper/ef1f496106b598b1484039f6b61f37fac1961949,"A Menagerie of Tracks at Maryland: HARD, Enterprise, QA, and Genomics, Oh My!","This year, the University of Maryland participated in four separate tracks: HARD, enterprise, question answering, and genomics. Our HARD experiments involved a trained intermediary who searched for documents on behalf of the user, created clarification forms manually, and exploited user responses accordingly. The aim was to better understand the nature of single-iteration clarification dialogs and to develop an ‚Äúontology of clarifications‚Äù that can be leveraged to guide system development. For the enterprise track, we submitted ocial runs to the Known Item Search and the Discussion Search tasks. Document transformation to normalize dates and version numbers was found to be helpful, but suppression of text quoted from earlier messages and expansion of the indexed terms for a message based on subject line threading proved to not be. For the QA track, we submitted a manual run of ‚Äúother‚Äù questions in an eort to quantify human performance on the task. Our genomics track participation was in collaboration with the National Library of Medicine, and is primarily reported in NLM‚Äôs overview paper.",Text Retrieval Conference,2005.0,17,11,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '145055395', 'name': 'E. Abels'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}, {'authorId': '1737250', 'name': 'Douglas W. Oard'}, {'authorId': '2143819726', 'name': 'Philip Wu'}, {'authorId': '2136373', 'name': 'Yejun Wu'}]"
f79a900f24f02ef2e274e6a9a69d456b9991720d,https://www.semanticscholar.org/paper/f79a900f24f02ef2e274e6a9a69d456b9991720d,UMD/BBN at MSE2005,"We implemented an initial application of a sentence-trimming approach (Trimmer) to the problem of multi-document summarization in the MSE2005 task. Sentence trimming was incorporated into a feature-based summarization system, called Multi-Document Trimmer (MDT), by using sentence trimming as both a pre-processing stage and a feature for sentence ranking. We demonstrate that we were able to port Trimmer easily to this new problem, although the impact of sentence trimming was minimal compared to other features used in the system. The performance of our system in the official MSE2005 task was around the middle of the pack (16 out of 27). After some minor bug fixes and a simple correction (dateline removal) we obtained an improvement on a post-hoc run on the test data.",,2005.0,5,4,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '35442155', 'name': 'R. Schwartz'}]"
fc688faf612693d4e8eb2237d20ad982334ef67f,https://www.semanticscholar.org/paper/fc688faf612693d4e8eb2237d20ad982334ef67f,Representation of Information Needs and the Elements of Context: A Case Study in the Domain of Clinical Medicine,"Information seekers today have an ingrained habit of issuing extremely short queries to retrieval systems. Although the dominance of Web search contributes to reinforcement of this behavior, the inability for retrieval systems to take advantage of more expressive query representations is also a culprit. Short queries pose a challenge to designers of information retrieval systems for a number of reasons: At the linguistic level, they often contain polysemous words that are difficult to disambiguate without appropriate contextual cues. At a higher level, short queries do not provide clues regarding the broader activities that give rise to the user‚Äôs information need. There is reason to believe that if a computer system were able to solicit richer queries from a user, it might be able to build a better model of the information seeking process, thereby leading to higher retrieval performance‚Äîfor example, Hearst [8] has shown that faceted queries can be converted into simple post-filtering constraints to boost precision. Note, however, that ‚Äúricher‚Äù queries do not necessarily mean natural language descriptions‚Äîin fact, language processing technology is not yet sufficiently advanced to capture the intricacies of free text for document retrieval. Instead, we believe that a more fruitful approach is to focus on structured representations of information needs that better capture the different aspects of the information seeking process. The idea that ‚Äúbags of words‚Äù are poor query representations is by no means new. Even before the invention of computers, librarians have long known that retrieval should be performed at the conceptual level. More recently, Belkin‚Äôs work on anomalous states of knowledge [3] brought this to the attention of information retrieval researchers. The idea that IR systems serve to bring different cognitive representations ‚Äúinto alignment‚Äù has also been explored within the framework of cognitive information retrieval [9]. We recognize the difficulty in designing query representa-",,2005.0,13,6,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1398175407', 'name': 'Dina Demner-Fushman'}]"
1f921759e67ad6e6e85cf4d70028d4ff85de029b,https://www.semanticscholar.org/paper/1f921759e67ad6e6e85cf4d70028d4ff85de029b,A Computational Framework for Non-Lexicalist Semantics,"Under a lexicalist approach to semantics, a verb completely encodes its syntactic and semantic structures, along with the relevant syntax-to-semantics mapping; polysemy is typically attributed to the existence of different lexical entries. A lexicon organized in this fashion contains much redundant information and is unable to capture cross-categorial morphological derivations. The solution is to spread the ""semantic load"" of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist Program.",North American Chapter of the Association for Computational Linguistics,2004.0,23,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
20823e7c5defc16555124d045d6c4b92ff10254b,https://www.semanticscholar.org/paper/20823e7c5defc16555124d045d6c4b92ff10254b,Event structure and the encoding of arguments: the syntax of the Mandarin and English verb phrase,"This work presents a theory of linguistic representation that attempts to capture the syntactic structure of verbs and their arguments. My framework is based on the assumption that the proper representation of argument structure is event structure. Furthermore, I develop the hypothesis that event structure is syntactic structure, and argue that verb meanings are compositionally derived in the syntax from verbalizing heads, functional elements that license eventive interpretations, and verbal roots, abstract concepts drawn from encyclopedic knowledge. The overall goal of the enterprise is to develop a theory that is able to transparently relate the structure and meaning of verbal arguments. By hypothesis, languages share the same inventory of primitive building blocks and are governed by the same set of constraints‚Äîall endowed by principles of Universal Grammar and subjected to parametric variations. Support for my theory is drawn from both Mandarin Chinese and English. In particular, the organization of the Mandarin verbal system provides strong evidence for the claim that activity and state are the only two primitive verb types in Chinese‚Äî achievements and accomplishments are syntactically-derived complex categories. As a specific instance of complex event composition, I examine Mandarin resultative verb compounds and demonstrate that a broad range of variations can be perspicuously captured in my framework. I show that patterns of argument sharing in these verbal compounds can be analyzed as control, thus grounding argument structure in wellknown syntactic constraints such as the Minimum Distance Principle. Finally, I argue that cross-linguistic differences in the realization of verbal arguments can be reduced to variations in the way functional elements interact with verbal roots. Overall, my work not only contributes to our understanding of how events are syntactically represented, but also explicates interactions at the syntax-semantics interface, clarifying the relationship between surface form, syntactic structure, and logical form. A theory of argument structure grounded in independently-motivated syntactic constraints, on the one hand, and the semantic structure of events, on the other hand, is able to account for a wide range of empirical facts with few stipulations. Thesis Supervisor: Boris Katz Title: Principal Research Scientist",,2004.0,202,67,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
234bf75f8aa0825e639febed540e23d2c8001ca6,https://www.semanticscholar.org/paper/234bf75f8aa0825e639febed540e23d2c8001ca6,Answering Multiple Questions on a Topic From Heterogeneous Resources,"MIT CSAIL‚Äôs entry into this year‚Äôs TREC Question Answering track focused on the conversational aspect of this year‚Äôs task, on improving the coverage of our list and definition systems, and on an infrastructure to generalize our TREC-specific tools for other question answering tasks. While our overall architecture remained largely unchanged from last year, we have built on our strengths for each component: our web-based factoid engine was adapted for input from a new web search engine; our list engine‚Äôs knowledge base expanded from 150 to over 3000 lists; our definitional nugget extractor now has expanded and improved patterns with improved component precision and recall. Beyond their internal improvements, these components were adapted to a larger conversational framework that passed information about the topic1 to factoids and lists. Answer selection for definitional2 questions newly took into account the prior questions and answers for duplicate removal. Our factoid engine, Aranea (Lin et al., 2002; Katz et al., 2003), used the World Wide Web to find candidate answers to the given question, and then projects its best candidates onto the corpus, choosing the one best supported. This year, instead of using only Google for web search, we integrated results from the Teoma search engine as well. Our list engine, Pauchok (Tellex et al., 2003), retrieved passage-sized chunks of text relevant to the question using information re-",Text Retrieval Conference,2004.0,10,29,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '2586735', 'name': 'M. Bilotti'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '144798452', 'name': 'Wesley Hildebrandt'}, {'authorId': '2641437', 'name': 'Roni Katzir'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2652713', 'name': 'D. Loreto'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}, {'authorId': '144371948', 'name': 'Federico Mora'}, {'authorId': '1723337', 'name': '√ñzlem Uzuner'}]"
4e3e655e168f91990a7b865195307c33de7c6b7a,https://www.semanticscholar.org/paper/4e3e655e168f91990a7b865195307c33de7c6b7a,What Works Better for Question Answering: Stemming or Morphological Query Expansion?,"How do dieren t information retrieval techniques aect the performance of document retrieval in the context of question answering? An exploration of this question is our overall research goal. In this paper, we specically examine strategies for coping with morphological variation. This work quantitatively compares two dieren t approaches to handling term variation: applying a stemming algorithm at indexing time, and performing morphological query expansion at retrieval time. We discovered that, compared to the no-stemming baseline, stemming results in lower recall, and morphological expansion yields higher recall. By separately weighting dieren t term variants, we were able to achieve even higher recall, which opens the door to interesting question analysis algorithms for sophisticated query generation. Another signican t contribution of our work is the development of a reusable question answering test collection to support our experiments.",,2004.0,12,75,"[{'authorId': '2586735', 'name': 'M. Bilotti'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
9b920be29fad71ad686c0e10990647b6942dc6fb,https://www.semanticscholar.org/paper/9b920be29fad71ad686c0e10990647b6942dc6fb,Viewing the Web as a Virtual Database for Question Answering,"Although the World Wide Web contains a tremendous amount of information, the lack of intuitive information access methods and the paucity of uniform structure make finding the right knowledge difficult. Our solution is to turn the Web into a ‚Äúvirtual database‚Äù and to access it through natural language. We have accomplished this by developing a stylized relational framework, called the object-property-value model, which captures the regularity found in both natural language questions and Web resources. We have adopted this framework in START and Omnibase, two components of a system that understands natural language questions and responds with answers extracted on the fly from heterogeneous and semistructured Web sources. Our system can answer millions of questions from hundreds of Web resources with high precision.",New Directions in Question Answering,2004.0,23,11,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}]"
ac980af7792ec49de9d9fc91e20d0a327282425b,https://www.semanticscholar.org/paper/ac980af7792ec49de9d9fc91e20d0a327282425b,Fine-Grained Lexical Semantic Representations and Compositionally-Derived Events in Mandarin Chinese,"Current lexical semantic representations for natural language applications view verbs as simple predicates over their arguments. These structures are too coarse-grained to capture many important generalizations about verbal argument structure. In this paper, I specifically defend the following two claims: verbs have rich internal structure expressible in terms of finer-grained primitives of meaning, and at least for some languages, verbal meaning is compositionally derived from these primitive elements. I primarily present evidence from Mandarin Chinese, whose verbal system is very different from that of English. Many empirical facts about the typology of verbs in Mandarin cannot be captured by a ""flat"" lexical semantic representation. These theoretical results hold important practical consequences for natural language processing applications.",HLT-NAACL 2004,2004.0,30,1,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
d9892fcc7264e8f21d6ea0d946fb2b3634ed8ab2,https://www.semanticscholar.org/paper/d9892fcc7264e8f21d6ea0d946fb2b3634ed8ab2,Answering Questions About Moving Objects in Videos,"Current question answering systems succeed in many respects regarding questions about textual documents. However, information exists in other media, which provides both opportunities and challenges for question answering. We describe our efforts in extending question answering capabilities to video data: our implemented prototype, Spot, can answer questions about moving objects in a surveillance setting. This novel application of vision and language technology is situated within a larger framework designed to integrate knowledge from multiple domains under a common representation. We believe that our framework will support the next generation of multimodal natural language information access systems.",New Directions in Question Answering,2004.0,23,5,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '34712076', 'name': 'C. Stauffer'}, {'authorId': '1719838', 'name': 'W. Grimson'}]"
08b90ce3f67a082255554d3448476fd722c05f9c,https://www.semanticscholar.org/paper/08b90ce3f67a082255554d3448476fd722c05f9c,Sticky notes for the semantic web,"Computer-based annotation is increasing in popularity as a mechanism for revising documents and sharing comments over the Internet. One reason behind this surge is that viewpoints, summaries, and notes written by others are often helpful to readers. In particular, these types of annotations can help users locate or recall relevant documents. We believe that this model can be applied to the problem of retrieval on the Semantic Web. In this paper, we propose a generalized annotation environment that supports richer forms of description such as natural language. We discuss how RDF can be used to model annotations and the connections between annotations and the documents they describe. Furthermore, we explore the idea of a question answering interface that allows retrieval based both on the text of the annotations and the annotations associated metadata. Finally, we speculate on how these features could be pervasively integrated into an information management environment, making Semantic Web annotation a first class player in terms of document management and retrieval",International Conference on Intelligent User Interfaces,2003.0,13,26,"[{'authorId': '1743286', 'name': 'David R Karger'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2249050', 'name': 'Dennis Quan'}]"
0e9fc78de5ad149efe7670142398fc59e334cd50,https://www.semanticscholar.org/paper/0e9fc78de5ad149efe7670142398fc59e334cd50,START: A Framework for Facilitating E-Rulemaking,"Federal agencies implement laws passed by Congress by making rules and regulations that can be applied in practice. Stakeholders and members of the public usually want to know how proposed rules will affect them, so they can effectively respond to the proposals, during the comment period. While the stakeholders, like business and advocacy groups, can employ information specialists to get their answers, individuals will have to turn to the rulemaking agencies for such information. Consequently, for online rulemaking to encourage and support public participation, there will be need for information access that is simple and intuitive to use, comprehensive in the material covered, specific to the user's needs and timely.",Digital Government Research,2003.0,0,0,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '143641586', 'name': 'R. Hurwitz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1723337', 'name': '√ñzlem Uzuner'}]"
12c5ea57b66dbfa8eba4a569af3defada4f3c70a,https://www.semanticscholar.org/paper/12c5ea57b66dbfa8eba4a569af3defada4f3c70a,Organizing Knowledge and Accessing a Comprehensive Base Using the World Wide Web,"To address the problem of information overload in today's world, we have developed START, a natural lan- guage question answering system that provides users with high-precision information access through the use of natural language annotations. To address the disfculty of accessing large amounts of heterogeneous structured and semistructured data, we have developed Omnibase, which assists START by integrating Web databases into a single, uniformly structured ""virtual database."" To address the sheer amount of unstruc- tured information available electronically, we have developed techniques for distilling large amounts of free tat into rela- tions that capture the salient aspects of the texf. The com- bination of natural language annotation technology, object- pmperpvalue data model, and relation extraction technology allows us to rapidly develop and deploy smrt applications for knowledge intensive domains. Our ultimate goal is to develop a computer system that acts like a ""smart reference librarian,"" providing users with ""just the right information"" in response fa questions posed in natural language.",,2003.0,16,0,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
182ab49a3d31fe468c7659ee89129c2cd8edc9de,https://www.semanticscholar.org/paper/182ab49a3d31fe468c7659ee89129c2cd8edc9de,Question answering from the web using knowledge annotation and knowledge mining techniques,"We present a strategy for answering fact-based natural language questions that is guided by a characterization of real-world user queries. Our approach, implemented in a system called Aranea, extracts answers from the Web using two different techniques: knowledge annotation and knowledge mining. Knowledge annotation is an approach to answering large classes of frequently occurring questions by utilizing semi\-structured and structured Web sources. Knowledge mining is a statistical approach that leverages massive amounts of Web data to overcome many natural language processing challenges. We have integrated these two different paradigms into a question answering system capable of providing users with concise answers that directly address their information needs.",International Conference on Information and Knowledge Management,2003.0,28,119,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '6104312', 'name': 'Boris Katz'}]"
29a22d3eab2668d05c8fa478e8a61e146e6dca35,https://www.semanticscholar.org/paper/29a22d3eab2668d05c8fa478e8a61e146e6dca35,Extracting Structural Paraphrases from Aligned Monolingual Corpora,"We present an approach for automatically learning paraphrases from aligned monolingual corpora. Our algorithm works by generalizing the syntactic paths between corresponding anchors in aligned sentence pairs. Compared to previous work, structural paraphrases generated by our algorithm tend to be much longer on average, and are capable of capturing long-distance dependencies. In addition to a standalone evaluation of our paraphrases, we also describe a question answering application currently under development that could immensely benefit from automatically-learned structural paraphrases.",IWP@ACL,2003.0,16,138,"[{'authorId': '2082403049', 'name': 'Ali Ibrahim'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
30328249e7ab7e67f4a83965415d916dd5b74ac0,https://www.semanticscholar.org/paper/30328249e7ab7e67f4a83965415d916dd5b74ac0,Better Public Policy Through Natural Language Information Access,"Federal agencies implement laws passed by the Congress by creating rules and regulations that can be applied in practice. During this process, staffs at the various agencies may review past and current regulations and receive comments from stakeholders and the public regarding the proposed regulations.Putting rulemaking online can increase the public's awareness of the proposed rules and its participation in the process. It can also facilitate staff work. A key factor in realizing these benefits will be the availability of simple, intuitive, and timely access to the empowering legislation, the proposed rules and information regarding them. We propose to provide such access through an information architecture that allows members of the public as well as staff and stakeholders to obtain the texts and information they desire by using everyday language. Over the past decade, we have developed the START and Omnibase systems for natural language question answering and have applied them in a variety of domains. We plan to use these systems and our experience to support online rule making.We note that besides providing information access, these systems can function more proactively, by soliciting feedback from targeted parties or by sending out notifications and information in response to standing queries submitted by the users.",Digital Government Research,2003.0,10,2,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '143641586', 'name': 'R. Hurwitz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1723337', 'name': '√ñzlem Uzuner'}]"
44cf0be24082e10b59c2fcf6f7ee42f93ae750eb,https://www.semanticscholar.org/paper/44cf0be24082e10b59c2fcf6f7ee42f93ae750eb,The role of context in question answering systems,"Despite recent advances in natural language question an-swering technology, the problem of designing effective user interfaces has been largely unexplored. We conducted a user study to investigate the problem and discovered that overall, users prefer a paragraph-sized chunk of text over just an exact phrase as the answer to their questions. Fur-thermore, users generally prefer answers embedded in con-text, regardless of the perceived reliability of the source documents. When users research a topic, increasing the amount of text returned to users significantly decreases the number of queries that they pose to the system, suggesting that users utilize supporting text to answer related ques-tions. We believe that these results can serve to guide future developments in question answering user interfaces.",CHI Extended Abstracts,2003.0,8,68,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2249050', 'name': 'Dennis Quan'}, {'authorId': '37845213', 'name': 'Vineet Sinha'}, {'authorId': '145822794', 'name': 'Karun Bakshi'}, {'authorId': '144723669', 'name': 'David Huynh'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '1743286', 'name': 'David R Karger'}]"
5166a0dfbc78b864c8d04318e4c404ac542385ed,https://www.semanticscholar.org/paper/5166a0dfbc78b864c8d04318e4c404ac542385ed,Question Answering Techniques for the World Wide Web,"Question answering systems have become increasingly popular because they deliver users short, succinct answers instead of overloading them with a large number of irrelevant documents. The vast amount of information readily available on the World Wide Web presents new opportunities and challenges for question answering. In order for question answering systems to benefit from this vast store of useful knowledge, they must cope with large volumes of useless data.",,2003.0,136,22,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '6104312', 'name': 'Boris Katz'}]"
51882ef298fc87c73801f3dc80947328860c0a00,https://www.semanticscholar.org/paper/51882ef298fc87c73801f3dc80947328860c0a00,What Makes a Good Answer? The Role of Context in Question Answering,"Question answering systems have proven to be helpful to users because they can provide succinct answers that do not require users to wade through a large number of documents. However, despite recent advances in the underlying question answering technology, the problem of designing effective interfaces has been largely unexplored. We conducted a user study to investigate this area and discovered that, overall, users prefer paragraph-sized chunks of text over just an exact phrase as the answer to their questions. Furthermore, users generally prefer answers embedded in context, regardless of the perceived reliability of the source documents. When researching a topic, increasing the amount of text returned to users significantly decreases the number of queries that they pose to the system, suggesting that users utilize supporting text to answer related questions. We believe that these results can serve to guide future developments in question answering interfaces.",IFIP TC13 International Conference on Human-Computer Interaction,2003.0,17,127,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2249050', 'name': 'Dennis Quan'}, {'authorId': '37845213', 'name': 'Vineet Sinha'}, {'authorId': '145822794', 'name': 'Karun Bakshi'}, {'authorId': '144723669', 'name': 'David Huynh'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '1743286', 'name': 'David R Karger'}]"
6ac274fb90f64c41de2bc5b0935dc57bf14a60a6,https://www.semanticscholar.org/paper/6ac274fb90f64c41de2bc5b0935dc57bf14a60a6,Selectively Using Relations to Improve Precision in Question Answering,"Despite the intuition that linguistically sophisticated techniques should be beneficial to question answering, real gains in performance have yet to be demonstrated empirically in a reliable manner. Systems built around sophisticated linguistic analysis generally perform worse than their linguistically-uninformed cousins. We believe that the key to effective application of natural language processing technology is to selectively employ it only when helpful, without abandoning simpler techniques. To this end, we identify two linguistic phenomena that current information extraction driven systems have difficulty with, and demonstrate how syntactic processing can help. By indexing syntactic relations that can be reliably extracted from corpus text and matching questions with documents at the relation level, we demonstrate that syntactic analysis enables a question answering system to successfully handle these phenomena, thereby improving precision.",,2003.0,14,118,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
828c773ec37c9f3e5e245780ba37dae7466acdd4,https://www.semanticscholar.org/paper/828c773ec37c9f3e5e245780ba37dae7466acdd4,Quantitative evaluation of passage retrieval algorithms for question answering,"Passage retrieval is an important component common to many question answering systems. Because most evaluations of question answering systems focus on end-to-end performance, comparison of common components becomes difficult. To address this shortcoming, we present a quantitative evaluation of various passage retrieval algorithms for question answering, implemented in a framework called Pauchok. We present three important findings: Boolean querying schemes perform well in the question answering task. The performance differences between various passage retrieval algorithms vary with the choice of document retriever, which suggests significant interactions between document retrieval and passage retrieval. The best algorithms in our evaluation employ density-based measures for scoring query terms. Our results reveal future directions for passage retrieval and question answering.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2003.0,27,349,"[{'authorId': '2913681', 'name': 'Stefanie Tellex'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}]"
9090ef73b412013196b464cf7d82f1238e71f414,https://www.semanticscholar.org/paper/9090ef73b412013196b464cf7d82f1238e71f414,Answering Questions about Moving Objects in Surveillance Videos,"Current question answering systems succeed in many respects regarding questions about textual documents. However, information exists in other media, which provides both opportunities and challenges for question answering. We present results in extending question answering capabilities to video footage captured in a surveillance setting. Our prototype system, called Spot, can answer questions about moving objects that appear within the video. We situate this novel application of vision and language technology within a larger framework designed to integrate language and vision systems under a common representation. We believe that our framework will support the next generation of multimodal natural language information access systems.",New Directions in Question Answering,2003.0,22,48,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '34712076', 'name': 'C. Stauffer'}, {'authorId': '1719838', 'name': 'W. Grimson'}]"
9df60943a1eb7cc51aae644e4d1d00523ea53a8d,https://www.semanticscholar.org/paper/9df60943a1eb7cc51aae644e4d1d00523ea53a8d,Integrating Web-based and Corpus-based Techniques for Question Answering,"MIT CSAIL‚Äôs entry in this year‚Äôs TREC Question Answering track focused on integrating Web-based techniques with more traditional strategies based on document retrieval and named-entity detection. We believe that achieving high performance in the question answering task requires a combination of multiple strategies designed to capitalize on different characteristics of various resources. The system we deployed for the TREC evaluation last year relied exclusively on the World Wide Web to answer factoid questions (Lin et al., 2002). The advantages that the Web offers are well known and have been exploited by previous systems (Brill et al., 2001; Clarke et al., 2001; Dumais et al., 2002). The immense amount of freely available unstructured text provides data redundancy, which can be leveraged with simple pattern matching techniques involving the expected answer formulations. In many ways, we can utilize huge quantities of data to overcome many thorny problems in natural language processing such as lexical ambiguity and paraphrases. Furthermore, Web search engines such as Google provide a convenient front-end for accessing and filtering enormous amounts of Web data. We have identified this class of techniques as the knowledge mining approach to question answering (Lin and Katz, 2003). In addition to viewing the Web as a repository of unstructured documents, we can also take advantage of structured and semistructured sources available on the Web using knowledge annotation techniques (Katz, 1997; Lin and Katz, 2003). Through empirical analysis of real world natural language questions, we have noticed that large classes of commonly occurring queries can be parameterized and captured using a simple object‚Äìproperty‚Äìvalue data model (Katz et al., 2002). Furthermore, such a data model is easy to impose on Web resources through a framework of wrapper scripts. These techniques allow our system to view the Web as if it were a ‚Äúvirtual database‚Äù and use knowledge contained therein to answer user questions. While the Web is undeniably a useful resource for question answering, it is not without drawbacks. Useful knowledge on the Web is often drowned out by the sheer amount of irrelevant material, and statistical techniques are often insufficient to separate right answers from wrong ones. Overcoming these obstacles will require addressing many outstanding issues in computational linguistics: anaphora resolution, paraphrase normalization, temporal reference calculation, and lexical disambiguation, just to name a few. Furthermore, the setup of the TREC evaluations necessitates an extra step in the question answering process for systems that extract answers from external sources, typically known as answer projection. For every Web-derived answer, a system must find a supporting document from the AQUAINT corpus, even if the corpus was not used in the answer extraction process. This year‚Äôs main task included definition and list questions in addition to factoid questions. Although Web-based techniques have proven effective in handling factoid questions, they are less applicable to tackling definition and list questions. The datadriven approach implicitly assumes that each natural language question has a unique answer. Since a single answer instance is sufficient, algorithms were designed to trade recall for precision. For list and definition questions, however, a more balanced approach is required, since multiple answers are not only desired, but necessary. We believe that the best strategy is to integrate Web-based approaches with more traditional question answering techniques driven by document retrieval and named-entity detection. Corpusand Web-based strategies should play complementary roles in an overall question answering framework.",Text Retrieval Conference,2003.0,15,70,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2652713', 'name': 'D. Loreto'}, {'authorId': '144798452', 'name': 'Wesley Hildebrandt'}, {'authorId': '2586735', 'name': 'M. Bilotti'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}, {'authorId': '144371948', 'name': 'Federico Mora'}]"
0c7c2ca0579112c81d5a98fb0d110d1a006759b5,https://www.semanticscholar.org/paper/0c7c2ca0579112c81d5a98fb0d110d1a006759b5,Web question answering: is more always better?,"This paper describes a question answering system that is designed to capitalize on the tremendous amount of data that is now available online. Most question answering systems use a wide variety of linguistic resources. We focus instead on the redundancy available in large corpora as an important resource. We use this redundancy to simplify the query rewrites that we need to use, and to support answer mining from returned snippets. Our system performs quite well given the simplicity of the techniques being utilized. Experimental results show that question answering accuracy can be greatly improved by analyzing more and more matching passages. Simple passage ranking and n-gram extraction techniques work well in our system making it efficient to use with many backend retrieval engines.",Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2002.0,20,344,"[{'authorId': '1728602', 'name': 'S. Dumais'}, {'authorId': '2339397', 'name': 'Michele Banko'}, {'authorId': '145022783', 'name': 'Eric Brill'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2067947449', 'name': 'Andrew Y. Ng'}]"
245a4fd0c0c6ecf1cae13e92c0a6fda6c2a0a5dc,https://www.semanticscholar.org/paper/245a4fd0c0c6ecf1cae13e92c0a6fda6c2a0a5dc,Annotating the Semantic Web Using Natural Language,"Because the ultimate purpose of the Semantic Web is to help users better locate, organize, and process content, we believe that it should be grounded in the information access method humans are most comfortable with---natural language. However, the Resource Description Framework (RDF), the foundation of the Semantic Web, was designed to be easily processed by computers, not humans. To render RDF more friendly to humans, we propose to augment it with natural language annotations, or metadata written in everyday language. We argue that natural language annotations, parsed into computer-readable representations, are not only intuitive and effective, but can also accelerate the pace with which the Semantic Web is being adopted. We believe that our technology can facilitate a happy marriage between natural language technology and the Semantic Web vision.",NLPXML@COLING,2002.0,19,30,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
3b0c064023ca9ad059086709e766c1cee7af6a3c,https://www.semanticscholar.org/paper/3b0c064023ca9ad059086709e766c1cee7af6a3c,Start and Beyond,"To address the problem of information overload in today‚Äôs world, we have developed Start, a natural language question answering system that provides users with multimedia information access through the use of natural language annotations. In order to harness the potential of knowledge sources on the World Wide Web, we have developed Omnibase, a virtual database that provides uniform access to Web resources. Our ultimate goal is to develop a computer system that acts like a ‚Äúsmart reference librarian,‚Äù and to a large extent, we have accomplished our goal. However, expanding our system‚Äôs domain of knowledge is a time-consuming task that requires trained individuals. This paper describes several research directions aimed at overcoming the limitations of our current technology.",,2002.0,21,18,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
433a55112018b7edb32c4212234a8f83b8042383,https://www.semanticscholar.org/paper/433a55112018b7edb32c4212234a8f83b8042383,Extracting Answers from the Web Using Data Annotation and Knowledge Mining Techniques.,"Production of strong lightweight membrane structure by applying a thin reflective coating such as aluminum to a rotating cylinder, applying a mesh material such as nylon over the aluminum coating, coating the mesh overlying the aluminum with a polymerizing material such as a para-xylylene monomer gas to polymerize as a film bound to the mesh and the aluminum, and applying an emissivity increasing material such as chromium and silicon monoxide to the polymer film to disperse such material colloidally into the growing polymer film, or applying such material to the final polymer film, and removing the resulting membrane structure from the cylinder. Alternatively, such membrane structure can be formed by etching a substrate in the form of an organic film such as a polyimide, or a metal foil, to remove material from the substrate and reduce its thickness, applying a thin reflective coating such as aluminum on one side of the substrate and applying an emissivity increasing coating such as chromium and silicon monoxide on the reverse side of the substrate.",,2002.0,0,16,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}, {'authorId': '2913681', 'name': 'Stefanie Tellex'}]"
728ce50dc5bceb9621c9ae7cbddf37d4183e9039,https://www.semanticscholar.org/paper/728ce50dc5bceb9621c9ae7cbddf37d4183e9039,Natural Language Annotations for the Semantic Web,,OTM Conferences / Workshops,2002.0,14,41,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2249050', 'name': 'Dennis Quan'}]"
963dc23a64603527e592b5fcfa8831845b1313ea,https://www.semanticscholar.org/paper/963dc23a64603527e592b5fcfa8831845b1313ea,The START Multimedia Information System: Current Technology and Future Directions,"To address the problem of information overload in today‚Äôs world, we have developed Start, a natural language question answering system that provides users with high-precision multimedia information access through the use of natural language annotations. To address the difficulty of accessing large amounts of heterogeneous data, we have developed Omnibase, which assists Start by integrating structured and semistructured Web databases into a single, uniformly structured ‚Äúvirtual database.‚Äù Our ultimate goal is to develop a computer system that acts like a ‚Äúsmart reference librarian,‚Äù and we believe we have laid a firm foundation for achieving our goal. This paper describes our current implemented system and discusses future research directions.",Multimedia Information Systems,2002.0,22,34,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724731', 'name': 'Sue Felshin'}]"
bb0468ff520abe817a1456f70e9c0eb0845ddebc,https://www.semanticscholar.org/paper/bb0468ff520abe817a1456f70e9c0eb0845ddebc,The Web as a Resource for Question Answering: Perspectives and Challenges,"The vast amounts of information readily available on the World Wide Web can be effectively used for question answering in two fundamentally different ways. In the federated approach, techniques for handling semistructured data are applied to access Web sources as if they were databases, allowing large classes of common questions to be answered uniformly. In the distributed approach, largescale text-processing techniques are used to extract answers directly from unstructured Web documents. Because the Web is orders of magnitude larger than any human-collected corpus, question answering systems can capitalize on its unparalleled-levels of data redundancy. Analysis of real-world user questions reveals that the federated and distributed approaches complement each other nicely, suggesting a hybrid approach in future question answering systems.",International Conference on Language Resources and Evaluation,2002.0,75,67,"[{'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
dedb02a94a1e461a065fd981f53e85e54bef170d,https://www.semanticscholar.org/paper/dedb02a94a1e461a065fd981f53e85e54bef170d,Omnibase: Uniform Access to Heterogeneous Data for Question Answering,,International Conference on Applications of Natural Language to Data Bases,2002.0,17,153,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}, {'authorId': '2082403049', 'name': 'Ali Ibrahim'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '38102633', 'name': 'Gregory A. Marton'}, {'authorId': '143954921', 'name': 'A. McFarland'}, {'authorId': '34868643', 'name': 'Baris Temelkuran'}]"
e52521e4a8af2df84b2141dd4c326b26e7204f00,https://www.semanticscholar.org/paper/e52521e4a8af2df84b2141dd4c326b26e7204f00,AskMSR: Question Answering Using the Worldwide Web,"The design of the AskMSR question answering system is motivated by recent observations in natural language processing that for many applications, significant improvements in accuracy can be attained simply by increasing the amount of data used for learning (e.g., Banko & Brill, 2001). By taking advantage of the vast amount of online text available via the worldwide web, rather than relying on an approach that depends heavily on natural language intensive techniques, we developed a simple but effective question answering system. Many groups working on question answering use a variety of linguistic resources ‚Äì part-of-speech tagging, parsing, named entiry extraction, WordNet, etc. We chose instead to focus on the tremendous resource that the web provides simply as a gigantic data repository. The web, which is home to billions of pages of electronic text, is orders of magnitude larger than the TREC QA document collection, which consists of fewer than 1 million documents.",,2002.0,5,73,"[{'authorId': '2339397', 'name': 'Michele Banko'}, {'authorId': '113773659', 'name': 'Eric Brili'}, {'authorId': '1728602', 'name': 'S. Dumais'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
260cb4e0f769872e28b1c84b8881b22267a213c1,https://www.semanticscholar.org/paper/260cb4e0f769872e28b1c84b8881b22267a213c1,Annotating the World Wide Web,"Motivation: Keyword search engines are popular because they provide results‚Äîoften, too many results! If we could understand, at least partially, the meaning of documents, rather than just recognizing the words, we could answer queries with much higher precision. Natural language is the most convenient and most intuitive method of information access, and people should be able to retrieve information using a system capable of understanding and answering natural language questions.",,2001.0,5,3,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
27b7d9df7bfc8437445eabbb56f69665a283c944,https://www.semanticscholar.org/paper/27b7d9df7bfc8437445eabbb56f69665a283c944,Improving the Precision of Information Retrieval Systems Using Syntactic Relations,"The Problem: Traditional information retrieval systems based on the ‚Äúbag-of-words‚Äù paradigm cannot capture the semantic content of documents. While these systems are relatively robust and have high recall, they suffer from very poor precision. On the other hand, it is impossible with current technology to build a practical information access system that fully analyzes and understands unrestricted natural language. Existing natural language systems, despite their high precision, have low recall and lack robustness.",,2001.0,5,1,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
2ab5a5fce5c7b580b6c9934ba9155be59f09a63e,https://www.semanticscholar.org/paper/2ab5a5fce5c7b580b6c9934ba9155be59f09a63e,Gathering Knowledge for a Question Answering System from Heterogeneous Information Sources,"Although vast amounts of information are available electronically today, no effective information access mechanism exists to provide humans with convenient information access. A general, open-domain question answering system is a solution to this problem. We propose an architecture for a collaborative question answering system that contains four primary components: an annotations system for storing knowledge, a ternary expression representation of language, a transformational rule system for handling some complexities of language, and a collaborative mechanism by which ordinary users can contribute new knowledge by teaching the system new information. We have developed a initial prototype, called Webnotator, with which to test these ideas.",HTLKM@ACL,2001.0,19,24,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724731', 'name': 'Sue Felshin'}]"
4548c06e6d056191f1a699ae6868704a14cb5f9b,https://www.semanticscholar.org/paper/4548c06e6d056191f1a699ae6868704a14cb5f9b,Data-Intensive Question Answering,Utilisation de la redondance des reponses elles-memes pour ameliorer le resultat final de la recherche d'information- redondance due a la tres grande quantite d'informations disponibles actuellement,Text Retrieval Conference,2001.0,13,330,"[{'authorId': '145022783', 'name': 'Eric Brill'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2339397', 'name': 'Michele Banko'}, {'authorId': '1728602', 'name': 'S. Dumais'}, {'authorId': '2067947449', 'name': 'Andrew Y. Ng'}]"
5bd08783b45511916cbb4b98f05dfc0377015879,https://www.semanticscholar.org/paper/5bd08783b45511916cbb4b98f05dfc0377015879,Information Access Using Natural Language,"Motivation: To address the problem of information overload in today‚Äôs world, we have developed START, a natural language question answering system that provides users with high-precision multimedia information access through the use of natural language annotations. To address the difficulty of accessing large amounts of heterogeneous data, we have developed Omnibase, which assists START by integrating structured and semistructured Web databases into a single, uniformly structured ‚Äúvirtual database.‚Äù Our ultimate goal is to develop a computer system that acts like a ‚Äúsmart reference librarian.‚Äù",,2001.0,12,2,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '68985875', 'name': 'L. Castagnola'}, {'authorId': '144893917', 'name': 'A. Fernandes'}, {'authorId': '2082403049', 'name': 'Ali Ibrahim'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '49801747', 'name': 'Jerome McFarland'}, {'authorId': '2797245', 'name': 'Alp Simsek'}]"
b4adeca45ea786f5bdf87e7f5af4684f34c46ed2,https://www.semanticscholar.org/paper/b4adeca45ea786f5bdf87e7f5af4684f34c46ed2,The Role of a Natural Language Conversational Interface in Online Sales: A Case Study,,International Journal of Speech Technology,2001.0,21,38,"[{'authorId': '1707259', 'name': 'J. Chai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2606846', 'name': 'Wlodek Zadrozny'}, {'authorId': '3360246', 'name': 'Yiming Ye'}, {'authorId': '1404599693', 'name': 'Margo Stys-Budzikowska'}, {'authorId': '32237576', 'name': 'V. Horvath'}, {'authorId': '2302447', 'name': 'N. Kambhatla'}, {'authorId': '39548870', 'name': 'C. Wolf'}]"
e36b5c921f9e03f615de986ead0e0b5bd28f7324,https://www.semanticscholar.org/paper/e36b5c921f9e03f615de986ead0e0b5bd28f7324,Evaluation of a Natural Language Dialog Based Web Navigation System-- A Case Study,"With the emergence of e-commerce, websites must accommodate both customer needs and business requirements. Menu driven navigation and keyword search provided by most commercial sites have tremendous limitations. There is no way to balance the current needs and intentions of a user with the business requirements of the site. Often, as a result, users are overwhelmed and frustrated by the lengthy interaction, because it‚Äôs hard to precisely describe their intentions, e.g. buying ""dark pants without cuffs"". The solution lies, in our opinion, in centering electronic commerce websites around natural language and multimodal dialog. This claim is supported by results of a recent study we performed, and which we present in this paper.",,2001.0,0,0,"[{'authorId': '1707259', 'name': 'J. Chai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2606846', 'name': 'Wlodek Zadrozny'}, {'authorId': '3360246', 'name': 'Yiming Ye'}, {'authorId': '2087524125', 'name': 'Margo Budzikowska'}, {'authorId': '32237576', 'name': 'V. Horvath'}, {'authorId': '2302447', 'name': 'N. Kambhatla'}, {'authorId': '39548870', 'name': 'C. Wolf'}]"
4640a3c0b3a9fca1dad6bf43be3aacdfe5727b14,https://www.semanticscholar.org/paper/4640a3c0b3a9fca1dad6bf43be3aacdfe5727b14,REXTOR: A System for Generating Relations from Natural Language,"This paper argues that a finite-state language model with a ternary expression representation is currently the most practical and suitable bridge between natural language processing and information retrieval. Despite the theoretical computational inadequacies of finite-state grammars, they are very cost effective (in time and space requirements) and adequate for practical purposes. The ternary expressions that we use are not only linguistically-motivated, but also amenable to rapid large-scale indexing. REXTOR (Relations EXtracTOR) is an implementation of this model; in one uniform framework, the system provides two separate grammars for extracting arbitrary patterns of text and building ternary expressions from them. These content representational structures serve as the input to our ternary expressions indexer. This approach to natural language information retrieval promises to significantly raise the performance of current systems.",,2000.0,31,26,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
bba5443bb097e99ca0f1d01f6d2c6cd59d035299,https://www.semanticscholar.org/paper/bba5443bb097e99ca0f1d01f6d2c6cd59d035299,Comparative Evaluation of a Natural Language Dialog Based System and a Menu Driven System for Information Access: a Case Study,"This paper describes the evaluation of a natural language dialog based navigation system (HappyAssistant) that helps users access e-commerce sites to find relevant information about products and services. The prototype system leverages technologies in natural language processing and human computer interaction to create a faster and more intuitive way of interacting with websites, especially for the less experienced users. The result of a comparative study shows that users prefer the natural language enabled navigation two to one over the menu driven navigation. In addition, the study confirmed the efficiency of using natural language dialog in terms of the number of clicks and the amount of time required to obtain the relevant information. In the case study, comparing to the menu driven system, the average number of clicks used in the natural language system was reduced by 63.2% and the average time was reduced by 33.3%.",RIAO Conference,2000.0,12,15,"[{'authorId': '1707259', 'name': 'J. Chai'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2606846', 'name': 'Wlodek Zadrozny'}, {'authorId': '3360246', 'name': 'Yiming Ye'}, {'authorId': '3166871', 'name': 'M. Budzikowska'}, {'authorId': '32237576', 'name': 'V. Horvath'}, {'authorId': '2302447', 'name': 'N. Kambhatla'}, {'authorId': '39548870', 'name': 'C. Wolf'}]"
a3664fcd675a638d8035291a54c134737ca94301,https://www.semanticscholar.org/paper/a3664fcd675a638d8035291a54c134737ca94301,Integrating Web resources and lexicons into a natural language query system,"The START system responds to natural language queries with answers in text, pictures, and other media. START's sentence-level natural language parsing relies on a number of mechanisms to help it process the huge, diverse resources available on the World Wide Web. Blitz, a hybrid heuristic- and corpus-based natural language preprocessor enables START to integrate a large and ever-changing lexicon of proper names, by using heuristic rules and precompiled tables of symbols to preprocess various highly regular and fixed expressions into lexical tokens. LaMeTH, a content-based system for extracting information from HTML documents, assists START by providing a uniform method of accessing information on the Web in real time. These mechanisms have considerably improved STARTS ability to analyze real-world sentences and answer queries through expansion of its lexicon and integration of Web resources.",Proceedings IEEE International Conference on Multimedia Computing and Systems,1999.0,10,5,"[{'authorId': '143912599', 'name': 'B. Katz'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '2075766686', 'name': 'Rebecca Schulman'}, {'authorId': '2078841315', 'name': 'Adnan Ilik'}, {'authorId': '2082403049', 'name': 'Ali Ibrahim'}, {'authorId': '1406784162', 'name': 'Philip Osafo-Kwaako'}]"
69eef712cf4ce4ed6b3b223fcf5394a0dc77a7ec,https://www.semanticscholar.org/paper/69eef712cf4ce4ed6b3b223fcf5394a0dc77a7ec,Blitz: A Preprocessor for Detecting Context-Independent Linguistic Structures 1,"The flow of natural language is often broken by constructions which are difficult to analyze with conventional linguistic parsers. To handle these constructions, which include numbers, dates, addresses, etc., and, to a lesser extent, proper nouns, NL systems typically implement specialized new rules. This leads to a level of complexity which renders maintenance or improvement difficult. Analyzing and tokenizing these constructions with an independent preprocessor can alleviate the burden on already taxed systems. Because these constructions have highly regular forms, strict structure, and can be largely understood in the absence of context, it is possible to shift the burden of processing away from the primary parser, and onto a simpler, faster, non-linguistic preprocessor. This paper describes Blitz, a hybrid database- and heuristic-based natural language preprocessor, which has been integrated into the START Natural Language System in order to demonstrate how non-linguistic preprocessing can improve parsing. As a result, START‚Äôs ability to analyze real-world sentences has improved considerably. Advantages of Blitz over existing systems are also discussed.",,1998.0,9,10,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724731', 'name': 'Sue Felshin'}, {'authorId': '2075766686', 'name': 'Rebecca Schulman'}, {'authorId': '2078841315', 'name': 'Adnan Ilik'}]"
02e5f147a3d49100bc9f32baccc36ae115435fc6,https://www.semanticscholar.org/paper/02e5f147a3d49100bc9f32baccc36ae115435fc6,"Reviewers, Volume 33",Jennifer Adair Jennifer Aldrich Angela Baum Michelle Bauml Doris Bergen Gloria Boutte Amanda Branscombe Lorraine Breffni Amy Broemmel Christopher Brown Nancy Brown Deborah Bruns Julie Bullard Jan G. Burcham Kathryn Castle Lori Caudle Christine Chaille Dong Hwa Choi Kenneth Counselman Leslie Couse Kay Cutler Sara Davis Anne Dorsey Angela Eckhoff Roy Evans Beatrice Fennimore Nancy Freeman Doris Fromberg Vicki Garavuso Dawn Garbett Jennifer Gilliard Dierdre Greer Sophia Han Sanna Harjusola-Webb Helen Hedges Julie Herron Rebecca Huss-Keeler Mary Jensen Jim Johnson Ithel Jones Laura Kates Virginia Keen Jill Klefstad Byran Korth Janice Kroeger Vickie Lake Karen LaParo Yuen-Ling Joyce Li Shannon McNair Daniel Meier Monica Miller-Marsh Mary Jane Moran Mark Nagasawa Stacey Neuharth-Pritchett Shelley Nicholson John Nimmo Deborah Norris Nadjwa Norton Cynthia Paris Will Parnell Jean Plaisir Beth Powers-Costello Patricia Ramsey Susan Recchia Stuart Reifel Frances Rust Sharon Ryan Catherine Scott-Little Lynda Kathryn Sharp Meagan Shedd Frances Sherwood Sara Sherwood Mariana Souto-Manning Dolores Stegelin Andrew Stremmel Judit Szente,International Conference on Computational Logic,1990.0,0,0,"[{'authorId': '1742930', 'name': 'E. Andr√©'}, {'authorId': '2124468062', 'name': 'Mark W. Johnson'}, {'authorId': '1696030', 'name': 'M. de Rijke'}, {'authorId': '1387994164', 'name': 'Jason Baldridge'}, {'authorId': '2692018', 'name': 'Laura Kallmeyer'}, {'authorId': '145428168', 'name': 'M. Riley'}, {'authorId': '35313721', 'name': 'S. Bangalore'}, {'authorId': '1932753', 'name': 'A. Kehler'}, {'authorId': '144386741', 'name': 'Fabio Rinaldi'}, {'authorId': '144779911', 'name': 'P. Blackburn'}, {'authorId': '1746503', 'name': 'A. Kilgarriff'}, {'authorId': '34739267', 'name': 'G. Ritchie'}, {'authorId': '3461596', 'name': 'Johan Bos'}, {'authorId': '152971314', 'name': 'Kevin Knight'}, {'authorId': '1794100', 'name': 'Brian Roark'}, {'authorId': '145977875', 'name': 'Antal van den Bosch'}, {'authorId': '1755162', 'name': 'Philipp Koehn'}, {'authorId': '2263444789', 'name': 'J. Rogers'}, {'authorId': '1784037', 'name': 'T. Brants'}, {'authorId': '2299876', 'name': 'R. Koeling'}, {'authorId': '144590225', 'name': 'D. Roth'}, {'authorId': '5486617', 'name': 'C. Brew'}, {'authorId': '145762466', 'name': 'A. Korhonen'}, {'authorId': '2064422245', 'name': 'Giorgio Satta'}, {'authorId': '145693410', 'name': 'Ted Briscoe'}, {'authorId': '2059862306', 'name': 'Andr√°s Kornai'}, {'authorId': '2135004', 'name': 'Karin Kipper Schuler'}, {'authorId': '3139133', 'name': 'Razvan C. Bunescu'}, {'authorId': '1404704044', 'name': 'Emiel Krahmer'}, {'authorId': '145077269', 'name': 'F. Sebastiani'}, {'authorId': '2526345', 'name': 'J. Burstein'}, {'authorId': '2695965', 'name': 'S. Kulick'}, {'authorId': '39290981', 'name': 'Julie C. Sedivy'}, {'authorId': '1788025', 'name': 'L. Cavedon'}, {'authorId': '1747893', 'name': 'Mirella Lapata'}, {'authorId': '3109039', 'name': 'Violeta Seretan'}, {'authorId': '2332834', 'name': 'Keh-Jiann Chen'}, {'authorId': '1733034', 'name': 'Gina-Anne Levow'}, {'authorId': '1692491', 'name': 'Stuart M. Shieber'}, {'authorId': '2218418', 'name': 'Timothy Chklovski'}, {'authorId': '2116425506', 'name': 'David Lewis'}, {'authorId': '1722590', 'name': 'Advaith Siddharthan'}, {'authorId': '2754495', 'name': 'Massimiliano Ciaramita'}, {'authorId': '1751795', 'name': 'G. Ligozat'}, {'authorId': '144866028', 'name': 'Michel Simard'}, {'authorId': '144523372', 'name': 'S. Clark'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '2153151617', 'name': 'David Smith'}, {'authorId': '2067900468', 'name': 'Michael Collins'}, {'authorId': '1729172', 'name': 'I. Mani'}, {'authorId': '1876369', 'name': 'H. Somers'}, {'authorId': '15379653', 'name': 'Ann A. Copestake'}, {'authorId': '2132343592', 'name': 'Christopher Manning'}, {'authorId': '1737285', 'name': 'Radu Soricut'}, {'authorId': '1733593', 'name': 'J. Curran'}, {'authorId': '1695463', 'name': 'D. Marcu'}, {'authorId': '145421878', 'name': 'R. Sproat'}, {'authorId': '7465342', 'name': 'Ido Dagan'}, {'authorId': '1701063', 'name': 'M. Maybury'}, {'authorId': '1690152', 'name': 'Amanda Stent'}, {'authorId': '1700007', 'name': 'Mona T. Diab'}, {'authorId': '1798723', 'name': 'Mandar Mitra'}, {'authorId': '31380436', 'name': 'M. Strube'}, {'authorId': '145660941', 'name': 'P. Edmonds'}, {'authorId': '78659204', 'name': 'Mehryar Mohri'}, {'authorId': '1760868', 'name': 'M. Surdeanu'}, {'authorId': '2140552', 'name': 'D. Eichmann'}, {'authorId': '1719404', 'name': 'Alessandro Moschitti'}, {'authorId': '1730911', 'name': 'M. Swerts'}, {'authorId': '144016062', 'name': 'T. M. Ellison'}, {'authorId': '1683363', 'name': 'M. Nederhof'}, {'authorId': '3259253', 'name': 'Kristina Toutanova'}, {'authorId': '1708114', 'name': 'K. Erk'}, {'authorId': '3115414', 'name': 'A. Nenkova'}, {'authorId': '38734660', 'name': 'S. Tseng'}, {'authorId': '2059490498', 'name': 'George Foster'}, {'authorId': '145322333', 'name': 'H. Ney'}, {'authorId': '5108268', 'name': 'G. Tur'}, {'authorId': '1683412', 'name': 'Pascale Fung'}, {'authorId': '2949607', 'name': 'S. Oepen'}, {'authorId': '1750554', 'name': 'Sriram Venkatapathy'}, {'authorId': '1794075', 'name': 'Claire Gardent'}, {'authorId': '1723120', 'name': 'Kemal Oflazer'}, {'authorId': '1817166', 'name': 'Clare R. Voss'}, {'authorId': '7519068', 'name': 'Josef van Genabith'}, {'authorId': '12514743', 'name': ""Tom O'Hara""}, {'authorId': '1736049', 'name': 'B. Webber'}, {'authorId': '1793218', 'name': 'D. Gildea'}, {'authorId': '145047294', 'name': 'Gerald Penn'}, {'authorId': '2106279802', 'name': 'David Weir'}, {'authorId': '2469966', 'name': 'Roxana Girju'}, {'authorId': '1678591', 'name': 'Massimo Poesio'}, {'authorId': '2009300', 'name': 'R. Wicentowski'}, {'authorId': '144003169', 'name': 'Claire Grover'}, {'authorId': '1735131', 'name': 'Sameer Pradhan'}, {'authorId': '144120827', 'name': 'Janyce Wiebe'}, {'authorId': '1696645', 'name': 'Nizar Habash'}, {'authorId': '2694275', 'name': 'D. Prescher'}, {'authorId': '49803096', 'name': 'Florian Wolf'}, {'authorId': '1713428', 'name': 'S. Harabagiu'}, {'authorId': '144790244', 'name': 'A. Prince'}, {'authorId': None, 'name': 'Fei Xia'}, {'authorId': '1752407', 'name': 'P. Heeman'}, {'authorId': '1707726', 'name': 'J. Pustejovsky'}, {'authorId': '1702849', 'name': 'Nianwen Xue'}, {'authorId': '3118681', 'name': 'J. Hockenmaier'}, {'authorId': '2113633716', 'name': 'D. R. Scott'}, {'authorId': '144105277', 'name': 'Wen-tau Yih'}, {'authorId': '1726601', 'name': 'R. Hwa'}, {'authorId': '1680292', 'name': 'P. Resnik'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}, {'authorId': '93837210', 'name': 'Su-Ching Jian'}, {'authorId': '3289329', 'name': 'S. Riezler'}, {'authorId': '2337426', 'name': 'Fabio Massimo Zanzotto'}]"
46df5ca1d4d59ae67bec9fd151d9c1d07331529e,https://www.semanticscholar.org/paper/46df5ca1d4d59ae67bec9fd151d9c1d07331529e,Ieee Transactions on Knowledge and Data Engineering 1 Runtime Optimizations for Tree-based Machine Learning Models,"‚ÄîTree-based models have proven to be an effective solution for web ranking as well as other machine learning problems in diverse domains. This paper focuses on optimizing the runtime performance of applying such models to make predictions, specifically using gradient-boosted regression trees for learning to rank. Although exceedingly simple conceptually, most implementations of tree-based models do not efficiently utilize modern superscalar processors. By laying out data structures in memory in a more cache-conscious fashion, removing branches from the execution flow using a technique called predication, and micro-batching predictions using a technique called vectorization, we are able to better exploit modern processor architectures. Experiments on synthetic data and on three standard learning-to-rank datasets show that our approach is significantly faster than standard implementations.",,,36,62,"[{'authorId': '1858497', 'name': 'N. Asadi'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1701063719', 'name': 'Arjen P. de Vries'}]"
9f9c7afc1862f0eab7d782dbb8c3fb92a530c668,https://www.semanticscholar.org/paper/9f9c7afc1862f0eab7d782dbb8c3fb92a530c668,UMD / BBN at MSE 2005,"We implemented an initial application of a sentence-trimming approach (Trimmer) to the problem of multi-document summarization in the MSE2005 task. Sentence trimming was incorporated into a feature-based summarization system, called Multi-Document Trimmer (MDT), by using sentence trimming as both a pre-processing stage and a feature for sentence ranking. We demonstrate that we were able to port Trimmer easily to this new problem, although the impact of sentence trimming was minimal compared to other features used in the system. The performance of our system in the official MSE2005 task was around the middle of the pack (16 out of 27). After some minor bug fixes and a simple correction (dateline removal) we obtained an improvement on a post-hoc run on the test data.",,,10,1,"[{'authorId': '3192273', 'name': 'David M. Zajic'}, {'authorId': '1752326', 'name': 'B. Dorr'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]"
aca43da47fc4313a146de5a94415b22a6229f337,https://www.semanticscholar.org/paper/aca43da47fc4313a146de5a94415b22a6229f337,Generating Relations from Natural Language Using REXTOR,"The Problem: Everyone wants to be able to find information rapidly and conveniently. Ideally, we would like to have a system with the understanding of a human being and the perfect memory of a computer. A user should be able to pose a question in plain English‚Äîfor example, ‚Äúwhat do frogs eat‚Äù‚Äîand get a sensible answer, such as ‚ÄúAdult frogs eat mainly insects and other small animals, including earthworms, minnows, and spiders.‚Äù",,,3,0,"[{'authorId': '6104312', 'name': 'Boris Katz'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}, {'authorId': '1724731', 'name': 'Sue Felshin'}]"
